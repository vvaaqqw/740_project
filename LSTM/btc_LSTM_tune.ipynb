{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TKAxbUFku8lD"
   },
   "source": [
    "# **Dependancies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oFJOnSzBk_uB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 11:03:14.836731: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "# from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, PredefinedSplit\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from collections import Counter\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import randint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "22PseW2xqQET"
   },
   "source": [
    "# **Loading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = pd.read_csv(\"../Data/train_btc_selected_features.csv\")\n",
    "btc = pd.read_csv(\"../Data/btc_Data.csv\")\n",
    "btc['Date'] = pd.to_datetime(btc['Date'])\n",
    "btc = btc.set_index(\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2663409/3854812091.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  btcData['returns'] = btcData['priceUSD'].pct_change().copy()\n"
     ]
    }
   ],
   "source": [
    "btcData = btc[selected.columns]\n",
    "btcData['returns'] = btcData['priceUSD'].pct_change().copy()\n",
    "Data = btcData.drop(columns=['priceUSD'])\n",
    "Data = Data[1:]\n",
    "# divide X and Y\n",
    "X = Data.iloc[:,0:]\n",
    "#Y = Data['returns']   # 用returns的话就用这一行，然后把下一行comment掉\n",
    "Y = btcData['priceUSD'].shift(-30)[1:] # 反之亦然\n",
    "# Split into three data sets\n",
    "X_train = X['2016-01-01':'2019-12-31']\n",
    "X_val = X['2020-01-01':'2021-05-31']\n",
    "X_test = X['2021-06-01':'2023-01-01']\n",
    "\n",
    "Y_train = Y['2016-01-01':'2019-12-31']\n",
    "Y_val = Y['2020-01-01':'2021-05-31']\n",
    "Y_test = Y['2021-06-01':'2023-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing mixmax, total=   0.0s\n",
      "[Pipeline] ............ (step 2 of 2) Processing robust, total=   0.0s\n"
     ]
    }
   ],
   "source": [
    "estimators=[]\n",
    "estimators.append(['mixmax',MinMaxScaler()])\n",
    "estimators.append(['robust',RobustScaler()])\n",
    "scale=Pipeline(estimators,verbose=True)\n",
    "scale.fit(X_train)\n",
    "X_train=scale.transform(X_train)\n",
    "X_test=scale.transform(X_test)\n",
    "X_val = scale.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.reshape(X_train,(X_train.shape[0],1,X_train.shape[1]))\n",
    "X_val=np.reshape(X_val,(X_val.shape[0],1,X_val.shape[1]))\n",
    "X_test=np.reshape(X_test,(X_test.shape[0],1,X_test.shape[1]))\n",
    "Y_train=Y_train.values\n",
    "Y_train=np.reshape(Y_train, (Y_train.shape[0],1,1))\n",
    "Y_val=Y_val.values\n",
    "Y_val=np.reshape(Y_val, (Y_val.shape[0],1,1))\n",
    "Y_test=Y_test.values\n",
    "Y_test=np.reshape(Y_test, (Y_test.shape[0],1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "NBZ9JgDTrHwV",
    "outputId": "40d0a5ca-682d-42d1-e08b-fd28df246868"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spectre/anaconda3/envs/tensorplustorch/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "adam=Adam(lr=lr_schedule(0),amsgrad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    #first layer\n",
    "    model.add(Bidirectional(LSTM(hp.Int('input_unit1',min_value=32,max_value=512,step=32), return_sequences=True, activation='relu'), input_shape=(1, X_train.shape[2])))\n",
    "    for i in range(hp.Int('n_layers', 1, 3)):\n",
    "        model.add(Bidirectional(LSTM(hp.Int(f'input_unit{i+1}',min_value=32,max_value=512,step=32), return_sequences=True, activation='relu')))\n",
    "    #dropout layer\n",
    "    model.add(Dropout(hp.Float('Dropout_rate',min_value=0,max_value=0.5,step=0.1)))\n",
    "    # Dense layer\n",
    "    model.add(Dense(1, activation=hp.Choice('dense_activation',values=['relu', 'sigmoid'],default='relu')))\n",
    "    model.compile(loss=\"logcosh\", optimizer='adam', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project btc_tune/LSTM_TUNE/oracle.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 11:03:16.723121: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-04 11:03:16.723985: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "384               |?                 |input_unit1\n",
      "1                 |?                 |n_layers\n",
      "0.3               |?                 |Dropout_rate\n",
      "sigmoid           |?                 |dense_activation\n",
      "\n",
      "Epoch 1/5000\n",
      "46/46 [==============================] - 5s 57ms/step - loss: 5026.0776 - mae: 5026.7710 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 4/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 5/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 6/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 7/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 8/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 9/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 10/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 11/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 12/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 13/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 14/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 15/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 16/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 17/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 18/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 19/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 20/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 21/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 22/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 23/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 24/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 25/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9736 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 26/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 27/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 28/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 29/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 30/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 31/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 32/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 33/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 34/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 35/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 36/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 37/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 38/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 39/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 40/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 41/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 42/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 43/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 44/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 45/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 46/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 47/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 48/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9731 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 49/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 50/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 51/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 52/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 53/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 54/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 55/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9731 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 56/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 57/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 5025.9756 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 58/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 59/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 60/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 61/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 62/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 63/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 64/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 65/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9736 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 66/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 67/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 68/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 69/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 70/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 71/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 72/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 73/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 74/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 75/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 76/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 77/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 78/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 79/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 80/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 81/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 82/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 83/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 84/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 85/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 86/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 87/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 88/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 89/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 90/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 91/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 92/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 93/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 94/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 95/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 96/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 97/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 98/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 99/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 100/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 101/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 102/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 103/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 104/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 105/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 106/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 107/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 108/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 109/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 110/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 111/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 112/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 113/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 114/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 115/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9761 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 116/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9751 - mae: 5026.6665 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 117/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 118/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 119/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 120/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 121/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 122/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 123/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 124/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 125/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 126/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 127/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 128/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 129/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 130/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 131/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 132/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 133/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 134/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 135/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 136/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 137/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 138/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 139/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 140/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 141/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 142/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 143/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 144/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 145/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 146/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 147/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 148/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 149/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 150/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 151/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 152/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 153/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9736 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 154/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 155/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 156/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 157/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 158/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 159/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 160/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 161/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 162/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 163/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 164/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 165/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 166/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 167/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 168/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 169/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 170/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 171/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 172/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 173/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 174/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 175/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 176/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9731 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 177/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 178/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 179/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 180/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 181/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 182/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 183/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 184/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 185/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 186/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 187/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 188/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 189/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 190/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 191/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9736 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 192/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 193/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 194/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 195/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 196/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 197/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 198/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 199/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 200/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 201/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 202/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 203/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 204/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 205/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 206/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 207/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 208/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 209/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 210/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 211/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 212/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 213/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 214/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 215/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 216/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 217/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 218/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 219/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 220/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 221/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9736 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 222/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 223/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9761 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 224/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9761 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 225/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 226/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 227/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 228/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 229/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 230/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 231/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 232/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 233/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9736 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 234/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 235/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 236/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 237/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 238/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 239/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 240/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 241/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 242/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 243/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 244/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9736 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 245/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 246/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 247/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 248/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 249/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 250/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 251/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 252/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 253/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 254/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9756 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 255/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 256/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 257/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 258/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 259/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 260/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 261/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 262/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 263/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 264/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 265/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9736 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 266/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 267/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 268/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 269/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 270/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 271/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 272/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 273/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 274/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 275/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 276/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 277/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 278/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 279/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 280/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 281/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9736 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 282/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 283/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 284/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 285/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 286/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 287/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9761 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 288/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 289/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 290/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 291/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 292/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 293/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 294/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 295/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 296/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 297/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 298/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 299/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 300/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 301/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 302/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 303/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 304/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 305/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 306/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 307/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 308/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 309/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 310/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 311/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 312/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 313/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 314/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 315/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 316/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 317/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9736 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 318/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 319/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 320/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 321/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 322/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 323/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 324/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 325/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 326/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 327/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 328/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 329/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 330/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 331/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 332/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 333/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 334/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 335/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 336/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 337/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 338/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 339/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 340/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9756 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 341/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 342/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 343/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 344/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 345/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 346/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 347/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 348/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 349/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 350/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 351/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 352/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 353/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 354/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 355/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 356/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 357/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 358/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 359/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 360/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 361/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 362/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 363/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 364/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 365/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 366/5000\n",
      "46/46 [==============================] - 3s 61ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 367/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 368/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 369/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 370/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 371/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 372/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 373/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 374/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 375/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 376/5000\n",
      "46/46 [==============================] - 3s 61ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 377/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 378/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 379/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 380/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 381/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 382/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 383/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 384/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 385/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 386/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 387/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 388/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 389/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 390/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 391/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 392/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 393/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 394/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 395/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 396/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 397/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 398/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 399/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 400/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 401/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 402/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 403/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9761 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 404/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 405/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 406/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 407/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 408/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 409/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 410/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 411/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9736 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 412/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 413/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 414/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 415/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 416/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 417/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 418/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 419/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 420/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 421/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 422/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 423/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 424/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 425/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 426/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 427/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 428/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 429/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 430/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 431/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 432/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 433/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 434/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 435/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 436/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 437/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 438/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 439/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 440/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 441/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 442/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 443/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9731 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 444/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 445/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 446/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 447/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 448/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 449/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 450/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 451/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 452/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 453/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 454/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 455/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 456/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 457/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 458/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 459/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 460/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 461/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 462/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9736 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 463/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9736 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 464/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 465/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 466/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 467/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 468/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 469/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 470/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 471/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 472/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 473/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 474/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 475/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 476/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 477/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 478/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 479/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9761 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 480/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 481/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9761 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 482/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 483/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 484/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9736 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 485/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 486/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 487/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 488/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 489/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 490/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 491/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 492/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 493/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 494/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 495/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 496/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 497/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 498/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 499/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 500/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 501/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 502/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9736 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 503/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 504/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 505/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 506/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 507/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 508/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 509/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 510/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 511/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 512/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9736 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 513/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 514/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 515/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 516/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 517/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9736 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 518/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 519/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 520/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 521/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 522/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 523/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 524/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 525/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 526/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 527/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 528/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 529/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 530/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 531/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 532/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 533/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9761 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 534/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 535/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 536/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 537/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 538/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 539/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 540/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 541/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 542/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9736 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 543/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 544/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 545/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 546/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9736 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 547/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9736 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 548/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 549/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 550/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9756 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 551/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 552/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 553/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 554/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 555/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 556/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 557/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 558/5000\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 559/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 560/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 561/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 562/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 563/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 564/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9736 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 565/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 566/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 567/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 568/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 569/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 570/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 571/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 572/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 573/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 574/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 575/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 576/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 577/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 578/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 579/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 580/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 581/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 582/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 583/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 584/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 585/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 586/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 587/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 588/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9756 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 589/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 590/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 591/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 592/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 593/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 594/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 595/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 596/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 597/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 598/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 599/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 600/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 601/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 602/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 603/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 604/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 605/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 606/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 607/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 608/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 609/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 610/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 611/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 612/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 613/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 614/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 615/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 616/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 617/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 618/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9756 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 619/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 620/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 621/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 622/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 623/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 624/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 625/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6699 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 626/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 627/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 628/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 629/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 630/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 631/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 632/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 633/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 634/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 635/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 636/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 637/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 638/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 639/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 640/5000\n",
      "46/46 [==============================] - 3s 58ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 641/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 642/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 643/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 644/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 645/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 646/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 647/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 648/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 649/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 650/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 651/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 652/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 653/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 654/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 655/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 656/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 657/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9736 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 658/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 659/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 660/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 661/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 662/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 663/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 664/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 665/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6665 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 666/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 667/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 668/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 669/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 670/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 671/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 672/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 673/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 674/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 675/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 676/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 677/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 678/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 679/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 680/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 681/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 682/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 683/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 684/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 685/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 686/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6665 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 687/5000\n",
      "46/46 [==============================] - 3s 76ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 688/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 689/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 690/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 691/5000\n",
      "46/46 [==============================] - 2s 55ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 692/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 693/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 694/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 695/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 696/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 697/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 698/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 699/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 700/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 701/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 702/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 703/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 704/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 705/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 706/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 707/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 708/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 709/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 710/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 711/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 712/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 713/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 714/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 715/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 716/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 717/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 718/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 719/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 720/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 721/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 722/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 723/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 724/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 725/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 726/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 727/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 728/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 729/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9736 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 730/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 731/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 732/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 733/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 734/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 735/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 736/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 737/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 738/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 739/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 740/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 741/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 742/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 743/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 744/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 745/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 746/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 747/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9736 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 748/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 749/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 750/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 751/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 752/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 753/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 754/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 755/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 756/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 757/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 758/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 759/5000\n",
      "46/46 [==============================] - 3s 54ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 760/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 761/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 762/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 763/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 764/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 765/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 766/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 767/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9736 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 768/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 769/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 770/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 771/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 772/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 773/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 774/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 775/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 776/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 777/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 778/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 779/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 780/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 781/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 782/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 783/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 784/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 785/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 786/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 787/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 788/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 789/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 790/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 791/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 792/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 793/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 794/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 795/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 796/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 797/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 798/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 799/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 800/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 801/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 802/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 803/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 804/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 805/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 806/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 807/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 808/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 809/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 810/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 811/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6694 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 812/5000\n",
      "46/46 [==============================] - 4s 79ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 813/5000\n",
      "46/46 [==============================] - 4s 79ms/step - loss: 5025.9761 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 814/5000\n",
      "46/46 [==============================] - 3s 69ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 815/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 816/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 817/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 818/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 819/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 820/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 821/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 822/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 823/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 824/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 825/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 826/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 827/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 828/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 829/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 830/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 831/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 832/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 833/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 834/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 835/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 836/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 837/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 838/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 839/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 840/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 841/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 842/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 843/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 844/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 845/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 846/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 847/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 848/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 849/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 850/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 851/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 852/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 853/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 854/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 855/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 856/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 857/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 858/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 859/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 860/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 861/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 862/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 863/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 864/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 865/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 866/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 867/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 868/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 869/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 870/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9736 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 871/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 872/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 873/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 874/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9731 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 875/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 876/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 877/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 878/5000\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 879/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 880/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 881/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 882/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 883/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9766 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 884/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 885/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 886/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 887/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 888/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 889/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 890/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 891/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 892/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9731 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 893/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 894/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 895/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 896/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 897/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 898/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 899/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 900/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 901/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 902/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 903/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 904/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 905/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 906/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 907/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 908/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 909/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 910/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 911/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 912/5000\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 913/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 914/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 915/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 916/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 917/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 918/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 919/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 920/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 921/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 922/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 923/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 924/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 925/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 926/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9756 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 927/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 928/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 929/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 930/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 931/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 932/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 933/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 934/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 935/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 936/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 937/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9756 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 938/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 939/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 940/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9736 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 941/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 942/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 943/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 944/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 945/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 946/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 947/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 948/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 949/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 950/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 951/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 952/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6694 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 953/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 954/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 955/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 956/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 957/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 958/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 959/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 960/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 961/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 962/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 963/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 964/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 965/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 966/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 967/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 968/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9761 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 969/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 970/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 971/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 972/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 973/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 974/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 975/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 976/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 977/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 978/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 979/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 980/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 981/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 982/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 983/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 984/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 985/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 986/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 987/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 988/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 989/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 990/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 991/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 992/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 993/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9751 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 994/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 995/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 996/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 997/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 998/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 999/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1000/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1001/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1002/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1003/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1004/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1005/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9736 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1006/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1007/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1008/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1009/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1010/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1011/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1012/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1013/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1014/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1015/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1016/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1017/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1018/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1019/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9736 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1020/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1021/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1022/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1023/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1024/5000\n",
      "46/46 [==============================] - 3s 54ms/step - loss: 5025.9751 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1025/5000\n",
      "46/46 [==============================] - 3s 58ms/step - loss: 5025.9736 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1026/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1027/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1028/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1029/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1030/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1031/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1032/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1033/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1034/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1035/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1036/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1037/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1038/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1039/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1040/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1041/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1042/5000\n",
      "46/46 [==============================] - 3s 61ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1043/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1044/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1045/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1046/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1047/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1048/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1049/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1050/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1051/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1052/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1053/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1054/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1055/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1056/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1057/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1058/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1059/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1060/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1061/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9736 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1062/5000\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1063/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1064/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1065/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1066/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1067/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1068/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1069/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1070/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1071/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1072/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1073/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1074/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1075/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1076/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1077/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1078/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6665 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1079/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1080/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1081/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1082/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1083/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1084/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1085/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1086/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1087/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1088/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1089/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1090/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1091/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1092/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1093/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1094/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1095/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1096/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1097/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1098/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1099/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1100/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1101/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1102/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1103/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1104/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1105/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1106/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1107/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1108/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1109/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1110/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1111/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1112/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1113/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1114/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1115/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1116/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1117/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1118/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1119/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1120/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1121/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1122/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1123/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1124/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1125/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1126/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1127/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1128/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1129/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1130/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1131/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1132/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1133/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1134/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1135/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1136/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1137/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1138/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1139/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1140/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1141/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1142/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1143/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1144/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1145/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1146/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6699 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1147/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1148/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1149/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1150/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1151/5000\n",
      "46/46 [==============================] - 3s 59ms/step - loss: 5025.9761 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1152/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1153/5000\n",
      "46/46 [==============================] - 3s 58ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1154/5000\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1155/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1156/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1157/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9736 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1158/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1159/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1160/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1161/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1162/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1163/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1164/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9756 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1165/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1166/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1167/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1168/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1169/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1170/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1171/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1172/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1173/5000\n",
      "46/46 [==============================] - 3s 54ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1174/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1175/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1176/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1177/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1178/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9736 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1179/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1180/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1181/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1182/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1183/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1184/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1185/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1186/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1187/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1188/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1189/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1190/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9736 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1191/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9746 - mae: 5026.6694 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1192/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1193/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1194/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1195/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1196/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1197/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1198/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1199/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1200/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1201/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1202/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1203/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1204/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1205/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1206/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1207/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1208/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1209/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1210/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1211/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1212/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9736 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1213/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1214/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1215/5000\n",
      "46/46 [==============================] - 3s 54ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1216/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1217/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1218/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1219/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1220/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1221/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1222/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1223/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1224/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1225/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1226/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1227/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1228/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 5025.9736 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1229/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1230/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1231/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1232/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1233/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1234/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1235/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1236/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1237/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1238/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1239/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1240/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1241/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1242/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1243/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1244/5000\n",
      "46/46 [==============================] - 3s 61ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1245/5000\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1246/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1247/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1248/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1249/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1250/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1251/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1252/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1253/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1254/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1255/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1256/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1257/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1258/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1259/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1260/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1261/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1262/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1263/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1264/5000\n",
      "46/46 [==============================] - 3s 54ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1265/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1266/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1267/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1268/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1269/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1270/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1271/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1272/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1273/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1274/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1275/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1276/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1277/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1278/5000\n",
      "46/46 [==============================] - 4s 78ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1279/5000\n",
      "46/46 [==============================] - 3s 76ms/step - loss: 5025.9736 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1280/5000\n",
      "46/46 [==============================] - 3s 62ms/step - loss: 5025.9746 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1281/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1282/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1283/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1284/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1285/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1286/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1287/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1288/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1289/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1290/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1291/5000\n",
      "46/46 [==============================] - 3s 58ms/step - loss: 5025.9746 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1292/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1293/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1294/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1295/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1296/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1297/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1298/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1299/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1300/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1301/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1302/5000\n",
      "46/46 [==============================] - 3s 58ms/step - loss: 5025.9756 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1303/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1304/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1305/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1306/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1307/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1308/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1309/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1310/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1311/5000\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1312/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1313/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1314/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1315/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6694 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1316/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1317/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1318/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1319/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1320/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1321/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1322/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1323/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1324/5000\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1325/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1326/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1327/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1328/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1329/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1330/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1331/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1332/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1333/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1334/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1335/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1336/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9736 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1337/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1338/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1339/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1340/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1341/5000\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1342/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1343/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1344/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1345/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1346/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1347/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1348/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1349/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1350/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1351/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1352/5000\n",
      "46/46 [==============================] - 3s 58ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1353/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1354/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1355/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1356/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1357/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1358/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1359/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1360/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1361/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1362/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1363/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1364/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1365/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1366/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1367/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1368/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9736 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1369/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1370/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1371/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1372/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1373/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1374/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1375/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9731 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1376/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1377/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1378/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1379/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1380/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1381/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1382/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1383/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1384/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1385/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1386/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1387/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1388/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1389/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1390/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1391/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1392/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1393/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1394/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1395/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1396/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1397/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1398/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1399/5000\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1400/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1401/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1402/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1403/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1404/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1405/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1406/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1407/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1408/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1409/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9736 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1410/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1411/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1412/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1413/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1414/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1415/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1416/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1417/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1418/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1419/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1420/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1421/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1422/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1423/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1424/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1425/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1426/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1427/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9736 - mae: 5026.6694 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1428/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1429/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1430/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1431/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1432/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1433/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1434/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1435/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1436/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1437/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1438/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1439/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1440/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1441/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1442/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1443/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1444/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1445/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1446/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1447/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1448/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1449/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1450/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1451/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9736 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1452/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1453/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1454/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1455/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1456/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1457/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1458/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1459/5000\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1460/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1461/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1462/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1463/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1464/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1465/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1466/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1467/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1468/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1469/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1470/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1471/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1472/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1473/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1474/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1475/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1476/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1477/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1478/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9736 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1479/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1480/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1481/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1482/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1483/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1484/5000\n",
      "46/46 [==============================] - 3s 54ms/step - loss: 5025.9756 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1485/5000\n",
      "46/46 [==============================] - 3s 54ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1486/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1487/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1488/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1489/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1490/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9736 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1491/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1492/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1493/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1494/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1495/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1496/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1497/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1498/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1499/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1500/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1501/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1502/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1503/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1504/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1505/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1506/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1507/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1508/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1509/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1510/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1511/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1512/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1513/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1514/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1515/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1516/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1517/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1518/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1519/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1520/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1521/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1522/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1523/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1524/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1525/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1526/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1527/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1528/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1529/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1530/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1531/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1532/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1533/5000\n",
      "46/46 [==============================] - 3s 58ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1534/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1535/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1536/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1537/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1538/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1539/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1540/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1541/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1542/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1543/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1544/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1545/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1546/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1547/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9756 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1548/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1549/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1550/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9736 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1551/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1552/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1553/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1554/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1555/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1556/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1557/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1558/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1559/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1560/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1561/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1562/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1563/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1564/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1565/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1566/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1567/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1568/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1569/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1570/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1571/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1572/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1573/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1574/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1575/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1576/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1577/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1578/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1579/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1580/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1581/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9736 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1582/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9761 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1583/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1584/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1585/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1586/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1587/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1588/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1589/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9741 - mae: 5026.6665 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1590/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1591/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1592/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1593/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1594/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9746 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1595/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1596/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1597/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6665 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1598/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1599/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1600/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1601/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1602/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1603/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1604/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9756 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1605/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1606/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1607/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1608/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1609/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1610/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1611/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1612/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1613/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1614/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1615/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1616/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1617/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1618/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1619/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1620/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1621/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1622/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1623/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1624/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1625/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1626/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1627/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1628/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1629/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1630/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1631/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1632/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1633/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1634/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1635/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1636/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1637/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1638/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1639/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1640/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1641/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9731 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1642/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1643/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1644/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1645/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1646/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1647/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1648/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9756 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1649/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6694 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1650/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1651/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1652/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1653/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1654/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1655/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1656/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1657/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1658/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1659/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1660/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1661/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1662/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1663/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1664/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1665/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1666/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1667/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 5025.9736 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1668/5000\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1669/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1670/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9736 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1671/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1672/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1673/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1674/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1675/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1676/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1677/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1678/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1679/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1680/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1681/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1682/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9761 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1683/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1684/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1685/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1686/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1687/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1688/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1689/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1690/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1691/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1692/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1693/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1694/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1695/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1696/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1697/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1698/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1699/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1700/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1701/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1702/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1703/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1704/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1705/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1706/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1707/5000\n",
      "46/46 [==============================] - 3s 59ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1708/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1709/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1710/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1711/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1712/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1713/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1714/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1715/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1716/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1717/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1718/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1719/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9736 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1720/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1721/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1722/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1723/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1724/5000\n",
      "46/46 [==============================] - 3s 54ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1725/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1726/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1727/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1728/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1729/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1730/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1731/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1732/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1733/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1734/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1735/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1736/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1737/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1738/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1739/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1740/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1741/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1742/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1743/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1744/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1745/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1746/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1747/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1748/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1749/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1750/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1751/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1752/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1753/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1754/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1755/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1756/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1757/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1758/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1759/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1760/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1761/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1762/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9736 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1763/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1764/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1765/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1766/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1767/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1768/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1769/5000\n",
      "46/46 [==============================] - 3s 58ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1770/5000\n",
      "46/46 [==============================] - 3s 59ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1771/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1772/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1773/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1774/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1775/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1776/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1777/5000\n",
      "46/46 [==============================] - 3s 74ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1778/5000\n",
      "46/46 [==============================] - 4s 81ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1779/5000\n",
      "46/46 [==============================] - 3s 73ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1780/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1781/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1782/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1783/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1784/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1785/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1786/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1787/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1788/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1789/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1790/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1791/5000\n",
      "46/46 [==============================] - 3s 62ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1792/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1793/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1794/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1795/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1796/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1797/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1798/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1799/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1800/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1801/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1802/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1803/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1804/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1805/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1806/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1807/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1808/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1809/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1810/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1811/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1812/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1813/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1814/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1815/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1816/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1817/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1818/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1819/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1820/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1821/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1822/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1823/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1824/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1825/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1826/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6665 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1827/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1828/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1829/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1830/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1831/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1832/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1833/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1834/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1835/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1836/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1837/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1838/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1839/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1840/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1841/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1842/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1843/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1844/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1845/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1846/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1847/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1848/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1849/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1850/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1851/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1852/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1853/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1854/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1855/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1856/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1857/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1858/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1859/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1860/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1861/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1862/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1863/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1864/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1865/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1866/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1867/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1868/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1869/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1870/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1871/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1872/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1873/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1874/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1875/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1876/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1877/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1878/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1879/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1880/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1881/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1882/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1883/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1884/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1885/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1886/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1887/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1888/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1889/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1890/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1891/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1892/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1893/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1894/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1895/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1896/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1897/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1898/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1899/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1900/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1901/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1902/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1903/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1904/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1905/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1906/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1907/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1908/5000\n",
      "46/46 [==============================] - 3s 72ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1909/5000\n",
      "46/46 [==============================] - 4s 81ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1910/5000\n",
      "46/46 [==============================] - 3s 72ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1911/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1912/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1913/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1914/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1915/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1916/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9736 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1917/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1918/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1919/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1920/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1921/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1922/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1923/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1924/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1925/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1926/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1927/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1928/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1929/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1930/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1931/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1932/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1933/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1934/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1935/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1936/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1937/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1938/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1939/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1940/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9736 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1941/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1942/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1943/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1944/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1945/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1946/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1947/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1948/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1949/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1950/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1951/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1952/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1953/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1954/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1955/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1956/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1957/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1958/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1959/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1960/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1961/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1962/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1963/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1964/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1965/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1966/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1967/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1968/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1969/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1970/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1971/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1972/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1973/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1974/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1975/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1976/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1977/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1978/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1979/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1980/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1981/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1982/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1983/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1984/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1985/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1986/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1987/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1988/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1989/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1990/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1991/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1992/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1993/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1994/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1995/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9761 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1996/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1997/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1998/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 1999/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2000/5000\n",
      "46/46 [==============================] - 3s 59ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2001/5000\n",
      "46/46 [==============================] - 3s 54ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2002/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2003/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2004/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2005/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2006/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2007/5000\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2008/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2009/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2010/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2011/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2012/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9731 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2013/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2014/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2015/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2016/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2017/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2018/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2019/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2020/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2021/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2022/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2023/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2024/5000\n",
      "46/46 [==============================] - 3s 58ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2025/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2026/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2027/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2028/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2029/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2030/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2031/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2032/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2033/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2034/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2035/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2036/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2037/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2038/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2039/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2040/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2041/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2042/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2043/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2044/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2045/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2046/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2047/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2048/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2049/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6665 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2050/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2051/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2052/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2053/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2054/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2055/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2056/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2057/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2058/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2059/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2060/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2061/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2062/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2063/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2064/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2065/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2066/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2067/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2068/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9736 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2069/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2070/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2071/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2072/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2073/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2074/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2075/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2076/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2077/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2078/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2079/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2080/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2081/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2082/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2083/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2084/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2085/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2086/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2087/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2088/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2089/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2090/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2091/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9736 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2092/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2093/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2094/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2095/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2096/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9731 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2097/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2098/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2099/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2100/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2101/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2102/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2103/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2104/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9761 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2105/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2106/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2107/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2108/5000\n",
      "46/46 [==============================] - 3s 54ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2109/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2110/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2111/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2112/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2113/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6665 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2114/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2115/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9736 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2116/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2117/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2118/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2119/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2120/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2121/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2122/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2123/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2124/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2125/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2126/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2127/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2128/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2129/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2130/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2131/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2132/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2133/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2134/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2135/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2136/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2137/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2138/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2139/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2140/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2141/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2142/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2143/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2144/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2145/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2146/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2147/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2148/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2149/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2150/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9756 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2151/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2152/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2153/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2154/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2155/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2156/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2157/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2158/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2159/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2160/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2161/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2162/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2163/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2164/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2165/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9736 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2166/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2167/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2168/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9756 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2169/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2170/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2171/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2172/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2173/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2174/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2175/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2176/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2177/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2178/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2179/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2180/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2181/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2182/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2183/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2184/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2185/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2186/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2187/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2188/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2189/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2190/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2191/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2192/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2193/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2194/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2195/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2196/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2197/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2198/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2199/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2200/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2201/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2202/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2203/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2204/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2205/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2206/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2207/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2208/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2209/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2210/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2211/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2212/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2213/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9736 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2214/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2215/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2216/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2217/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2218/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2219/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2220/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2221/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2222/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2223/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2224/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2225/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2226/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2227/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2228/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2229/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2230/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2231/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2232/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9736 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2233/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2234/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2235/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2236/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2237/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2238/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2239/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2240/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2241/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2242/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2243/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2244/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9736 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2245/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2246/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2247/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2248/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2249/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2250/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2251/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2252/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2253/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2254/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2255/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2256/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2257/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2258/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2259/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2260/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2261/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2262/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2263/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2264/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2265/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2266/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2267/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2268/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2269/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2270/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2271/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2272/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2273/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2274/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2275/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2276/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2277/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2278/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2279/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2280/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9761 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2281/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9736 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2282/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2283/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2284/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2285/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2286/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2287/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2288/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2289/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2290/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2291/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2292/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2293/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2294/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2295/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2296/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2297/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2298/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2299/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2300/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2301/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2302/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2303/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2304/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2305/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2306/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9731 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2307/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2308/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2309/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2310/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2311/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2312/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2313/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2314/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2315/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2316/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2317/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2318/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2319/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2320/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2321/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2322/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2323/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2324/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2325/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2326/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6665 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2327/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2328/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2329/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2330/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2331/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2332/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2333/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2334/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2335/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2336/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2337/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2338/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2339/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2340/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2341/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2342/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2343/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2344/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2345/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2346/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2347/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2348/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2349/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2350/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2351/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2352/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2353/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2354/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2355/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2356/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2357/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2358/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2359/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2360/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2361/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9731 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2362/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2363/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2364/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2365/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2366/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2367/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2368/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2369/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2370/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2371/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2372/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2373/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2374/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2375/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2376/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2377/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2378/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2379/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2380/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2381/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2382/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2383/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2384/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2385/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2386/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2387/5000\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2388/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2389/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2390/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2391/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2392/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2393/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2394/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2395/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2396/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2397/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2398/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2399/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2400/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2401/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2402/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2403/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2404/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2405/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2406/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2407/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2408/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2409/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2410/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2411/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2412/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2413/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2414/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2415/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2416/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2417/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2418/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2419/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2420/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2421/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2422/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2423/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2424/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2425/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2426/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2427/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2428/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2429/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2430/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2431/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2432/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2433/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2434/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2435/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2436/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2437/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6694 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2438/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2439/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2440/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2441/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2442/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2443/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2444/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2445/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2446/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2447/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2448/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2449/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2450/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2451/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2452/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2453/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2454/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2455/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2456/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2457/5000\n",
      "46/46 [==============================] - 3s 62ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2458/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2459/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2460/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2461/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2462/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2463/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2464/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9761 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2465/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9736 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2466/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2467/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2468/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2469/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2470/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2471/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2472/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2473/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2474/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2475/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2476/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2477/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2478/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6665 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2479/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2480/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2481/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2482/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2483/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2484/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2485/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2486/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2487/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2488/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2489/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2490/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2491/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2492/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2493/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2494/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2495/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2496/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6665 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2497/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2498/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2499/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2500/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2501/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2502/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2503/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2504/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2505/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2506/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2507/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2508/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2509/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2510/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2511/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2512/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2513/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2514/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2515/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2516/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2517/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2518/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2519/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2520/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2521/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2522/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2523/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2524/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2525/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2526/5000\n",
      "46/46 [==============================] - 3s 59ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2527/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2528/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2529/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2530/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2531/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2532/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2533/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2534/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2535/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2536/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2537/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2538/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2539/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2540/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2541/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2542/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2543/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9746 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2544/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 5025.9756 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2545/5000\n",
      "46/46 [==============================] - 3s 59ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2546/5000\n",
      "46/46 [==============================] - 3s 58ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2547/5000\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2548/5000\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2549/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2550/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2551/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2552/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2553/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2554/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9736 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2555/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2556/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2557/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2558/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2559/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2560/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2561/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2562/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9761 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2563/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2564/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2565/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2566/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2567/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2568/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2569/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2570/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2571/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2572/5000\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 5025.9741 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2573/5000\n",
      "46/46 [==============================] - 3s 58ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2574/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2575/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2576/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2577/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2578/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2579/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2580/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2581/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2582/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2583/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2584/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2585/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6694 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2586/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2587/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2588/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2589/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2590/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2591/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2592/5000\n",
      "46/46 [==============================] - 3s 58ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2593/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2594/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2595/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2596/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2597/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2598/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2599/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2600/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2601/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2602/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2603/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2604/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2605/5000\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2606/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2607/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2608/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2609/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 5025.9756 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2610/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2611/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2612/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2613/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2614/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6694 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2615/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2616/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2617/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2618/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2619/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2620/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2621/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6694 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2622/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2623/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2624/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2625/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2626/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2627/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9736 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2628/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2629/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2630/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2631/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2632/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2633/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2634/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2635/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2636/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2637/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2638/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2639/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2640/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2641/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2642/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2643/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9756 - mae: 5026.6665 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2644/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2645/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2646/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2647/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2648/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2649/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2650/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2651/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2652/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2653/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2654/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2655/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2656/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2657/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2658/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2659/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2660/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2661/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2662/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2663/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2664/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2665/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2666/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2667/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2668/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2669/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2670/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2671/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2672/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2673/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2674/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2675/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2676/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2677/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2678/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2679/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2680/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2681/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2682/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2683/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2684/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2685/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2686/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2687/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2688/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2689/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2690/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2691/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2692/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2693/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2694/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2695/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2696/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2697/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2698/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9736 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2699/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2700/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2701/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2702/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2703/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2704/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2705/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2706/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2707/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2708/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2709/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2710/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9761 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2711/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2712/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9736 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2713/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2714/5000\n",
      "46/46 [==============================] - 3s 54ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2715/5000\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2716/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2717/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2718/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2719/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2720/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2721/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2722/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2723/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2724/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2725/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2726/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2727/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2728/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2729/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2730/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2731/5000\n",
      "46/46 [==============================] - 3s 58ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2732/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2733/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2734/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9736 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2735/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2736/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2737/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2738/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2739/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2740/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2741/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2742/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2743/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2744/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2745/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2746/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2747/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2748/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2749/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2750/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2751/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2752/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2753/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2754/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2755/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2756/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2757/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2758/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2759/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2760/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9746 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2761/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2762/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2763/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2764/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2765/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2766/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2767/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2768/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2769/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2770/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2771/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2772/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2773/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2774/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2775/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2776/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2777/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2778/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2779/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2780/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2781/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2782/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2783/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2784/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2785/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2786/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2787/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2788/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2789/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2790/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2791/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9736 - mae: 5026.6694 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2792/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2793/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2794/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9761 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2795/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2796/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2797/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2798/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2799/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2800/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9736 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2801/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2802/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2803/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2804/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2805/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6665 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2806/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2807/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2808/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2809/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2810/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2811/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2812/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2813/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2814/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2815/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2816/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2817/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2818/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2819/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2820/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2821/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2822/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2823/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2824/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2825/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2826/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2827/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2828/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2829/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2830/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2831/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2832/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2833/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2834/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2835/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2836/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2837/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2838/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2839/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2840/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2841/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2842/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2843/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2844/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2845/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2846/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2847/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2848/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2849/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2850/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2851/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2852/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2853/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2854/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2855/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2856/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2857/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2858/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2859/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2860/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2861/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2862/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2863/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2864/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2865/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2866/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2867/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2868/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2869/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2870/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2871/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2872/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2873/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2874/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2875/5000\n",
      "46/46 [==============================] - 3s 62ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2876/5000\n",
      "46/46 [==============================] - 4s 77ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2877/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2878/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2879/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2880/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2881/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2882/5000\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 5025.9736 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2883/5000\n",
      "46/46 [==============================] - 3s 59ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2884/5000\n",
      "46/46 [==============================] - 3s 64ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2885/5000\n",
      "46/46 [==============================] - 3s 62ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2886/5000\n",
      "46/46 [==============================] - 4s 77ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2887/5000\n",
      "46/46 [==============================] - 3s 62ms/step - loss: 5025.9761 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2888/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9736 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2889/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2890/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2891/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2892/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2893/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2894/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2895/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2896/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2897/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2898/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2899/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2900/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2901/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2902/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9736 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2903/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2904/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2905/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2906/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2907/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2908/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2909/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2910/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2911/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2912/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9736 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2913/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2914/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2915/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2916/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2917/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2918/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2919/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2920/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2921/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2922/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2923/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2924/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2925/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2926/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2927/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2928/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2929/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2930/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2931/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2932/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2933/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2934/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2935/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2936/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2937/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2938/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2939/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2940/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2941/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2942/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2943/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2944/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2945/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2946/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2947/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2948/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2949/5000\n",
      "46/46 [==============================] - 3s 54ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2950/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2951/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2952/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2953/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2954/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2955/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2956/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2957/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2958/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2959/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9731 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2960/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2961/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2962/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2963/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2964/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2965/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2966/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2967/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2968/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2969/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2970/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9736 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2971/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2972/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2973/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2974/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6665 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2975/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2976/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2977/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2978/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2979/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2980/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2981/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2982/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2983/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2984/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9736 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2985/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2986/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2987/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2988/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2989/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2990/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2991/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2992/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2993/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2994/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2995/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2996/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2997/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2998/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 2999/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3000/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3001/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9756 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3002/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3003/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3004/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3005/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3006/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3007/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3008/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9751 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3009/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3010/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3011/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3012/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3013/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3014/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3015/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3016/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3017/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3018/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3019/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3020/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3021/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3022/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3023/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3024/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3025/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3026/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3027/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3028/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3029/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3030/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3031/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3032/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3033/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3034/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3035/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3036/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3037/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3038/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3039/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3040/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3041/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3042/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3043/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3044/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3045/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3046/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3047/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3048/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3049/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3050/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3051/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3052/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3053/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3054/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3055/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3056/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3057/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3058/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3059/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3060/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3061/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3062/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3063/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3064/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3065/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3066/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3067/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3068/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3069/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3070/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3071/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3072/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3073/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3074/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3075/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3076/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3077/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3078/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3079/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3080/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3081/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3082/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3083/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3084/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3085/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9756 - mae: 5026.6665 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3086/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3087/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3088/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3089/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3090/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9751 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3091/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3092/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3093/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9761 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3094/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3095/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3096/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3097/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3098/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3099/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3100/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3101/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3102/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3103/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3104/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3105/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3106/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3107/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3108/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3109/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3110/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3111/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3112/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3113/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3114/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3115/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3116/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3117/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3118/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3119/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9736 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3120/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3121/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3122/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3123/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3124/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3125/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3126/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3127/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3128/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3129/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3130/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3131/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3132/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3133/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3134/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3135/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3136/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3137/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3138/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3139/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3140/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6694 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3141/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3142/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3143/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3144/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3145/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3146/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3147/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3148/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3149/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3150/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3151/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3152/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3153/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3154/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3155/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3156/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3157/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3158/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3159/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3160/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3161/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3162/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3163/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3164/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3165/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3166/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3167/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3168/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3169/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3170/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3171/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3172/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3173/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9736 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3174/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3175/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3176/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3177/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5025.9751 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3178/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3179/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6665 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3180/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9741 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3181/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3182/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9741 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3183/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3184/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3185/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9756 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3186/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3187/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3188/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9751 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3189/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3190/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3191/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3192/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9756 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3193/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 5025.9751 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3194/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9756 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3195/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3196/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3197/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9741 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3198/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3199/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 5025.9751 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3200/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5025.9746 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3201/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5025.9741 - mae: 5026.6685 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3202/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9761 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3203/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5025.9746 - mae: 5026.6689 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3204/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3205/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 5025.9746 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3206/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3207/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9756 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3208/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5025.9756 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3209/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 5025.9741 - mae: 5026.6670 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3210/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5025.9746 - mae: 5026.6675 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3211/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5025.9751 - mae: 5026.6680 - val_loss: 23407.9863 - val_mae: 23408.6797\n",
      "Epoch 3212/5000\n",
      "33/46 [====================>.........] - ETA: 0s - loss: 5010.2129 - mae: 5010.9048"
     ]
    }
   ],
   "source": [
    "tuner= kt.RandomSearch(\n",
    "        build_model,\n",
    "        objective='val_mse',\n",
    "        max_trials=10,\n",
    "        executions_per_trial=1,\n",
    "        directory='btc_tune',\n",
    "        project_name='LSTM_TUNE'\n",
    "        )\n",
    "\n",
    "tuner.search(\n",
    "        x=X_train,\n",
    "        y=Y_train,\n",
    "        epochs=5000,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_val,Y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best hyperparameters.\n",
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "# Build the model with the best hp.\n",
    "regressor = build_model(best_hp)\n",
    "# Fit with the entire dataset.\n",
    "X_val = np.concatenate((X_train, X_val))\n",
    "Y_val = np.concatenate((Y_train, Y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0WWSdc7AxKV6"
   },
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='loss', patience=1000, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(x=X_all, y=Y_all, epochs=5000, batch_size=32, use_multiprocessing=True, callbacks=[earlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf8814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred=regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0f090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for check\n",
    "Y_train_pred=regressor.predict(X_train)\n",
    "r2_score(Y_train, Y_train_pred) #training score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e757ef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2=r2_score(Y_test[:-30],y_pred[:-30]) #score/ r^2\n",
    "print(f'r2:{r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ef1c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2_oos\n",
    "def r2_oos(ret, pred):\n",
    "    sum_of_sq_res = np.nansum(np.power((ret-pred), 2))\n",
    "    sum_of_sq_total = np.nansum(np.power(ret, 2))\n",
    "    \n",
    "    return 1-sum_of_sq_res/sum_of_sq_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b87143",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae=mean_absolute_error(Y_test[:-30],y_pred[:-30]) #mae\n",
    "print(f'mae:{mae}')\n",
    "\n",
    "rmse=np.sqrt(mean_squared_error(Y_test[:-30],y_pred[:-30])) #rmse\n",
    "print(f'rmse:{rmse}')\n",
    "\n",
    "mape=mean_absolute_percentage_error(Y_test[:-30],y_pred[:-30]) #mape\n",
    "print(f'mape:{mape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8969a6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_oos = r2_oos(Y_test[:-30], y_pred[:-30])\n",
    "print(f'r2_oos:{r2_oos}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb36caf",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5641115",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df = pd.DataFrame(zip(Y_test,y_pred),columns=['Y_test','y_pred'])\n",
    "pre_df.index = Y_test.index\n",
    "pre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4bd2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df['pred_returns'] = pre_df['y_pred'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b94aa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9674c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(zip(Y_test,y_pred),columns=['Y_test','y_pred']).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732393ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df.to_csv(\"../result/LSTM/btc_lstm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!kdeconnect-cli -n TAS-AN00 --ping-msg 'Script complete!'"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Stock Market Predictor.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "efc08374433b8d8e4a9fd8a0a66f7295c7ce37eceb639810a945045512ff181b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
