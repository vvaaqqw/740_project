{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TKAxbUFku8lD"
   },
   "source": [
    "# **Dependancies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oFJOnSzBk_uB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 15:40:36.867982: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import *\n",
    "from keras.callbacks import *\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from keras.layers import *\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "22PseW2xqQET"
   },
   "source": [
    "# **Loading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = pd.read_csv(\"../Data/train_btc_selected_features.csv\")\n",
    "btc = pd.read_csv(\"../Data/btc_Data.csv\")\n",
    "btc['Date'] = pd.to_datetime(btc['Date'])\n",
    "btc = btc.set_index(\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2899128/3854812091.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  btcData['returns'] = btcData['priceUSD'].pct_change().copy()\n"
     ]
    }
   ],
   "source": [
    "btcData = btc[selected.columns]\n",
    "btcData['returns'] = btcData['priceUSD'].pct_change().copy()\n",
    "Data = btcData.drop(columns=['priceUSD'])\n",
    "Data = Data[1:]\n",
    "# divide X and Y\n",
    "X = Data.iloc[:,0:]\n",
    "#Y = Data['returns']   # 用returns的话就用这一行，然后把下一行comment掉\n",
    "Y = btcData['priceUSD'].shift(-30)[1:] # 反之亦然\n",
    "# Split into three data sets\n",
    "X_train = X['2016-01-01':'2019-12-31']\n",
    "X_val = X['2020-01-01':'2021-05-31']\n",
    "X_test = X['2021-06-01':'2023-01-01']\n",
    "\n",
    "Y_train = Y['2016-01-01':'2019-12-31']\n",
    "Y_val = Y['2020-01-01':'2021-05-31']\n",
    "Y_test = Y['2021-06-01':'2023-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing mixmax, total=   0.0s\n",
      "[Pipeline] ............ (step 2 of 2) Processing robust, total=   0.0s\n"
     ]
    }
   ],
   "source": [
    "estimators=[]\n",
    "estimators.append(['mixmax',MinMaxScaler()])\n",
    "estimators.append(['robust',RobustScaler()])\n",
    "scale=Pipeline(estimators,verbose=True)\n",
    "scale.fit(X_train)\n",
    "X_train=scale.transform(X_train)\n",
    "X_test=scale.transform(X_test)\n",
    "X_val = scale.transform(X_val)\n",
    "tmp_index = Y_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.reshape(X_train,(X_train.shape[0],1,X_train.shape[1]))\n",
    "X_val=np.reshape(X_val,(X_val.shape[0],1,X_val.shape[1]))\n",
    "X_test=np.reshape(X_test,(X_test.shape[0],1,X_test.shape[1]))\n",
    "Y_train=Y_train.values\n",
    "Y_train=np.reshape(Y_train, (Y_train.shape[0],1,1))\n",
    "Y_val=Y_val.values\n",
    "Y_val=np.reshape(Y_val, (Y_val.shape[0],1,1))\n",
    "Y_test=Y_test.values\n",
    "Y_test=np.reshape(Y_test, (Y_test.shape[0],1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "NBZ9JgDTrHwV",
    "outputId": "40d0a5ca-682d-42d1-e08b-fd28df246868"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spectre/anaconda3/envs/tensorplustorch/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "adam=optimizers.Adam(lr=lr_schedule(0),amsgrad=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://medium.com/analytics-vidhya/hypertuning-a-lstm-with-keras-tuner-to-forecast-solar-irradiance-7da7577e96eb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 15:40:38.123040: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-04 15:40:38.124107: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "regressor = Sequential()\n",
    "regressor.add(Bidirectional(LSTM(350, return_sequences=True, activation='relu'), input_shape=(1, X_train.shape[2])))\n",
    "regressor.add(Bidirectional(LSTM(350, return_sequences=True, activation='relu')))\n",
    "regressor.add(Dense(1))\n",
    "regressor.compile(loss=\"logcosh\", optimizer=adam, metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0WWSdc7AxKV6"
   },
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=1000, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "46/46 [==============================] - 4s 45ms/step - loss: 4761.9102 - mae: 4762.6025 - val_loss: 19223.4375 - val_mae: 19224.1309\n",
      "Epoch 2/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 3436.6812 - mae: 3437.3745 - val_loss: 6741.5103 - val_mae: 6742.2036\n",
      "Epoch 3/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 2029.5686 - mae: 2030.2611 - val_loss: 6016.0298 - val_mae: 6016.7231\n",
      "Epoch 4/5000\n",
      "46/46 [==============================] - 2s 33ms/step - loss: 1599.3231 - mae: 1600.0159 - val_loss: 6294.9976 - val_mae: 6295.6899\n",
      "Epoch 5/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 1308.4103 - mae: 1309.1031 - val_loss: 6447.3574 - val_mae: 6448.0503\n",
      "Epoch 6/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 1172.9850 - mae: 1173.6772 - val_loss: 6705.4082 - val_mae: 6706.1011\n",
      "Epoch 7/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 1077.5599 - mae: 1078.2521 - val_loss: 6746.4648 - val_mae: 6747.1572\n",
      "Epoch 8/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 998.5330 - mae: 999.2253 - val_loss: 6637.0420 - val_mae: 6637.7344\n",
      "Epoch 9/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 918.2461 - mae: 918.9393 - val_loss: 6797.2437 - val_mae: 6797.9375\n",
      "Epoch 10/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 866.6864 - mae: 867.3784 - val_loss: 6660.9585 - val_mae: 6661.6509\n",
      "Epoch 11/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 824.1135 - mae: 824.8052 - val_loss: 6722.1611 - val_mae: 6722.8550\n",
      "Epoch 12/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 789.4299 - mae: 790.1219 - val_loss: 6707.3052 - val_mae: 6707.9980\n",
      "Epoch 13/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 756.3674 - mae: 757.0588 - val_loss: 6782.2139 - val_mae: 6782.9062\n",
      "Epoch 14/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 739.6895 - mae: 740.3812 - val_loss: 6678.3589 - val_mae: 6679.0518\n",
      "Epoch 15/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 725.6108 - mae: 726.3026 - val_loss: 6642.2930 - val_mae: 6642.9858\n",
      "Epoch 16/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 696.0662 - mae: 696.7585 - val_loss: 6686.8706 - val_mae: 6687.5640\n",
      "Epoch 17/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 683.5601 - mae: 684.2515 - val_loss: 6708.5723 - val_mae: 6709.2651\n",
      "Epoch 18/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 667.2184 - mae: 667.9091 - val_loss: 6674.0215 - val_mae: 6674.7153\n",
      "Epoch 19/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 639.6090 - mae: 640.3015 - val_loss: 6758.4370 - val_mae: 6759.1304\n",
      "Epoch 20/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 632.4681 - mae: 633.1594 - val_loss: 6639.6704 - val_mae: 6640.3628\n",
      "Epoch 21/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 607.0414 - mae: 607.7330 - val_loss: 6815.0308 - val_mae: 6815.7246\n",
      "Epoch 22/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 613.0208 - mae: 613.7118 - val_loss: 7108.9312 - val_mae: 7109.6250\n",
      "Epoch 23/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 592.6418 - mae: 593.3336 - val_loss: 6988.0093 - val_mae: 6988.7031\n",
      "Epoch 24/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 574.1237 - mae: 574.8157 - val_loss: 7163.4453 - val_mae: 7164.1392\n",
      "Epoch 25/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 556.7792 - mae: 557.4715 - val_loss: 7084.8247 - val_mae: 7085.5181\n",
      "Epoch 26/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 546.1251 - mae: 546.8163 - val_loss: 6961.8042 - val_mae: 6962.4971\n",
      "Epoch 27/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 533.2756 - mae: 533.9672 - val_loss: 7266.5005 - val_mae: 7267.1934\n",
      "Epoch 28/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 526.0018 - mae: 526.6932 - val_loss: 7063.5166 - val_mae: 7064.2095\n",
      "Epoch 29/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 510.9754 - mae: 511.6673 - val_loss: 7174.4282 - val_mae: 7175.1206\n",
      "Epoch 30/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 504.8999 - mae: 505.5915 - val_loss: 7356.4922 - val_mae: 7357.1855\n",
      "Epoch 31/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 494.2892 - mae: 494.9802 - val_loss: 7130.7637 - val_mae: 7131.4565\n",
      "Epoch 32/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 485.0920 - mae: 485.7841 - val_loss: 7353.3579 - val_mae: 7354.0522\n",
      "Epoch 33/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 468.8946 - mae: 469.5852 - val_loss: 7339.9551 - val_mae: 7340.6489\n",
      "Epoch 34/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 471.9717 - mae: 472.6639 - val_loss: 7169.9917 - val_mae: 7170.6836\n",
      "Epoch 35/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 455.3268 - mae: 456.0186 - val_loss: 7444.6230 - val_mae: 7445.3159\n",
      "Epoch 36/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 446.6702 - mae: 447.3611 - val_loss: 7902.8213 - val_mae: 7903.5151\n",
      "Epoch 37/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 459.9071 - mae: 460.5991 - val_loss: 7548.8110 - val_mae: 7549.5039\n",
      "Epoch 38/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 432.6509 - mae: 433.3423 - val_loss: 7405.2520 - val_mae: 7405.9443\n",
      "Epoch 39/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 433.5648 - mae: 434.2554 - val_loss: 7670.1445 - val_mae: 7670.8379\n",
      "Epoch 40/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 422.3019 - mae: 422.9928 - val_loss: 7499.1411 - val_mae: 7499.8345\n",
      "Epoch 41/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 428.1313 - mae: 428.8223 - val_loss: 7715.5215 - val_mae: 7716.2144\n",
      "Epoch 42/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 404.5780 - mae: 405.2688 - val_loss: 7795.0376 - val_mae: 7795.7305\n",
      "Epoch 43/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 405.2369 - mae: 405.9293 - val_loss: 7671.0093 - val_mae: 7671.7017\n",
      "Epoch 44/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 392.5053 - mae: 393.1970 - val_loss: 7719.8096 - val_mae: 7720.5029\n",
      "Epoch 45/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 398.6097 - mae: 399.2993 - val_loss: 7759.0127 - val_mae: 7759.7061\n",
      "Epoch 46/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 381.0323 - mae: 381.7234 - val_loss: 8371.6553 - val_mae: 8372.3496\n",
      "Epoch 47/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 366.6870 - mae: 367.3767 - val_loss: 7988.8838 - val_mae: 7989.5767\n",
      "Epoch 48/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 374.6842 - mae: 375.3739 - val_loss: 8018.2017 - val_mae: 8018.8950\n",
      "Epoch 49/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 356.5095 - mae: 357.2007 - val_loss: 7984.3013 - val_mae: 7984.9941\n",
      "Epoch 50/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 359.2728 - mae: 359.9630 - val_loss: 8084.7612 - val_mae: 8085.4536\n",
      "Epoch 51/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 352.7989 - mae: 353.4875 - val_loss: 7968.1743 - val_mae: 7968.8677\n",
      "Epoch 52/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 356.5918 - mae: 357.2808 - val_loss: 8028.5542 - val_mae: 8029.2471\n",
      "Epoch 53/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 337.9150 - mae: 338.6064 - val_loss: 8298.7314 - val_mae: 8299.4238\n",
      "Epoch 54/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 336.9047 - mae: 337.5961 - val_loss: 8582.3672 - val_mae: 8583.0605\n",
      "Epoch 55/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 341.4232 - mae: 342.1124 - val_loss: 8645.3174 - val_mae: 8646.0098\n",
      "Epoch 56/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 342.0989 - mae: 342.7899 - val_loss: 8057.6157 - val_mae: 8058.3091\n",
      "Epoch 57/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 322.8372 - mae: 323.5283 - val_loss: 8322.6250 - val_mae: 8323.3184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 317.8030 - mae: 318.4928 - val_loss: 8477.8115 - val_mae: 8478.5049\n",
      "Epoch 59/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 329.1577 - mae: 329.8482 - val_loss: 8591.9971 - val_mae: 8592.6904\n",
      "Epoch 60/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 329.9289 - mae: 330.6205 - val_loss: 8517.5518 - val_mae: 8518.2461\n",
      "Epoch 61/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 315.9620 - mae: 316.6522 - val_loss: 8645.0439 - val_mae: 8645.7363\n",
      "Epoch 62/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 316.9644 - mae: 317.6551 - val_loss: 8230.3887 - val_mae: 8231.0820\n",
      "Epoch 63/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 304.6367 - mae: 305.3261 - val_loss: 8482.8174 - val_mae: 8483.5107\n",
      "Epoch 64/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 295.0815 - mae: 295.7715 - val_loss: 8520.3418 - val_mae: 8521.0342\n",
      "Epoch 65/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 307.8517 - mae: 308.5420 - val_loss: 8951.9570 - val_mae: 8952.6504\n",
      "Epoch 66/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 291.4536 - mae: 292.1434 - val_loss: 9312.2959 - val_mae: 9312.9893\n",
      "Epoch 67/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 298.4991 - mae: 299.1895 - val_loss: 9072.7627 - val_mae: 9073.4541\n",
      "Epoch 68/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 284.8845 - mae: 285.5727 - val_loss: 8528.0244 - val_mae: 8528.7178\n",
      "Epoch 69/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 285.0374 - mae: 285.7278 - val_loss: 8784.8271 - val_mae: 8785.5195\n",
      "Epoch 70/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 288.4981 - mae: 289.1860 - val_loss: 8934.1670 - val_mae: 8934.8604\n",
      "Epoch 71/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 276.3970 - mae: 277.0861 - val_loss: 8935.6953 - val_mae: 8936.3887\n",
      "Epoch 72/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 281.1679 - mae: 281.8571 - val_loss: 9117.5488 - val_mae: 9118.2422\n",
      "Epoch 73/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 278.4038 - mae: 279.0937 - val_loss: 9047.8535 - val_mae: 9048.5479\n",
      "Epoch 74/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 274.4296 - mae: 275.1196 - val_loss: 8863.9121 - val_mae: 8864.6055\n",
      "Epoch 75/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 264.8692 - mae: 265.5581 - val_loss: 9120.8691 - val_mae: 9121.5625\n",
      "Epoch 76/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 262.2023 - mae: 262.8922 - val_loss: 9164.5186 - val_mae: 9165.2109\n",
      "Epoch 77/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 259.7431 - mae: 260.4304 - val_loss: 9133.6641 - val_mae: 9134.3564\n",
      "Epoch 78/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 266.7695 - mae: 267.4598 - val_loss: 9484.5869 - val_mae: 9485.2803\n",
      "Epoch 79/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 262.6812 - mae: 263.3712 - val_loss: 9402.1191 - val_mae: 9402.8125\n",
      "Epoch 80/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 257.9889 - mae: 258.6772 - val_loss: 9160.6436 - val_mae: 9161.3379\n",
      "Epoch 81/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 253.6785 - mae: 254.3682 - val_loss: 9114.0400 - val_mae: 9114.7334\n",
      "Epoch 82/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 265.4232 - mae: 266.1126 - val_loss: 9490.7891 - val_mae: 9491.4814\n",
      "Epoch 83/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 249.7307 - mae: 250.4197 - val_loss: 9177.5293 - val_mae: 9178.2227\n",
      "Epoch 84/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 253.6125 - mae: 254.3013 - val_loss: 9145.6279 - val_mae: 9146.3203\n",
      "Epoch 85/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 250.8350 - mae: 251.5251 - val_loss: 9279.2930 - val_mae: 9279.9873\n",
      "Epoch 86/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 240.8040 - mae: 241.4922 - val_loss: 9306.6299 - val_mae: 9307.3242\n",
      "Epoch 87/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 234.1005 - mae: 234.7893 - val_loss: 9424.8389 - val_mae: 9425.5332\n",
      "Epoch 88/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 238.6758 - mae: 239.3649 - val_loss: 9450.6836 - val_mae: 9451.3770\n",
      "Epoch 89/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 228.3073 - mae: 228.9960 - val_loss: 9435.1230 - val_mae: 9435.8164\n",
      "Epoch 90/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 225.6584 - mae: 226.3470 - val_loss: 9300.0791 - val_mae: 9300.7725\n",
      "Epoch 91/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 229.2903 - mae: 229.9801 - val_loss: 9164.4883 - val_mae: 9165.1816\n",
      "Epoch 92/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 231.3948 - mae: 232.0846 - val_loss: 9495.8535 - val_mae: 9496.5469\n",
      "Epoch 93/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 234.5796 - mae: 235.2694 - val_loss: 9273.5537 - val_mae: 9274.2471\n",
      "Epoch 94/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 238.3342 - mae: 239.0226 - val_loss: 9247.3672 - val_mae: 9248.0605\n",
      "Epoch 95/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 243.9592 - mae: 244.6486 - val_loss: 9520.9717 - val_mae: 9521.6650\n",
      "Epoch 96/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 227.8019 - mae: 228.4919 - val_loss: 9319.0215 - val_mae: 9319.7139\n",
      "Epoch 97/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 227.7550 - mae: 228.4460 - val_loss: 9495.0303 - val_mae: 9495.7236\n",
      "Epoch 98/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 224.0787 - mae: 224.7691 - val_loss: 9218.6162 - val_mae: 9219.3086\n",
      "Epoch 99/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 215.6087 - mae: 216.2974 - val_loss: 9523.2080 - val_mae: 9523.9014\n",
      "Epoch 100/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 218.2452 - mae: 218.9350 - val_loss: 9071.0332 - val_mae: 9071.7256\n",
      "Epoch 101/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 212.3346 - mae: 213.0233 - val_loss: 9281.6904 - val_mae: 9282.3828\n",
      "Epoch 102/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 210.6095 - mae: 211.2975 - val_loss: 9528.2832 - val_mae: 9528.9756\n",
      "Epoch 103/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 212.4662 - mae: 213.1548 - val_loss: 9473.4395 - val_mae: 9474.1328\n",
      "Epoch 104/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 213.4827 - mae: 214.1718 - val_loss: 9337.2178 - val_mae: 9337.9092\n",
      "Epoch 105/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 215.1217 - mae: 215.8122 - val_loss: 9444.0771 - val_mae: 9444.7705\n",
      "Epoch 106/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 215.3097 - mae: 216.0014 - val_loss: 9563.9365 - val_mae: 9564.6279\n",
      "Epoch 107/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 201.3819 - mae: 202.0715 - val_loss: 9312.1611 - val_mae: 9312.8545\n",
      "Epoch 108/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 206.2923 - mae: 206.9799 - val_loss: 9376.3545 - val_mae: 9377.0479\n",
      "Epoch 109/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 213.5511 - mae: 214.2405 - val_loss: 9425.7207 - val_mae: 9426.4131\n",
      "Epoch 110/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 198.7382 - mae: 199.4269 - val_loss: 9541.4023 - val_mae: 9542.0957\n",
      "Epoch 111/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 200.7295 - mae: 201.4177 - val_loss: 9527.8496 - val_mae: 9528.5420\n",
      "Epoch 112/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 200.1604 - mae: 200.8461 - val_loss: 9814.1377 - val_mae: 9814.8301\n",
      "Epoch 113/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 199.0576 - mae: 199.7458 - val_loss: 9404.9512 - val_mae: 9405.6445\n",
      "Epoch 114/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 202.4057 - mae: 203.0914 - val_loss: 9824.5674 - val_mae: 9825.2598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 195.2096 - mae: 195.8991 - val_loss: 9780.7510 - val_mae: 9781.4453\n",
      "Epoch 116/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 200.8238 - mae: 201.5137 - val_loss: 9599.7041 - val_mae: 9600.3975\n",
      "Epoch 117/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 194.6975 - mae: 195.3839 - val_loss: 9530.5342 - val_mae: 9531.2275\n",
      "Epoch 118/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 190.0944 - mae: 190.7831 - val_loss: 9412.7539 - val_mae: 9413.4473\n",
      "Epoch 119/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 194.4309 - mae: 195.1187 - val_loss: 9593.9326 - val_mae: 9594.6260\n",
      "Epoch 120/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 185.8822 - mae: 186.5707 - val_loss: 9686.0713 - val_mae: 9686.7646\n",
      "Epoch 121/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 188.1131 - mae: 188.8006 - val_loss: 9747.0381 - val_mae: 9747.7324\n",
      "Epoch 122/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 186.6509 - mae: 187.3398 - val_loss: 9499.6699 - val_mae: 9500.3633\n",
      "Epoch 123/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 189.7750 - mae: 190.4636 - val_loss: 9436.1377 - val_mae: 9436.8291\n",
      "Epoch 124/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 194.0383 - mae: 194.7263 - val_loss: 9594.8760 - val_mae: 9595.5703\n",
      "Epoch 125/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 178.4480 - mae: 179.1345 - val_loss: 9634.8857 - val_mae: 9635.5781\n",
      "Epoch 126/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 186.2968 - mae: 186.9852 - val_loss: 9687.2715 - val_mae: 9687.9639\n",
      "Epoch 127/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 188.2307 - mae: 188.9190 - val_loss: 9505.3213 - val_mae: 9506.0137\n",
      "Epoch 128/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 180.3059 - mae: 180.9932 - val_loss: 9539.5615 - val_mae: 9540.2549\n",
      "Epoch 129/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 181.5916 - mae: 182.2799 - val_loss: 9881.7061 - val_mae: 9882.3984\n",
      "Epoch 130/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 177.1720 - mae: 177.8597 - val_loss: 9642.5410 - val_mae: 9643.2354\n",
      "Epoch 131/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 186.8068 - mae: 187.4938 - val_loss: 9559.8320 - val_mae: 9560.5264\n",
      "Epoch 132/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 180.0449 - mae: 180.7312 - val_loss: 9511.7012 - val_mae: 9512.3945\n",
      "Epoch 133/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 191.2218 - mae: 191.9107 - val_loss: 9785.7939 - val_mae: 9786.4863\n",
      "Epoch 134/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 188.4902 - mae: 189.1774 - val_loss: 9433.1221 - val_mae: 9433.8154\n",
      "Epoch 135/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 194.3571 - mae: 195.0454 - val_loss: 9690.8916 - val_mae: 9691.5850\n",
      "Epoch 136/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 183.1446 - mae: 183.8300 - val_loss: 9612.2598 - val_mae: 9612.9531\n",
      "Epoch 137/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 167.4973 - mae: 168.1847 - val_loss: 9641.1094 - val_mae: 9641.8027\n",
      "Epoch 138/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 177.1279 - mae: 177.8163 - val_loss: 9626.5498 - val_mae: 9627.2432\n",
      "Epoch 139/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 181.2210 - mae: 181.9105 - val_loss: 9534.8184 - val_mae: 9535.5098\n",
      "Epoch 140/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 173.3852 - mae: 174.0741 - val_loss: 9478.5732 - val_mae: 9479.2656\n",
      "Epoch 141/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 171.3346 - mae: 172.0209 - val_loss: 9444.8701 - val_mae: 9445.5635\n",
      "Epoch 142/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 169.0971 - mae: 169.7856 - val_loss: 9661.5537 - val_mae: 9662.2471\n",
      "Epoch 143/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 163.2325 - mae: 163.9230 - val_loss: 9344.6113 - val_mae: 9345.3027\n",
      "Epoch 144/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 167.6983 - mae: 168.3879 - val_loss: 9516.5898 - val_mae: 9517.2832\n",
      "Epoch 145/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 158.9341 - mae: 159.6229 - val_loss: 9637.2354 - val_mae: 9637.9287\n",
      "Epoch 146/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 166.0575 - mae: 166.7453 - val_loss: 9526.5098 - val_mae: 9527.2031\n",
      "Epoch 147/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 160.7860 - mae: 161.4709 - val_loss: 9478.6133 - val_mae: 9479.3076\n",
      "Epoch 148/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 162.4992 - mae: 163.1864 - val_loss: 9362.2471 - val_mae: 9362.9404\n",
      "Epoch 149/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 163.5057 - mae: 164.1917 - val_loss: 9423.0586 - val_mae: 9423.7500\n",
      "Epoch 150/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 151.4103 - mae: 152.0978 - val_loss: 9600.7246 - val_mae: 9601.4180\n",
      "Epoch 151/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 150.9936 - mae: 151.6806 - val_loss: 9471.1396 - val_mae: 9471.8330\n",
      "Epoch 152/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 157.7054 - mae: 158.3939 - val_loss: 9410.8652 - val_mae: 9411.5605\n",
      "Epoch 153/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 155.5848 - mae: 156.2735 - val_loss: 9395.4961 - val_mae: 9396.1895\n",
      "Epoch 154/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 163.3452 - mae: 164.0339 - val_loss: 9398.8828 - val_mae: 9399.5771\n",
      "Epoch 155/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 156.4116 - mae: 157.0976 - val_loss: 9347.1504 - val_mae: 9347.8438\n",
      "Epoch 156/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 155.0026 - mae: 155.6893 - val_loss: 9622.1016 - val_mae: 9622.7949\n",
      "Epoch 157/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 149.5626 - mae: 150.2501 - val_loss: 9588.5508 - val_mae: 9589.2461\n",
      "Epoch 158/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 151.1712 - mae: 151.8593 - val_loss: 9305.2197 - val_mae: 9305.9141\n",
      "Epoch 159/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 155.3137 - mae: 155.9984 - val_loss: 9602.6211 - val_mae: 9603.3145\n",
      "Epoch 160/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 166.2640 - mae: 166.9510 - val_loss: 9306.5625 - val_mae: 9307.2559\n",
      "Epoch 161/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 156.2904 - mae: 156.9770 - val_loss: 9105.6885 - val_mae: 9106.3809\n",
      "Epoch 162/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 161.8308 - mae: 162.5183 - val_loss: 9379.3994 - val_mae: 9380.0918\n",
      "Epoch 163/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 153.5622 - mae: 154.2474 - val_loss: 9114.7822 - val_mae: 9115.4746\n",
      "Epoch 164/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 165.1819 - mae: 165.8718 - val_loss: 9221.8770 - val_mae: 9222.5703\n",
      "Epoch 165/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 144.1866 - mae: 144.8745 - val_loss: 9444.3311 - val_mae: 9445.0244\n",
      "Epoch 166/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 145.3739 - mae: 146.0600 - val_loss: 9259.3965 - val_mae: 9260.0908\n",
      "Epoch 167/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 143.8497 - mae: 144.5373 - val_loss: 9441.7861 - val_mae: 9442.4795\n",
      "Epoch 168/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 141.8133 - mae: 142.5008 - val_loss: 9327.8965 - val_mae: 9328.5889\n",
      "Epoch 169/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 149.1137 - mae: 149.8009 - val_loss: 9365.4092 - val_mae: 9366.1016\n",
      "Epoch 170/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 157.1732 - mae: 157.8602 - val_loss: 9278.7070 - val_mae: 9279.3994\n",
      "Epoch 171/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 39ms/step - loss: 143.4708 - mae: 144.1591 - val_loss: 9475.4697 - val_mae: 9476.1641\n",
      "Epoch 172/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 146.4708 - mae: 147.1570 - val_loss: 9270.6494 - val_mae: 9271.3428\n",
      "Epoch 173/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 148.9255 - mae: 149.6096 - val_loss: 9220.2578 - val_mae: 9220.9502\n",
      "Epoch 174/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 155.3364 - mae: 156.0237 - val_loss: 9289.5586 - val_mae: 9290.2510\n",
      "Epoch 175/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 141.5325 - mae: 142.2188 - val_loss: 9449.6729 - val_mae: 9450.3662\n",
      "Epoch 176/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 141.3732 - mae: 142.0574 - val_loss: 9400.7480 - val_mae: 9401.4414\n",
      "Epoch 177/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 136.4855 - mae: 137.1705 - val_loss: 9079.1543 - val_mae: 9079.8496\n",
      "Epoch 178/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 131.3553 - mae: 132.0433 - val_loss: 9329.4570 - val_mae: 9330.1504\n",
      "Epoch 179/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 138.5036 - mae: 139.1918 - val_loss: 9297.3252 - val_mae: 9298.0176\n",
      "Epoch 180/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 142.7442 - mae: 143.4310 - val_loss: 9107.7910 - val_mae: 9108.4844\n",
      "Epoch 181/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 133.8188 - mae: 134.5047 - val_loss: 9185.3594 - val_mae: 9186.0527\n",
      "Epoch 182/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 125.9312 - mae: 126.6153 - val_loss: 9245.3545 - val_mae: 9246.0479\n",
      "Epoch 183/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 137.0822 - mae: 137.7677 - val_loss: 9229.2734 - val_mae: 9229.9668\n",
      "Epoch 184/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 136.5462 - mae: 137.2314 - val_loss: 9274.7168 - val_mae: 9275.4111\n",
      "Epoch 185/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 139.9775 - mae: 140.6655 - val_loss: 9313.5986 - val_mae: 9314.2930\n",
      "Epoch 186/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 140.0265 - mae: 140.7144 - val_loss: 9439.8496 - val_mae: 9440.5430\n",
      "Epoch 187/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 132.7736 - mae: 133.4590 - val_loss: 9087.7578 - val_mae: 9088.4502\n",
      "Epoch 188/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 143.7486 - mae: 144.4351 - val_loss: 9193.0439 - val_mae: 9193.7383\n",
      "Epoch 189/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 146.8842 - mae: 147.5697 - val_loss: 9046.2373 - val_mae: 9046.9307\n",
      "Epoch 190/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 140.9891 - mae: 141.6741 - val_loss: 9453.3164 - val_mae: 9454.0098\n",
      "Epoch 191/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 146.5508 - mae: 147.2349 - val_loss: 9174.7100 - val_mae: 9175.4033\n",
      "Epoch 192/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 137.7166 - mae: 138.4017 - val_loss: 9144.3311 - val_mae: 9145.0244\n",
      "Epoch 193/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 145.3356 - mae: 146.0248 - val_loss: 9392.9473 - val_mae: 9393.6406\n",
      "Epoch 194/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 147.2680 - mae: 147.9564 - val_loss: 9331.8965 - val_mae: 9332.5898\n",
      "Epoch 195/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 133.1597 - mae: 133.8450 - val_loss: 9249.9121 - val_mae: 9250.6055\n",
      "Epoch 196/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 133.5697 - mae: 134.2532 - val_loss: 9298.7656 - val_mae: 9299.4600\n",
      "Epoch 197/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 134.2850 - mae: 134.9727 - val_loss: 9137.1602 - val_mae: 9137.8545\n",
      "Epoch 198/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 130.0367 - mae: 130.7249 - val_loss: 9146.1465 - val_mae: 9146.8389\n",
      "Epoch 199/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 126.6908 - mae: 127.3763 - val_loss: 9144.5391 - val_mae: 9145.2324\n",
      "Epoch 200/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 133.3628 - mae: 134.0487 - val_loss: 9301.3271 - val_mae: 9302.0215\n",
      "Epoch 201/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 127.1173 - mae: 127.8029 - val_loss: 9242.1416 - val_mae: 9242.8350\n",
      "Epoch 202/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 128.3490 - mae: 129.0353 - val_loss: 9190.1582 - val_mae: 9190.8496\n",
      "Epoch 203/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 124.7392 - mae: 125.4268 - val_loss: 9441.8799 - val_mae: 9442.5732\n",
      "Epoch 204/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 136.6041 - mae: 137.2926 - val_loss: 9190.3916 - val_mae: 9191.0850\n",
      "Epoch 205/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 136.5555 - mae: 137.2426 - val_loss: 9134.2275 - val_mae: 9134.9199\n",
      "Epoch 206/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 128.8846 - mae: 129.5726 - val_loss: 9159.4053 - val_mae: 9160.0977\n",
      "Epoch 207/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 121.2833 - mae: 121.9699 - val_loss: 9317.1709 - val_mae: 9317.8652\n",
      "Epoch 208/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 142.0215 - mae: 142.7108 - val_loss: 9418.4141 - val_mae: 9419.1084\n",
      "Epoch 209/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 127.9005 - mae: 128.5881 - val_loss: 9204.7666 - val_mae: 9205.4590\n",
      "Epoch 210/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 125.3241 - mae: 126.0080 - val_loss: 9507.0244 - val_mae: 9507.7178\n",
      "Epoch 211/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 129.2357 - mae: 129.9205 - val_loss: 9204.0859 - val_mae: 9204.7803\n",
      "Epoch 212/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 134.0940 - mae: 134.7798 - val_loss: 9246.3828 - val_mae: 9247.0771\n",
      "Epoch 213/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 124.2334 - mae: 124.9213 - val_loss: 9221.7910 - val_mae: 9222.4834\n",
      "Epoch 214/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 131.5233 - mae: 132.2104 - val_loss: 9330.8057 - val_mae: 9331.4990\n",
      "Epoch 215/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 129.9435 - mae: 130.6273 - val_loss: 9107.1787 - val_mae: 9107.8711\n",
      "Epoch 216/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 135.8387 - mae: 136.5236 - val_loss: 9268.4121 - val_mae: 9269.1035\n",
      "Epoch 217/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 117.6144 - mae: 118.3034 - val_loss: 9165.8789 - val_mae: 9166.5723\n",
      "Epoch 218/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 130.7275 - mae: 131.4158 - val_loss: 9105.3799 - val_mae: 9106.0732\n",
      "Epoch 219/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 120.3057 - mae: 120.9931 - val_loss: 9237.9551 - val_mae: 9238.6484\n",
      "Epoch 220/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 120.9705 - mae: 121.6573 - val_loss: 9106.8516 - val_mae: 9107.5449\n",
      "Epoch 221/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 120.4119 - mae: 121.0971 - val_loss: 9195.1104 - val_mae: 9195.8037\n",
      "Epoch 222/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 120.5036 - mae: 121.1892 - val_loss: 9178.1953 - val_mae: 9178.8887\n",
      "Epoch 223/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 120.8822 - mae: 121.5669 - val_loss: 9288.5645 - val_mae: 9289.2568\n",
      "Epoch 224/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 125.6940 - mae: 126.3819 - val_loss: 9138.3271 - val_mae: 9139.0205\n",
      "Epoch 225/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 125.4992 - mae: 126.1822 - val_loss: 9076.4141 - val_mae: 9077.1084\n",
      "Epoch 226/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 123.3680 - mae: 124.0531 - val_loss: 9273.5557 - val_mae: 9274.2500\n",
      "Epoch 227/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 37ms/step - loss: 117.3982 - mae: 118.0833 - val_loss: 9202.9805 - val_mae: 9203.6738\n",
      "Epoch 228/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 125.1335 - mae: 125.8199 - val_loss: 8987.9033 - val_mae: 8988.5967\n",
      "Epoch 229/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 116.0978 - mae: 116.7858 - val_loss: 9092.6172 - val_mae: 9093.3096\n",
      "Epoch 230/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 124.2226 - mae: 124.9086 - val_loss: 9185.0605 - val_mae: 9185.7539\n",
      "Epoch 231/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 123.3172 - mae: 124.0042 - val_loss: 9226.4170 - val_mae: 9227.1104\n",
      "Epoch 232/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 124.0046 - mae: 124.6924 - val_loss: 8942.5039 - val_mae: 8943.1973\n",
      "Epoch 233/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 120.9621 - mae: 121.6477 - val_loss: 9236.3486 - val_mae: 9237.0420\n",
      "Epoch 234/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 116.9511 - mae: 117.6370 - val_loss: 9075.5127 - val_mae: 9076.2051\n",
      "Epoch 235/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 123.1045 - mae: 123.7907 - val_loss: 9030.5801 - val_mae: 9031.2725\n",
      "Epoch 236/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 122.8900 - mae: 123.5729 - val_loss: 9060.9570 - val_mae: 9061.6504\n",
      "Epoch 237/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 119.7970 - mae: 120.4823 - val_loss: 8877.3779 - val_mae: 8878.0703\n",
      "Epoch 238/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 128.3290 - mae: 129.0118 - val_loss: 9219.1963 - val_mae: 9219.8887\n",
      "Epoch 239/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 112.9212 - mae: 113.6083 - val_loss: 9030.9033 - val_mae: 9031.5957\n",
      "Epoch 240/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 119.9161 - mae: 120.6021 - val_loss: 9127.1182 - val_mae: 9127.8115\n",
      "Epoch 241/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 116.5103 - mae: 117.1954 - val_loss: 8974.6816 - val_mae: 8975.3740\n",
      "Epoch 242/5000\n",
      "46/46 [==============================] - 2s 33ms/step - loss: 121.7650 - mae: 122.4507 - val_loss: 9361.6621 - val_mae: 9362.3545\n",
      "Epoch 243/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 123.2140 - mae: 123.8989 - val_loss: 9183.9766 - val_mae: 9184.6699\n",
      "Epoch 244/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 112.4192 - mae: 113.1053 - val_loss: 9195.3467 - val_mae: 9196.0400\n",
      "Epoch 245/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 115.4008 - mae: 116.0850 - val_loss: 9254.5713 - val_mae: 9255.2637\n",
      "Epoch 246/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 114.6396 - mae: 115.3265 - val_loss: 9244.2490 - val_mae: 9244.9434\n",
      "Epoch 247/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 117.8058 - mae: 118.4909 - val_loss: 9288.6543 - val_mae: 9289.3486\n",
      "Epoch 248/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 107.4530 - mae: 108.1372 - val_loss: 9158.3408 - val_mae: 9159.0342\n",
      "Epoch 249/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 112.7312 - mae: 113.4171 - val_loss: 9185.6777 - val_mae: 9186.3711\n",
      "Epoch 250/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 117.8347 - mae: 118.5201 - val_loss: 9077.1934 - val_mae: 9077.8867\n",
      "Epoch 251/5000\n",
      "46/46 [==============================] - 2s 33ms/step - loss: 111.8738 - mae: 112.5567 - val_loss: 9012.3652 - val_mae: 9013.0596\n",
      "Epoch 252/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 111.0321 - mae: 111.7177 - val_loss: 9028.4443 - val_mae: 9029.1377\n",
      "Epoch 253/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 124.7968 - mae: 125.4823 - val_loss: 9280.7080 - val_mae: 9281.4014\n",
      "Epoch 254/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 119.2872 - mae: 119.9741 - val_loss: 9080.2734 - val_mae: 9080.9668\n",
      "Epoch 255/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 110.8831 - mae: 111.5679 - val_loss: 9235.8271 - val_mae: 9236.5195\n",
      "Epoch 256/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 122.2845 - mae: 122.9720 - val_loss: 9053.4863 - val_mae: 9054.1807\n",
      "Epoch 257/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 125.8191 - mae: 126.5049 - val_loss: 9229.3750 - val_mae: 9230.0674\n",
      "Epoch 258/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 116.4595 - mae: 117.1457 - val_loss: 9133.1895 - val_mae: 9133.8818\n",
      "Epoch 259/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 116.0638 - mae: 116.7490 - val_loss: 8926.5342 - val_mae: 8927.2266\n",
      "Epoch 260/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 113.4977 - mae: 114.1833 - val_loss: 9143.6475 - val_mae: 9144.3408\n",
      "Epoch 261/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 108.1282 - mae: 108.8134 - val_loss: 9054.1611 - val_mae: 9054.8535\n",
      "Epoch 262/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 104.0039 - mae: 104.6870 - val_loss: 9086.9316 - val_mae: 9087.6250\n",
      "Epoch 263/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 111.0978 - mae: 111.7852 - val_loss: 9065.3691 - val_mae: 9066.0635\n",
      "Epoch 264/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 112.3465 - mae: 113.0335 - val_loss: 9057.9961 - val_mae: 9058.6895\n",
      "Epoch 265/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 113.3469 - mae: 114.0313 - val_loss: 9184.8145 - val_mae: 9185.5078\n",
      "Epoch 266/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 108.0206 - mae: 108.7067 - val_loss: 9160.0518 - val_mae: 9160.7451\n",
      "Epoch 267/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 105.1747 - mae: 105.8592 - val_loss: 9415.5947 - val_mae: 9416.2871\n",
      "Epoch 268/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 103.3856 - mae: 104.0672 - val_loss: 8984.1299 - val_mae: 8984.8232\n",
      "Epoch 269/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 112.9820 - mae: 113.6670 - val_loss: 9036.0830 - val_mae: 9036.7764\n",
      "Epoch 270/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 108.3710 - mae: 109.0575 - val_loss: 8973.7031 - val_mae: 8974.3955\n",
      "Epoch 271/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 118.6774 - mae: 119.3640 - val_loss: 9240.9990 - val_mae: 9241.6914\n",
      "Epoch 272/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 117.5430 - mae: 118.2297 - val_loss: 9194.4424 - val_mae: 9195.1367\n",
      "Epoch 273/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 115.9492 - mae: 116.6348 - val_loss: 9283.3701 - val_mae: 9284.0635\n",
      "Epoch 274/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 114.1106 - mae: 114.7952 - val_loss: 8962.4570 - val_mae: 8963.1494\n",
      "Epoch 275/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 111.1088 - mae: 111.7939 - val_loss: 9312.1074 - val_mae: 9312.8008\n",
      "Epoch 276/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 102.7210 - mae: 103.4068 - val_loss: 9154.0791 - val_mae: 9154.7725\n",
      "Epoch 277/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 114.8792 - mae: 115.5648 - val_loss: 9040.5566 - val_mae: 9041.2500\n",
      "Epoch 278/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 106.2464 - mae: 106.9317 - val_loss: 9238.5430 - val_mae: 9239.2363\n",
      "Epoch 279/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 106.0862 - mae: 106.7700 - val_loss: 9298.7979 - val_mae: 9299.4902\n",
      "Epoch 280/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 108.0958 - mae: 108.7808 - val_loss: 9030.1582 - val_mae: 9030.8516\n",
      "Epoch 281/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 112.8726 - mae: 113.5595 - val_loss: 9097.3633 - val_mae: 9098.0576\n",
      "Epoch 282/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 105.8896 - mae: 106.5774 - val_loss: 9203.6445 - val_mae: 9204.3379\n",
      "Epoch 283/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 41ms/step - loss: 105.0236 - mae: 105.7095 - val_loss: 8973.6826 - val_mae: 8974.3750\n",
      "Epoch 284/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 103.5832 - mae: 104.2669 - val_loss: 9026.8750 - val_mae: 9027.5684\n",
      "Epoch 285/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 102.8287 - mae: 103.5135 - val_loss: 9063.1504 - val_mae: 9063.8447\n",
      "Epoch 286/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 107.6147 - mae: 108.2983 - val_loss: 9115.6611 - val_mae: 9116.3545\n",
      "Epoch 287/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 106.7025 - mae: 107.3906 - val_loss: 9135.1260 - val_mae: 9135.8193\n",
      "Epoch 288/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 108.9613 - mae: 109.6464 - val_loss: 9132.9307 - val_mae: 9133.6240\n",
      "Epoch 289/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 104.8743 - mae: 105.5598 - val_loss: 9179.3682 - val_mae: 9180.0596\n",
      "Epoch 290/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 102.0392 - mae: 102.7264 - val_loss: 8963.6729 - val_mae: 8964.3652\n",
      "Epoch 291/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 105.9555 - mae: 106.6383 - val_loss: 8986.3662 - val_mae: 8987.0596\n",
      "Epoch 292/5000\n",
      "46/46 [==============================] - 2s 33ms/step - loss: 101.8647 - mae: 102.5499 - val_loss: 9046.3828 - val_mae: 9047.0752\n",
      "Epoch 293/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 114.1023 - mae: 114.7892 - val_loss: 9103.8105 - val_mae: 9104.5039\n",
      "Epoch 294/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 102.6561 - mae: 103.3403 - val_loss: 8967.2148 - val_mae: 8967.9092\n",
      "Epoch 295/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 108.4438 - mae: 109.1236 - val_loss: 9202.2969 - val_mae: 9202.9902\n",
      "Epoch 296/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 103.6150 - mae: 104.3009 - val_loss: 8924.6533 - val_mae: 8925.3486\n",
      "Epoch 297/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 109.9492 - mae: 110.6318 - val_loss: 9095.3574 - val_mae: 9096.0498\n",
      "Epoch 298/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 100.4913 - mae: 101.1758 - val_loss: 9141.5693 - val_mae: 9142.2617\n",
      "Epoch 299/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 97.2527 - mae: 97.9376 - val_loss: 9264.7344 - val_mae: 9265.4268\n",
      "Epoch 300/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 101.3459 - mae: 102.0262 - val_loss: 9183.0117 - val_mae: 9183.7041\n",
      "Epoch 301/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 100.1135 - mae: 100.8000 - val_loss: 9212.7764 - val_mae: 9213.4688\n",
      "Epoch 302/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 103.7789 - mae: 104.4620 - val_loss: 9289.7344 - val_mae: 9290.4277\n",
      "Epoch 303/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 100.9616 - mae: 101.6444 - val_loss: 9284.3682 - val_mae: 9285.0615\n",
      "Epoch 304/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 100.4156 - mae: 101.0996 - val_loss: 9308.1387 - val_mae: 9308.8311\n",
      "Epoch 305/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 101.4825 - mae: 102.1679 - val_loss: 9094.8438 - val_mae: 9095.5371\n",
      "Epoch 306/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 107.5432 - mae: 108.2282 - val_loss: 9246.1738 - val_mae: 9246.8672\n",
      "Epoch 307/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 103.5834 - mae: 104.2677 - val_loss: 9134.6357 - val_mae: 9135.3281\n",
      "Epoch 308/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 103.2004 - mae: 103.8857 - val_loss: 9350.7500 - val_mae: 9351.4443\n",
      "Epoch 309/5000\n",
      "46/46 [==============================] - 2s 33ms/step - loss: 104.8872 - mae: 105.5726 - val_loss: 9233.0820 - val_mae: 9233.7734\n",
      "Epoch 310/5000\n",
      "46/46 [==============================] - 2s 33ms/step - loss: 104.9937 - mae: 105.6784 - val_loss: 9146.2549 - val_mae: 9146.9482\n",
      "Epoch 311/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 110.8978 - mae: 111.5836 - val_loss: 9072.8672 - val_mae: 9073.5596\n",
      "Epoch 312/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 101.9580 - mae: 102.6428 - val_loss: 9118.8379 - val_mae: 9119.5303\n",
      "Epoch 313/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 101.5975 - mae: 102.2827 - val_loss: 9144.3760 - val_mae: 9145.0693\n",
      "Epoch 314/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 98.2331 - mae: 98.9169 - val_loss: 9098.1230 - val_mae: 9098.8154\n",
      "Epoch 315/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 104.2579 - mae: 104.9445 - val_loss: 9109.2500 - val_mae: 9109.9453\n",
      "Epoch 316/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 103.8859 - mae: 104.5707 - val_loss: 8983.3555 - val_mae: 8984.0479\n",
      "Epoch 317/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 102.7466 - mae: 103.4301 - val_loss: 9282.5088 - val_mae: 9283.2031\n",
      "Epoch 318/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 105.8744 - mae: 106.5571 - val_loss: 9054.0410 - val_mae: 9054.7344\n",
      "Epoch 319/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 108.3468 - mae: 109.0296 - val_loss: 9088.8760 - val_mae: 9089.5684\n",
      "Epoch 320/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 99.9090 - mae: 100.5945 - val_loss: 9147.7930 - val_mae: 9148.4873\n",
      "Epoch 321/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 111.0261 - mae: 111.7128 - val_loss: 9241.6572 - val_mae: 9242.3506\n",
      "Epoch 322/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 108.4890 - mae: 109.1738 - val_loss: 9105.4697 - val_mae: 9106.1611\n",
      "Epoch 323/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 104.8584 - mae: 105.5413 - val_loss: 9167.9492 - val_mae: 9168.6426\n",
      "Epoch 324/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 102.1591 - mae: 102.8407 - val_loss: 9248.0918 - val_mae: 9248.7852\n",
      "Epoch 325/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 100.0664 - mae: 100.7503 - val_loss: 9117.0801 - val_mae: 9117.7725\n",
      "Epoch 326/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 96.9047 - mae: 97.5900 - val_loss: 8864.6689 - val_mae: 8865.3613\n",
      "Epoch 327/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 105.0049 - mae: 105.6914 - val_loss: 9153.4229 - val_mae: 9154.1152\n",
      "Epoch 328/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 99.3752 - mae: 100.0593 - val_loss: 9103.7139 - val_mae: 9104.4062\n",
      "Epoch 329/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 101.3337 - mae: 102.0185 - val_loss: 9153.6699 - val_mae: 9154.3623\n",
      "Epoch 330/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 99.6544 - mae: 100.3381 - val_loss: 9086.2646 - val_mae: 9086.9580\n",
      "Epoch 331/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 90.8836 - mae: 91.5679 - val_loss: 9213.5137 - val_mae: 9214.2070\n",
      "Epoch 332/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 97.7143 - mae: 98.3982 - val_loss: 9233.8545 - val_mae: 9234.5498\n",
      "Epoch 333/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 95.8119 - mae: 96.4976 - val_loss: 9116.1592 - val_mae: 9116.8506\n",
      "Epoch 334/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 105.1601 - mae: 105.8452 - val_loss: 9073.6572 - val_mae: 9074.3506\n",
      "Epoch 335/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 91.8953 - mae: 92.5777 - val_loss: 9048.2617 - val_mae: 9048.9561\n",
      "Epoch 336/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 94.9981 - mae: 95.6826 - val_loss: 9064.1865 - val_mae: 9064.8799\n",
      "Epoch 337/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 97.1023 - mae: 97.7831 - val_loss: 9044.6123 - val_mae: 9045.3047\n",
      "Epoch 338/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 104.3630 - mae: 105.0478 - val_loss: 9149.8564 - val_mae: 9150.5498\n",
      "Epoch 339/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 98.0211 - mae: 98.7063 - val_loss: 9174.6045 - val_mae: 9175.2979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 340/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 96.5130 - mae: 97.1966 - val_loss: 8995.8232 - val_mae: 8996.5166\n",
      "Epoch 341/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 100.3922 - mae: 101.0768 - val_loss: 9199.4307 - val_mae: 9200.1230\n",
      "Epoch 342/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 102.2356 - mae: 102.9208 - val_loss: 9055.5791 - val_mae: 9056.2725\n",
      "Epoch 343/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 95.8187 - mae: 96.5023 - val_loss: 9251.6162 - val_mae: 9252.3086\n",
      "Epoch 344/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 99.4788 - mae: 100.1634 - val_loss: 9213.2979 - val_mae: 9213.9922\n",
      "Epoch 345/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 95.1304 - mae: 95.8130 - val_loss: 9121.9580 - val_mae: 9122.6504\n",
      "Epoch 346/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 104.8933 - mae: 105.5795 - val_loss: 9088.0020 - val_mae: 9088.6953\n",
      "Epoch 347/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 99.6557 - mae: 100.3435 - val_loss: 9126.9023 - val_mae: 9127.5957\n",
      "Epoch 348/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 104.3589 - mae: 105.0434 - val_loss: 8976.1143 - val_mae: 8976.8076\n",
      "Epoch 349/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 95.3917 - mae: 96.0760 - val_loss: 9127.9531 - val_mae: 9128.6465\n",
      "Epoch 350/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 96.4319 - mae: 97.1171 - val_loss: 9077.0459 - val_mae: 9077.7383\n",
      "Epoch 351/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 101.3395 - mae: 102.0243 - val_loss: 8996.5156 - val_mae: 8997.2080\n",
      "Epoch 352/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 98.5458 - mae: 99.2292 - val_loss: 9230.0459 - val_mae: 9230.7383\n",
      "Epoch 353/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 92.6796 - mae: 93.3619 - val_loss: 9195.2148 - val_mae: 9195.9092\n",
      "Epoch 354/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 101.5308 - mae: 102.2165 - val_loss: 9150.6416 - val_mae: 9151.3350\n",
      "Epoch 355/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 93.8108 - mae: 94.4957 - val_loss: 9034.5459 - val_mae: 9035.2383\n",
      "Epoch 356/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 98.6308 - mae: 99.3154 - val_loss: 9076.2002 - val_mae: 9076.8936\n",
      "Epoch 357/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 92.1497 - mae: 92.8320 - val_loss: 9100.1738 - val_mae: 9100.8652\n",
      "Epoch 358/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 100.4986 - mae: 101.1849 - val_loss: 9240.0986 - val_mae: 9240.7920\n",
      "Epoch 359/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 97.5472 - mae: 98.2313 - val_loss: 9151.3496 - val_mae: 9152.0439\n",
      "Epoch 360/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 89.1689 - mae: 89.8542 - val_loss: 9088.4648 - val_mae: 9089.1582\n",
      "Epoch 361/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 93.6204 - mae: 94.3039 - val_loss: 9119.9287 - val_mae: 9120.6221\n",
      "Epoch 362/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 96.9494 - mae: 97.6336 - val_loss: 9180.7568 - val_mae: 9181.4502\n",
      "Epoch 363/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 91.2908 - mae: 91.9753 - val_loss: 9004.5674 - val_mae: 9005.2598\n",
      "Epoch 364/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 94.4881 - mae: 95.1732 - val_loss: 9011.3633 - val_mae: 9012.0576\n",
      "Epoch 365/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 85.4774 - mae: 86.1624 - val_loss: 9091.8320 - val_mae: 9092.5244\n",
      "Epoch 366/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 89.5624 - mae: 90.2481 - val_loss: 9074.8887 - val_mae: 9075.5820\n",
      "Epoch 367/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 93.9069 - mae: 94.5919 - val_loss: 9026.7812 - val_mae: 9027.4746\n",
      "Epoch 368/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 91.4188 - mae: 92.1021 - val_loss: 8962.5693 - val_mae: 8963.2607\n",
      "Epoch 369/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 89.4011 - mae: 90.0859 - val_loss: 8894.3359 - val_mae: 8895.0283\n",
      "Epoch 370/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 91.0913 - mae: 91.7768 - val_loss: 9127.9941 - val_mae: 9128.6885\n",
      "Epoch 371/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 93.7425 - mae: 94.4243 - val_loss: 9072.7988 - val_mae: 9073.4912\n",
      "Epoch 372/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 89.8930 - mae: 90.5734 - val_loss: 9226.3008 - val_mae: 9226.9941\n",
      "Epoch 373/5000\n",
      "46/46 [==============================] - 2s 33ms/step - loss: 98.0062 - mae: 98.6898 - val_loss: 9093.6338 - val_mae: 9094.3271\n",
      "Epoch 374/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 90.4664 - mae: 91.1511 - val_loss: 9051.8613 - val_mae: 9052.5547\n",
      "Epoch 375/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 100.5486 - mae: 101.2331 - val_loss: 9170.7920 - val_mae: 9171.4854\n",
      "Epoch 376/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 96.0417 - mae: 96.7252 - val_loss: 8909.3633 - val_mae: 8910.0566\n",
      "Epoch 377/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 88.4806 - mae: 89.1650 - val_loss: 8905.1465 - val_mae: 8905.8389\n",
      "Epoch 378/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 91.4814 - mae: 92.1658 - val_loss: 9094.4541 - val_mae: 9095.1475\n",
      "Epoch 379/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 88.4926 - mae: 89.1787 - val_loss: 9013.1035 - val_mae: 9013.7959\n",
      "Epoch 380/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 91.8580 - mae: 92.5398 - val_loss: 9070.4609 - val_mae: 9071.1543\n",
      "Epoch 381/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 95.0904 - mae: 95.7754 - val_loss: 9089.0303 - val_mae: 9089.7236\n",
      "Epoch 382/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 98.5282 - mae: 99.2111 - val_loss: 9098.3994 - val_mae: 9099.0928\n",
      "Epoch 383/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 90.3474 - mae: 91.0327 - val_loss: 9213.2383 - val_mae: 9213.9307\n",
      "Epoch 384/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 92.3087 - mae: 92.9926 - val_loss: 9095.7236 - val_mae: 9096.4150\n",
      "Epoch 385/5000\n",
      "46/46 [==============================] - 2s 33ms/step - loss: 95.1163 - mae: 95.8017 - val_loss: 9009.2158 - val_mae: 9009.9092\n",
      "Epoch 386/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 94.3695 - mae: 95.0498 - val_loss: 8994.4717 - val_mae: 8995.1650\n",
      "Epoch 387/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 90.0860 - mae: 90.7711 - val_loss: 9018.1338 - val_mae: 9018.8281\n",
      "Epoch 388/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 85.1434 - mae: 85.8286 - val_loss: 8987.0693 - val_mae: 8987.7617\n",
      "Epoch 389/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 89.0690 - mae: 89.7500 - val_loss: 8976.1846 - val_mae: 8976.8770\n",
      "Epoch 390/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 90.9388 - mae: 91.6215 - val_loss: 9158.5391 - val_mae: 9159.2324\n",
      "Epoch 391/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 91.6630 - mae: 92.3454 - val_loss: 9118.5977 - val_mae: 9119.2891\n",
      "Epoch 392/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 101.0406 - mae: 101.7248 - val_loss: 8906.8076 - val_mae: 8907.5000\n",
      "Epoch 393/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 89.4698 - mae: 90.1521 - val_loss: 9158.5820 - val_mae: 9159.2744\n",
      "Epoch 394/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 88.2116 - mae: 88.8932 - val_loss: 8984.7354 - val_mae: 8985.4297\n",
      "Epoch 395/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 96.7950 - mae: 97.4779 - val_loss: 9231.7109 - val_mae: 9232.4043\n",
      "Epoch 396/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 97.2188 - mae: 97.9012 - val_loss: 9094.5527 - val_mae: 9095.2471\n",
      "Epoch 397/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 40ms/step - loss: 94.9661 - mae: 95.6475 - val_loss: 9121.8555 - val_mae: 9122.5498\n",
      "Epoch 398/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 97.2529 - mae: 97.9395 - val_loss: 9025.5508 - val_mae: 9026.2441\n",
      "Epoch 399/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 91.2062 - mae: 91.8901 - val_loss: 9096.3760 - val_mae: 9097.0674\n",
      "Epoch 400/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 85.2413 - mae: 85.9253 - val_loss: 9117.8613 - val_mae: 9118.5557\n",
      "Epoch 401/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 94.0473 - mae: 94.7325 - val_loss: 9069.7725 - val_mae: 9070.4648\n",
      "Epoch 402/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 99.4139 - mae: 100.0976 - val_loss: 9219.1201 - val_mae: 9219.8125\n",
      "Epoch 403/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 99.1010 - mae: 99.7849 - val_loss: 9094.5625 - val_mae: 9095.2559\n",
      "Epoch 404/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 87.9589 - mae: 88.6417 - val_loss: 9110.3350 - val_mae: 9111.0273\n",
      "Epoch 405/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 91.8254 - mae: 92.5083 - val_loss: 9157.5508 - val_mae: 9158.2461\n",
      "Epoch 406/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 92.8177 - mae: 93.4998 - val_loss: 8952.8994 - val_mae: 8953.5928\n",
      "Epoch 407/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 90.7286 - mae: 91.4112 - val_loss: 9101.9502 - val_mae: 9102.6445\n",
      "Epoch 408/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 87.1270 - mae: 87.8113 - val_loss: 9034.2500 - val_mae: 9034.9443\n",
      "Epoch 409/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 88.8524 - mae: 89.5340 - val_loss: 8971.3809 - val_mae: 8972.0742\n",
      "Epoch 410/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 81.1372 - mae: 81.8215 - val_loss: 9019.3086 - val_mae: 9020.0010\n",
      "Epoch 411/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 84.4023 - mae: 85.0880 - val_loss: 9023.4590 - val_mae: 9024.1504\n",
      "Epoch 412/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 99.3111 - mae: 99.9945 - val_loss: 9114.7314 - val_mae: 9115.4238\n",
      "Epoch 413/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 97.0618 - mae: 97.7475 - val_loss: 9048.7803 - val_mae: 9049.4727\n",
      "Epoch 414/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 86.9392 - mae: 87.6248 - val_loss: 9179.6348 - val_mae: 9180.3281\n",
      "Epoch 415/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 89.9336 - mae: 90.6155 - val_loss: 8949.3730 - val_mae: 8950.0674\n",
      "Epoch 416/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 86.6115 - mae: 87.2941 - val_loss: 8905.3887 - val_mae: 8906.0811\n",
      "Epoch 417/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 87.7012 - mae: 88.3871 - val_loss: 8915.2520 - val_mae: 8915.9463\n",
      "Epoch 418/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 84.9978 - mae: 85.6843 - val_loss: 9036.9805 - val_mae: 9037.6748\n",
      "Epoch 419/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 94.1855 - mae: 94.8697 - val_loss: 9000.2266 - val_mae: 9000.9199\n",
      "Epoch 420/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 84.6279 - mae: 85.3103 - val_loss: 9141.6133 - val_mae: 9142.3047\n",
      "Epoch 421/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 86.9754 - mae: 87.6574 - val_loss: 9027.0566 - val_mae: 9027.7500\n",
      "Epoch 422/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 91.2772 - mae: 91.9609 - val_loss: 8787.2891 - val_mae: 8787.9824\n",
      "Epoch 423/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 94.5081 - mae: 95.1906 - val_loss: 8945.2275 - val_mae: 8945.9209\n",
      "Epoch 424/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 93.3907 - mae: 94.0732 - val_loss: 8956.0449 - val_mae: 8956.7363\n",
      "Epoch 425/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 80.7375 - mae: 81.4223 - val_loss: 8828.7080 - val_mae: 8829.4014\n",
      "Epoch 426/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 90.1203 - mae: 90.8018 - val_loss: 9024.7979 - val_mae: 9025.4912\n",
      "Epoch 427/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 89.9154 - mae: 90.5984 - val_loss: 8863.4209 - val_mae: 8864.1143\n",
      "Epoch 428/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 84.2082 - mae: 84.8900 - val_loss: 9085.8623 - val_mae: 9086.5557\n",
      "Epoch 429/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 81.4790 - mae: 82.1586 - val_loss: 8988.6084 - val_mae: 8989.3008\n",
      "Epoch 430/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 80.8827 - mae: 81.5641 - val_loss: 8955.3936 - val_mae: 8956.0859\n",
      "Epoch 431/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 80.8974 - mae: 81.5792 - val_loss: 9147.8262 - val_mae: 9148.5205\n",
      "Epoch 432/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 86.3981 - mae: 87.0806 - val_loss: 9034.1416 - val_mae: 9034.8350\n",
      "Epoch 433/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 84.8919 - mae: 85.5779 - val_loss: 9046.9248 - val_mae: 9047.6182\n",
      "Epoch 434/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 86.7166 - mae: 87.3988 - val_loss: 8850.1016 - val_mae: 8850.7949\n",
      "Epoch 435/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 88.7067 - mae: 89.3928 - val_loss: 8870.5518 - val_mae: 8871.2451\n",
      "Epoch 436/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 87.0850 - mae: 87.7685 - val_loss: 8892.3652 - val_mae: 8893.0586\n",
      "Epoch 437/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 86.7923 - mae: 87.4731 - val_loss: 8997.9102 - val_mae: 8998.6045\n",
      "Epoch 438/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 88.8795 - mae: 89.5624 - val_loss: 8874.3623 - val_mae: 8875.0547\n",
      "Epoch 439/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 86.9003 - mae: 87.5809 - val_loss: 9016.1650 - val_mae: 9016.8574\n",
      "Epoch 440/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 86.3987 - mae: 87.0786 - val_loss: 8966.2129 - val_mae: 8966.9072\n",
      "Epoch 441/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 91.6668 - mae: 92.3472 - val_loss: 9081.7109 - val_mae: 9082.4053\n",
      "Epoch 442/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 84.5363 - mae: 85.2193 - val_loss: 8986.5605 - val_mae: 8987.2539\n",
      "Epoch 443/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 84.7483 - mae: 85.4328 - val_loss: 9087.7422 - val_mae: 9088.4336\n",
      "Epoch 444/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 80.0767 - mae: 80.7589 - val_loss: 8769.6924 - val_mae: 8770.3848\n",
      "Epoch 445/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 82.6163 - mae: 83.2955 - val_loss: 8743.9727 - val_mae: 8744.6641\n",
      "Epoch 446/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 86.9071 - mae: 87.5870 - val_loss: 8632.2119 - val_mae: 8632.9043\n",
      "Epoch 447/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 79.6332 - mae: 80.3161 - val_loss: 8896.2676 - val_mae: 8896.9600\n",
      "Epoch 448/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 82.6887 - mae: 83.3707 - val_loss: 8819.9043 - val_mae: 8820.5977\n",
      "Epoch 449/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 86.6478 - mae: 87.3291 - val_loss: 8819.8359 - val_mae: 8820.5283\n",
      "Epoch 450/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 81.8252 - mae: 82.5078 - val_loss: 8873.7627 - val_mae: 8874.4561\n",
      "Epoch 451/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 79.4207 - mae: 80.1062 - val_loss: 9091.4297 - val_mae: 9092.1230\n",
      "Epoch 452/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 89.5630 - mae: 90.2469 - val_loss: 9010.5654 - val_mae: 9011.2588\n",
      "Epoch 453/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 84.2477 - mae: 84.9285 - val_loss: 9073.5352 - val_mae: 9074.2285\n",
      "Epoch 454/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 39ms/step - loss: 80.8788 - mae: 81.5624 - val_loss: 9212.1777 - val_mae: 9212.8711\n",
      "Epoch 455/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 82.0221 - mae: 82.7034 - val_loss: 8995.4980 - val_mae: 8996.1904\n",
      "Epoch 456/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 82.8868 - mae: 83.5671 - val_loss: 8943.5039 - val_mae: 8944.1963\n",
      "Epoch 457/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 88.3188 - mae: 89.0034 - val_loss: 9093.0186 - val_mae: 9093.7119\n",
      "Epoch 458/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 84.7278 - mae: 85.4123 - val_loss: 9076.7695 - val_mae: 9077.4629\n",
      "Epoch 459/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 85.3819 - mae: 86.0662 - val_loss: 8925.9131 - val_mae: 8926.6064\n",
      "Epoch 460/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 82.9706 - mae: 83.6513 - val_loss: 9086.2383 - val_mae: 9086.9326\n",
      "Epoch 461/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 85.6127 - mae: 86.2971 - val_loss: 9018.0566 - val_mae: 9018.7490\n",
      "Epoch 462/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 79.9399 - mae: 80.6234 - val_loss: 9061.2803 - val_mae: 9061.9746\n",
      "Epoch 463/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 78.5749 - mae: 79.2607 - val_loss: 9044.9580 - val_mae: 9045.6514\n",
      "Epoch 464/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 86.9636 - mae: 87.6467 - val_loss: 8913.5557 - val_mae: 8914.2500\n",
      "Epoch 465/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 81.9182 - mae: 82.5990 - val_loss: 8944.3906 - val_mae: 8945.0820\n",
      "Epoch 466/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 89.2345 - mae: 89.9185 - val_loss: 9082.2334 - val_mae: 9082.9277\n",
      "Epoch 467/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 87.6966 - mae: 88.3825 - val_loss: 8986.6914 - val_mae: 8987.3867\n",
      "Epoch 468/5000\n",
      "46/46 [==============================] - 3s 58ms/step - loss: 80.9626 - mae: 81.6463 - val_loss: 8920.3594 - val_mae: 8921.0537\n",
      "Epoch 469/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 81.6272 - mae: 82.3108 - val_loss: 8979.7549 - val_mae: 8980.4502\n",
      "Epoch 470/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 92.0381 - mae: 92.7236 - val_loss: 8927.6816 - val_mae: 8928.3750\n",
      "Epoch 471/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 91.7229 - mae: 92.4071 - val_loss: 9126.6523 - val_mae: 9127.3477\n",
      "Epoch 472/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 88.9809 - mae: 89.6631 - val_loss: 9030.9014 - val_mae: 9031.5947\n",
      "Epoch 473/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 83.8904 - mae: 84.5732 - val_loss: 8923.3662 - val_mae: 8924.0596\n",
      "Epoch 474/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 87.4887 - mae: 88.1729 - val_loss: 8956.0312 - val_mae: 8956.7246\n",
      "Epoch 475/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 81.9696 - mae: 82.6549 - val_loss: 8988.6533 - val_mae: 8989.3467\n",
      "Epoch 476/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 79.5802 - mae: 80.2623 - val_loss: 8902.0176 - val_mae: 8902.7109\n",
      "Epoch 477/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 84.8470 - mae: 85.5314 - val_loss: 9011.1338 - val_mae: 9011.8271\n",
      "Epoch 478/5000\n",
      "46/46 [==============================] - 1s 31ms/step - loss: 79.4587 - mae: 80.1461 - val_loss: 8942.0938 - val_mae: 8942.7852\n",
      "Epoch 479/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 81.9639 - mae: 82.6502 - val_loss: 8901.7920 - val_mae: 8902.4854\n",
      "Epoch 480/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 84.4998 - mae: 85.1842 - val_loss: 8941.9814 - val_mae: 8942.6738\n",
      "Epoch 481/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 74.0764 - mae: 74.7593 - val_loss: 8806.9512 - val_mae: 8807.6445\n",
      "Epoch 482/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 89.6843 - mae: 90.3685 - val_loss: 8817.3359 - val_mae: 8818.0293\n",
      "Epoch 483/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 81.2326 - mae: 81.9163 - val_loss: 8868.2256 - val_mae: 8868.9180\n",
      "Epoch 484/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 84.8258 - mae: 85.5104 - val_loss: 8888.8154 - val_mae: 8889.5078\n",
      "Epoch 485/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 77.4049 - mae: 78.0830 - val_loss: 8888.5088 - val_mae: 8889.2031\n",
      "Epoch 486/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 79.3975 - mae: 80.0824 - val_loss: 8803.2480 - val_mae: 8803.9414\n",
      "Epoch 487/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 78.7837 - mae: 79.4651 - val_loss: 8902.8701 - val_mae: 8903.5625\n",
      "Epoch 488/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 78.1440 - mae: 78.8266 - val_loss: 8874.2988 - val_mae: 8874.9941\n",
      "Epoch 489/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 77.0554 - mae: 77.7369 - val_loss: 8974.2715 - val_mae: 8974.9648\n",
      "Epoch 490/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 78.8510 - mae: 79.5325 - val_loss: 8877.6309 - val_mae: 8878.3242\n",
      "Epoch 491/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 80.7723 - mae: 81.4541 - val_loss: 8967.4414 - val_mae: 8968.1348\n",
      "Epoch 492/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 80.2645 - mae: 80.9489 - val_loss: 9029.7344 - val_mae: 9030.4277\n",
      "Epoch 493/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 80.5220 - mae: 81.2049 - val_loss: 8993.7764 - val_mae: 8994.4688\n",
      "Epoch 494/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 79.2983 - mae: 79.9792 - val_loss: 8904.2871 - val_mae: 8904.9795\n",
      "Epoch 495/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 89.7848 - mae: 90.4664 - val_loss: 8868.2432 - val_mae: 8868.9365\n",
      "Epoch 496/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 83.6881 - mae: 84.3721 - val_loss: 8943.9590 - val_mae: 8944.6523\n",
      "Epoch 497/5000\n",
      "46/46 [==============================] - 2s 33ms/step - loss: 82.1059 - mae: 82.7878 - val_loss: 8971.0830 - val_mae: 8971.7764\n",
      "Epoch 498/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 77.4832 - mae: 78.1638 - val_loss: 8929.8047 - val_mae: 8930.4980\n",
      "Epoch 499/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 78.6315 - mae: 79.3122 - val_loss: 8889.8203 - val_mae: 8890.5137\n",
      "Epoch 500/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 76.5066 - mae: 77.1865 - val_loss: 8958.1826 - val_mae: 8958.8760\n",
      "Epoch 501/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 77.0009 - mae: 77.6855 - val_loss: 9022.8984 - val_mae: 9023.5908\n",
      "Epoch 502/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 81.3578 - mae: 82.0422 - val_loss: 8957.1074 - val_mae: 8957.8018\n",
      "Epoch 503/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 81.3273 - mae: 82.0077 - val_loss: 9079.0439 - val_mae: 9079.7363\n",
      "Epoch 504/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 78.4806 - mae: 79.1619 - val_loss: 8839.5557 - val_mae: 8840.2500\n",
      "Epoch 505/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 81.4898 - mae: 82.1730 - val_loss: 8979.5879 - val_mae: 8980.2812\n",
      "Epoch 506/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 75.3789 - mae: 76.0587 - val_loss: 9088.9268 - val_mae: 9089.6191\n",
      "Epoch 507/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 83.7569 - mae: 84.4373 - val_loss: 8994.3623 - val_mae: 8995.0537\n",
      "Epoch 508/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 80.1639 - mae: 80.8461 - val_loss: 9167.2031 - val_mae: 9167.8965\n",
      "Epoch 509/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 87.7751 - mae: 88.4581 - val_loss: 8988.9990 - val_mae: 8989.6934\n",
      "Epoch 510/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 74.5853 - mae: 75.2694 - val_loss: 8912.3125 - val_mae: 8913.0068\n",
      "Epoch 511/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 39ms/step - loss: 76.7209 - mae: 77.4031 - val_loss: 8997.9365 - val_mae: 8998.6289\n",
      "Epoch 512/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 79.4598 - mae: 80.1420 - val_loss: 9019.6865 - val_mae: 9020.3799\n",
      "Epoch 513/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 78.7575 - mae: 79.4404 - val_loss: 8874.3027 - val_mae: 8874.9951\n",
      "Epoch 514/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 78.2857 - mae: 78.9702 - val_loss: 9015.1494 - val_mae: 9015.8418\n",
      "Epoch 515/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 74.6112 - mae: 75.2913 - val_loss: 9073.6787 - val_mae: 9074.3721\n",
      "Epoch 516/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 74.8911 - mae: 75.5730 - val_loss: 9098.1094 - val_mae: 9098.8027\n",
      "Epoch 517/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 77.4988 - mae: 78.1790 - val_loss: 8928.5342 - val_mae: 8929.2275\n",
      "Epoch 518/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 80.3883 - mae: 81.0700 - val_loss: 8984.2480 - val_mae: 8984.9414\n",
      "Epoch 519/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 74.5215 - mae: 75.2024 - val_loss: 8897.5361 - val_mae: 8898.2295\n",
      "Epoch 520/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 79.5559 - mae: 80.2359 - val_loss: 8882.7334 - val_mae: 8883.4258\n",
      "Epoch 521/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 79.7260 - mae: 80.4068 - val_loss: 9029.9443 - val_mae: 9030.6377\n",
      "Epoch 522/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 70.5129 - mae: 71.1948 - val_loss: 8987.8906 - val_mae: 8988.5840\n",
      "Epoch 523/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 80.8737 - mae: 81.5585 - val_loss: 9012.6904 - val_mae: 9013.3838\n",
      "Epoch 524/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 77.9766 - mae: 78.6599 - val_loss: 8960.9785 - val_mae: 8961.6729\n",
      "Epoch 525/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 72.0826 - mae: 72.7672 - val_loss: 8987.7129 - val_mae: 8988.4062\n",
      "Epoch 526/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 77.0840 - mae: 77.7665 - val_loss: 9070.5342 - val_mae: 9071.2285\n",
      "Epoch 527/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 76.2228 - mae: 76.9037 - val_loss: 9100.4404 - val_mae: 9101.1318\n",
      "Epoch 528/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 78.2337 - mae: 78.9192 - val_loss: 9033.0518 - val_mae: 9033.7461\n",
      "Epoch 529/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 73.4481 - mae: 74.1282 - val_loss: 8970.1924 - val_mae: 8970.8857\n",
      "Epoch 530/5000\n",
      "46/46 [==============================] - 3s 62ms/step - loss: 76.2741 - mae: 76.9560 - val_loss: 8979.0332 - val_mae: 8979.7275\n",
      "Epoch 531/5000\n",
      "46/46 [==============================] - 3s 72ms/step - loss: 71.4597 - mae: 72.1375 - val_loss: 8927.3945 - val_mae: 8928.0879\n",
      "Epoch 532/5000\n",
      "46/46 [==============================] - 3s 75ms/step - loss: 85.3002 - mae: 85.9824 - val_loss: 9048.9961 - val_mae: 9049.6895\n",
      "Epoch 533/5000\n",
      "46/46 [==============================] - 3s 76ms/step - loss: 81.1525 - mae: 81.8318 - val_loss: 9062.0996 - val_mae: 9062.7920\n",
      "Epoch 534/5000\n",
      "46/46 [==============================] - 4s 77ms/step - loss: 71.7989 - mae: 72.4798 - val_loss: 8997.7305 - val_mae: 8998.4229\n",
      "Epoch 535/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 73.5341 - mae: 74.2143 - val_loss: 9091.8906 - val_mae: 9092.5840\n",
      "Epoch 536/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 73.9389 - mae: 74.6181 - val_loss: 9127.5830 - val_mae: 9128.2754\n",
      "Epoch 537/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 77.8725 - mae: 78.5547 - val_loss: 8954.6475 - val_mae: 8955.3389\n",
      "Epoch 538/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 82.2199 - mae: 82.9014 - val_loss: 8971.2246 - val_mae: 8971.9180\n",
      "Epoch 539/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 73.7862 - mae: 74.4655 - val_loss: 9024.9785 - val_mae: 9025.6709\n",
      "Epoch 540/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 72.0971 - mae: 72.7777 - val_loss: 8970.2061 - val_mae: 8970.8994\n",
      "Epoch 541/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 75.7769 - mae: 76.4608 - val_loss: 8986.4619 - val_mae: 8987.1553\n",
      "Epoch 542/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 77.7909 - mae: 78.4733 - val_loss: 8943.0547 - val_mae: 8943.7490\n",
      "Epoch 543/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 74.7517 - mae: 75.4323 - val_loss: 8971.0713 - val_mae: 8971.7637\n",
      "Epoch 544/5000\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 72.7151 - mae: 73.3968 - val_loss: 8983.4541 - val_mae: 8984.1484\n",
      "Epoch 545/5000\n",
      "46/46 [==============================] - 3s 71ms/step - loss: 75.6690 - mae: 76.3513 - val_loss: 8923.1494 - val_mae: 8923.8438\n",
      "Epoch 546/5000\n",
      "46/46 [==============================] - 3s 62ms/step - loss: 69.9744 - mae: 70.6545 - val_loss: 8942.8066 - val_mae: 8943.5000\n",
      "Epoch 547/5000\n",
      "46/46 [==============================] - 3s 75ms/step - loss: 73.0993 - mae: 73.7810 - val_loss: 8954.4561 - val_mae: 8955.1504\n",
      "Epoch 548/5000\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 75.2197 - mae: 75.9002 - val_loss: 9046.0537 - val_mae: 9046.7490\n",
      "Epoch 549/5000\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 79.6627 - mae: 80.3452 - val_loss: 9115.0273 - val_mae: 9115.7217\n",
      "Epoch 550/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 77.3563 - mae: 78.0403 - val_loss: 8965.4893 - val_mae: 8966.1826\n",
      "Epoch 551/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 78.7103 - mae: 79.3917 - val_loss: 8941.0488 - val_mae: 8941.7432\n",
      "Epoch 552/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 82.6157 - mae: 83.2981 - val_loss: 8834.2930 - val_mae: 8834.9863\n",
      "Epoch 553/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 69.4852 - mae: 70.1644 - val_loss: 8885.1006 - val_mae: 8885.7930\n",
      "Epoch 554/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 74.3884 - mae: 75.0703 - val_loss: 8964.3066 - val_mae: 8964.9990\n",
      "Epoch 555/5000\n",
      "46/46 [==============================] - 3s 59ms/step - loss: 78.3970 - mae: 79.0788 - val_loss: 8915.9785 - val_mae: 8916.6719\n",
      "Epoch 556/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 73.9925 - mae: 74.6765 - val_loss: 8931.3779 - val_mae: 8932.0713\n",
      "Epoch 557/5000\n",
      "46/46 [==============================] - 3s 59ms/step - loss: 73.3939 - mae: 74.0744 - val_loss: 9031.2168 - val_mae: 9031.9102\n",
      "Epoch 558/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 72.0604 - mae: 72.7419 - val_loss: 8973.3281 - val_mae: 8974.0215\n",
      "Epoch 559/5000\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 72.9415 - mae: 73.6222 - val_loss: 8826.0723 - val_mae: 8826.7646\n",
      "Epoch 560/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 77.3107 - mae: 77.9904 - val_loss: 9012.7773 - val_mae: 9013.4697\n",
      "Epoch 561/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 72.8643 - mae: 73.5481 - val_loss: 8935.1270 - val_mae: 8935.8213\n",
      "Epoch 562/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 78.2210 - mae: 78.9048 - val_loss: 8952.9854 - val_mae: 8953.6787\n",
      "Epoch 563/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 75.1636 - mae: 75.8457 - val_loss: 8917.9629 - val_mae: 8918.6562\n",
      "Epoch 564/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 73.6841 - mae: 74.3671 - val_loss: 8886.6318 - val_mae: 8887.3262\n",
      "Epoch 565/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 81.2178 - mae: 81.8966 - val_loss: 8886.4199 - val_mae: 8887.1113\n",
      "Epoch 566/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 77.4849 - mae: 78.1663 - val_loss: 9001.5078 - val_mae: 9002.2002\n",
      "Epoch 567/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 91.7382 - mae: 92.4191 - val_loss: 9044.1592 - val_mae: 9044.8525\n",
      "Epoch 568/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 52ms/step - loss: 82.8026 - mae: 83.4858 - val_loss: 8869.9268 - val_mae: 8870.6191\n",
      "Epoch 569/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 77.9620 - mae: 78.6426 - val_loss: 8943.5098 - val_mae: 8944.2012\n",
      "Epoch 570/5000\n",
      "46/46 [==============================] - 3s 54ms/step - loss: 73.2167 - mae: 73.8965 - val_loss: 8958.0605 - val_mae: 8958.7529\n",
      "Epoch 571/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 78.4032 - mae: 79.0887 - val_loss: 8915.8496 - val_mae: 8916.5430\n",
      "Epoch 572/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 79.8994 - mae: 80.5796 - val_loss: 9179.6016 - val_mae: 9180.2939\n",
      "Epoch 573/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 77.2684 - mae: 77.9456 - val_loss: 8945.4775 - val_mae: 8946.1719\n",
      "Epoch 574/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 78.2203 - mae: 78.9039 - val_loss: 8899.2031 - val_mae: 8899.8965\n",
      "Epoch 575/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 77.8505 - mae: 78.5289 - val_loss: 9000.1035 - val_mae: 9000.7969\n",
      "Epoch 576/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 73.6837 - mae: 74.3640 - val_loss: 8977.2812 - val_mae: 8977.9746\n",
      "Epoch 577/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 76.5786 - mae: 77.2582 - val_loss: 8968.1250 - val_mae: 8968.8174\n",
      "Epoch 578/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 73.3462 - mae: 74.0280 - val_loss: 9000.8145 - val_mae: 9001.5078\n",
      "Epoch 579/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 74.0184 - mae: 74.6972 - val_loss: 9078.2959 - val_mae: 9078.9893\n",
      "Epoch 580/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 74.6557 - mae: 75.3370 - val_loss: 8938.4092 - val_mae: 8939.1025\n",
      "Epoch 581/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 75.9808 - mae: 76.6636 - val_loss: 8826.6494 - val_mae: 8827.3418\n",
      "Epoch 582/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 71.1371 - mae: 71.8167 - val_loss: 8928.5859 - val_mae: 8929.2793\n",
      "Epoch 583/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 75.2648 - mae: 75.9470 - val_loss: 8891.1035 - val_mae: 8891.7979\n",
      "Epoch 584/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 73.3652 - mae: 74.0458 - val_loss: 8945.1006 - val_mae: 8945.7939\n",
      "Epoch 585/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 72.8751 - mae: 73.5557 - val_loss: 8911.9082 - val_mae: 8912.6006\n",
      "Epoch 586/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 67.2443 - mae: 67.9296 - val_loss: 8884.5410 - val_mae: 8885.2324\n",
      "Epoch 587/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 71.4883 - mae: 72.1718 - val_loss: 8948.2979 - val_mae: 8948.9902\n",
      "Epoch 588/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 66.6997 - mae: 67.3788 - val_loss: 8845.7188 - val_mae: 8846.4121\n",
      "Epoch 589/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 71.0402 - mae: 71.7201 - val_loss: 8897.4473 - val_mae: 8898.1406\n",
      "Epoch 590/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 68.0253 - mae: 68.7100 - val_loss: 8874.2383 - val_mae: 8874.9316\n",
      "Epoch 591/5000\n",
      "46/46 [==============================] - 3s 61ms/step - loss: 74.0614 - mae: 74.7436 - val_loss: 8818.0879 - val_mae: 8818.7803\n",
      "Epoch 592/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 77.5596 - mae: 78.2464 - val_loss: 8852.1445 - val_mae: 8852.8350\n",
      "Epoch 593/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 69.6498 - mae: 70.3303 - val_loss: 8782.6318 - val_mae: 8783.3242\n",
      "Epoch 594/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 74.5611 - mae: 75.2426 - val_loss: 8903.8457 - val_mae: 8904.5391\n",
      "Epoch 595/5000\n",
      "46/46 [==============================] - 2s 55ms/step - loss: 69.9451 - mae: 70.6225 - val_loss: 8976.2656 - val_mae: 8976.9580\n",
      "Epoch 596/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 69.5914 - mae: 70.2736 - val_loss: 8988.3047 - val_mae: 8988.9990\n",
      "Epoch 597/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 73.0227 - mae: 73.7057 - val_loss: 8907.3037 - val_mae: 8907.9961\n",
      "Epoch 598/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 74.6434 - mae: 75.3248 - val_loss: 8939.3213 - val_mae: 8940.0146\n",
      "Epoch 599/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 71.8728 - mae: 72.5498 - val_loss: 8818.0703 - val_mae: 8818.7617\n",
      "Epoch 600/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 70.6167 - mae: 71.2969 - val_loss: 8954.5752 - val_mae: 8955.2676\n",
      "Epoch 601/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 69.3766 - mae: 70.0587 - val_loss: 8891.9209 - val_mae: 8892.6143\n",
      "Epoch 602/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 67.4791 - mae: 68.1582 - val_loss: 8835.5000 - val_mae: 8836.1934\n",
      "Epoch 603/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 69.3540 - mae: 70.0310 - val_loss: 9006.0879 - val_mae: 9006.7803\n",
      "Epoch 604/5000\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 69.1847 - mae: 69.8673 - val_loss: 8981.1309 - val_mae: 8981.8232\n",
      "Epoch 605/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 70.1291 - mae: 70.8083 - val_loss: 8940.5645 - val_mae: 8941.2559\n",
      "Epoch 606/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 75.4388 - mae: 76.1200 - val_loss: 8993.6914 - val_mae: 8994.3838\n",
      "Epoch 607/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 72.3770 - mae: 73.0546 - val_loss: 8975.8604 - val_mae: 8976.5527\n",
      "Epoch 608/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 69.4406 - mae: 70.1210 - val_loss: 8898.1777 - val_mae: 8898.8711\n",
      "Epoch 609/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 70.9281 - mae: 71.6108 - val_loss: 8909.1133 - val_mae: 8909.8047\n",
      "Epoch 610/5000\n",
      "46/46 [==============================] - 3s 62ms/step - loss: 70.2969 - mae: 70.9799 - val_loss: 8915.3984 - val_mae: 8916.0908\n",
      "Epoch 611/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 64.8318 - mae: 65.5149 - val_loss: 8906.6836 - val_mae: 8907.3760\n",
      "Epoch 612/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 69.9794 - mae: 70.6629 - val_loss: 8878.2822 - val_mae: 8878.9756\n",
      "Epoch 613/5000\n",
      "46/46 [==============================] - 3s 58ms/step - loss: 76.0759 - mae: 76.7554 - val_loss: 8844.8496 - val_mae: 8845.5430\n",
      "Epoch 614/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 70.6000 - mae: 71.2802 - val_loss: 8839.4902 - val_mae: 8840.1836\n",
      "Epoch 615/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 67.8069 - mae: 68.4902 - val_loss: 8913.5107 - val_mae: 8914.2041\n",
      "Epoch 616/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 69.6674 - mae: 70.3484 - val_loss: 9008.6631 - val_mae: 9009.3564\n",
      "Epoch 617/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 70.5042 - mae: 71.1859 - val_loss: 8984.4355 - val_mae: 8985.1299\n",
      "Epoch 618/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 69.0547 - mae: 69.7350 - val_loss: 8878.4316 - val_mae: 8879.1250\n",
      "Epoch 619/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 64.4572 - mae: 65.1379 - val_loss: 8942.2314 - val_mae: 8942.9248\n",
      "Epoch 620/5000\n",
      "46/46 [==============================] - 3s 59ms/step - loss: 66.7667 - mae: 67.4481 - val_loss: 8982.3682 - val_mae: 8983.0625\n",
      "Epoch 621/5000\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 69.2383 - mae: 69.9209 - val_loss: 9034.1143 - val_mae: 9034.8066\n",
      "Epoch 622/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 66.7044 - mae: 67.3885 - val_loss: 8859.1191 - val_mae: 8859.8115\n",
      "Epoch 623/5000\n",
      "46/46 [==============================] - 3s 58ms/step - loss: 77.0020 - mae: 77.6823 - val_loss: 8930.6797 - val_mae: 8931.3721\n",
      "Epoch 624/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 72.4196 - mae: 73.0995 - val_loss: 8808.3789 - val_mae: 8809.0723\n",
      "Epoch 625/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 3s 55ms/step - loss: 70.8093 - mae: 71.4873 - val_loss: 8945.5059 - val_mae: 8946.2002\n",
      "Epoch 626/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 70.2023 - mae: 70.8863 - val_loss: 8870.9043 - val_mae: 8871.5977\n",
      "Epoch 627/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 68.9769 - mae: 69.6566 - val_loss: 8917.0166 - val_mae: 8917.7090\n",
      "Epoch 628/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 64.9102 - mae: 65.5900 - val_loss: 8826.7871 - val_mae: 8827.4805\n",
      "Epoch 629/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 68.5895 - mae: 69.2677 - val_loss: 8935.3232 - val_mae: 8936.0156\n",
      "Epoch 630/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 73.3362 - mae: 74.0185 - val_loss: 8914.0889 - val_mae: 8914.7812\n",
      "Epoch 631/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 68.8484 - mae: 69.5281 - val_loss: 9004.8135 - val_mae: 9005.5078\n",
      "Epoch 632/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 64.4433 - mae: 65.1245 - val_loss: 9015.3662 - val_mae: 9016.0586\n",
      "Epoch 633/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 73.9789 - mae: 74.6588 - val_loss: 8766.3223 - val_mae: 8767.0156\n",
      "Epoch 634/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 73.0857 - mae: 73.7645 - val_loss: 8776.4365 - val_mae: 8777.1289\n",
      "Epoch 635/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 66.8222 - mae: 67.5031 - val_loss: 8974.8535 - val_mae: 8975.5488\n",
      "Epoch 636/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 72.2837 - mae: 72.9617 - val_loss: 8976.5928 - val_mae: 8977.2861\n",
      "Epoch 637/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 66.8115 - mae: 67.4926 - val_loss: 8940.1504 - val_mae: 8940.8447\n",
      "Epoch 638/5000\n",
      "46/46 [==============================] - 3s 58ms/step - loss: 71.7634 - mae: 72.4444 - val_loss: 8850.1699 - val_mae: 8850.8623\n",
      "Epoch 639/5000\n",
      "46/46 [==============================] - 3s 61ms/step - loss: 64.1476 - mae: 64.8240 - val_loss: 8871.6416 - val_mae: 8872.3340\n",
      "Epoch 640/5000\n",
      "46/46 [==============================] - 3s 59ms/step - loss: 68.0108 - mae: 68.6936 - val_loss: 8891.0645 - val_mae: 8891.7559\n",
      "Epoch 641/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 67.1671 - mae: 67.8484 - val_loss: 8967.5225 - val_mae: 8968.2158\n",
      "Epoch 642/5000\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 69.6553 - mae: 70.3332 - val_loss: 8985.4082 - val_mae: 8986.1016\n",
      "Epoch 643/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 69.9661 - mae: 70.6467 - val_loss: 8919.1582 - val_mae: 8919.8496\n",
      "Epoch 644/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 65.6266 - mae: 66.3027 - val_loss: 8812.7744 - val_mae: 8813.4678\n",
      "Epoch 645/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 69.8645 - mae: 70.5459 - val_loss: 8813.2432 - val_mae: 8813.9355\n",
      "Epoch 646/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 71.5775 - mae: 72.2561 - val_loss: 8874.2236 - val_mae: 8874.9150\n",
      "Epoch 647/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 71.1324 - mae: 71.8134 - val_loss: 8839.5830 - val_mae: 8840.2754\n",
      "Epoch 648/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 72.0454 - mae: 72.7261 - val_loss: 8942.5342 - val_mae: 8943.2275\n",
      "Epoch 649/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 68.8446 - mae: 69.5222 - val_loss: 8916.8984 - val_mae: 8917.5908\n",
      "Epoch 650/5000\n",
      "46/46 [==============================] - 3s 58ms/step - loss: 65.2586 - mae: 65.9377 - val_loss: 8958.6504 - val_mae: 8959.3457\n",
      "Epoch 651/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 69.2367 - mae: 69.9197 - val_loss: 8916.1367 - val_mae: 8916.8301\n",
      "Epoch 652/5000\n",
      "46/46 [==============================] - 3s 58ms/step - loss: 62.0995 - mae: 62.7778 - val_loss: 8849.7129 - val_mae: 8850.4053\n",
      "Epoch 653/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 66.8770 - mae: 67.5590 - val_loss: 8985.2852 - val_mae: 8985.9775\n",
      "Epoch 654/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 75.0291 - mae: 75.7053 - val_loss: 8920.1143 - val_mae: 8920.8057\n",
      "Epoch 655/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 67.4272 - mae: 68.1063 - val_loss: 8958.6006 - val_mae: 8959.2920\n",
      "Epoch 656/5000\n",
      "46/46 [==============================] - 3s 61ms/step - loss: 68.0485 - mae: 68.7285 - val_loss: 8866.4199 - val_mae: 8867.1113\n",
      "Epoch 657/5000\n",
      "46/46 [==============================] - 3s 61ms/step - loss: 66.7673 - mae: 67.4473 - val_loss: 8865.2090 - val_mae: 8865.9023\n",
      "Epoch 658/5000\n",
      "46/46 [==============================] - 3s 63ms/step - loss: 65.1710 - mae: 65.8527 - val_loss: 8827.6221 - val_mae: 8828.3145\n",
      "Epoch 659/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 64.5359 - mae: 65.2156 - val_loss: 8903.2705 - val_mae: 8903.9629\n",
      "Epoch 660/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 71.8970 - mae: 72.5797 - val_loss: 8891.7666 - val_mae: 8892.4609\n",
      "Epoch 661/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 66.9883 - mae: 67.6647 - val_loss: 8963.9150 - val_mae: 8964.6074\n",
      "Epoch 662/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 63.4906 - mae: 64.1713 - val_loss: 8873.7129 - val_mae: 8874.4053\n",
      "Epoch 663/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 72.8785 - mae: 73.5629 - val_loss: 8983.0723 - val_mae: 8983.7656\n",
      "Epoch 664/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 68.6843 - mae: 69.3682 - val_loss: 8861.9580 - val_mae: 8862.6504\n",
      "Epoch 665/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 73.0441 - mae: 73.7240 - val_loss: 9003.2354 - val_mae: 9003.9287\n",
      "Epoch 666/5000\n",
      "46/46 [==============================] - 3s 59ms/step - loss: 65.0327 - mae: 65.7124 - val_loss: 8933.3291 - val_mae: 8934.0215\n",
      "Epoch 667/5000\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 62.0104 - mae: 62.6910 - val_loss: 8857.6172 - val_mae: 8858.3096\n",
      "Epoch 668/5000\n",
      "46/46 [==============================] - 3s 66ms/step - loss: 65.6171 - mae: 66.2997 - val_loss: 8924.3350 - val_mae: 8925.0273\n",
      "Epoch 669/5000\n",
      "46/46 [==============================] - 3s 58ms/step - loss: 72.5184 - mae: 73.2010 - val_loss: 9010.3301 - val_mae: 9011.0225\n",
      "Epoch 670/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 68.9591 - mae: 69.6393 - val_loss: 8893.3320 - val_mae: 8894.0264\n",
      "Epoch 671/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 63.6966 - mae: 64.3724 - val_loss: 8872.5322 - val_mae: 8873.2246\n",
      "Epoch 672/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 70.9319 - mae: 71.6133 - val_loss: 8850.4766 - val_mae: 8851.1689\n",
      "Epoch 673/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 66.0617 - mae: 66.7432 - val_loss: 8967.9668 - val_mae: 8968.6592\n",
      "Epoch 674/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 67.3266 - mae: 68.0087 - val_loss: 8941.8896 - val_mae: 8942.5820\n",
      "Epoch 675/5000\n",
      "46/46 [==============================] - 3s 54ms/step - loss: 67.7189 - mae: 68.3972 - val_loss: 8829.2969 - val_mae: 8829.9912\n",
      "Epoch 676/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 68.2382 - mae: 68.9176 - val_loss: 8854.4170 - val_mae: 8855.1094\n",
      "Epoch 677/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 67.7579 - mae: 68.4405 - val_loss: 8890.4229 - val_mae: 8891.1172\n",
      "Epoch 678/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 68.4204 - mae: 69.0999 - val_loss: 8914.7168 - val_mae: 8915.4092\n",
      "Epoch 679/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 67.1068 - mae: 67.7889 - val_loss: 8827.7637 - val_mae: 8828.4570\n",
      "Epoch 680/5000\n",
      "46/46 [==============================] - 3s 58ms/step - loss: 66.1089 - mae: 66.7913 - val_loss: 8924.7402 - val_mae: 8925.4316\n",
      "Epoch 681/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 66.7531 - mae: 67.4344 - val_loss: 8887.6250 - val_mae: 8888.3174\n",
      "Epoch 682/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 3s 59ms/step - loss: 66.3698 - mae: 67.0459 - val_loss: 8955.7266 - val_mae: 8956.4199\n",
      "Epoch 683/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 68.0837 - mae: 68.7582 - val_loss: 8832.5459 - val_mae: 8833.2363\n",
      "Epoch 684/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 68.9460 - mae: 69.6250 - val_loss: 8971.7920 - val_mae: 8972.4844\n",
      "Epoch 685/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 63.0134 - mae: 63.6918 - val_loss: 8832.6309 - val_mae: 8833.3232\n",
      "Epoch 686/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 61.4609 - mae: 62.1369 - val_loss: 8847.8105 - val_mae: 8848.5020\n",
      "Epoch 687/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 62.5152 - mae: 63.1972 - val_loss: 8888.1777 - val_mae: 8888.8701\n",
      "Epoch 688/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 69.6524 - mae: 70.3323 - val_loss: 8966.7324 - val_mae: 8967.4248\n",
      "Epoch 689/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 71.7558 - mae: 72.4391 - val_loss: 8859.8682 - val_mae: 8860.5596\n",
      "Epoch 690/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 70.5755 - mae: 71.2570 - val_loss: 8946.1602 - val_mae: 8946.8535\n",
      "Epoch 691/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 63.8494 - mae: 64.5314 - val_loss: 8923.3584 - val_mae: 8924.0508\n",
      "Epoch 692/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 64.0054 - mae: 64.6878 - val_loss: 8866.8613 - val_mae: 8867.5557\n",
      "Epoch 693/5000\n",
      "46/46 [==============================] - 3s 54ms/step - loss: 64.3620 - mae: 65.0417 - val_loss: 8882.4473 - val_mae: 8883.1396\n",
      "Epoch 694/5000\n",
      "46/46 [==============================] - 3s 58ms/step - loss: 62.6259 - mae: 63.3041 - val_loss: 8864.8408 - val_mae: 8865.5352\n",
      "Epoch 695/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 55.0121 - mae: 55.6953 - val_loss: 8911.3037 - val_mae: 8911.9961\n",
      "Epoch 696/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 68.9462 - mae: 69.6255 - val_loss: 8852.7959 - val_mae: 8853.4883\n",
      "Epoch 697/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 66.8777 - mae: 67.5551 - val_loss: 8960.8350 - val_mae: 8961.5283\n",
      "Epoch 698/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 64.2032 - mae: 64.8820 - val_loss: 8830.7617 - val_mae: 8831.4551\n",
      "Epoch 699/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 62.1251 - mae: 62.8012 - val_loss: 8946.4375 - val_mae: 8947.1309\n",
      "Epoch 700/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 69.5540 - mae: 70.2350 - val_loss: 8927.1924 - val_mae: 8927.8857\n",
      "Epoch 701/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 69.2439 - mae: 69.9184 - val_loss: 8988.2734 - val_mae: 8988.9668\n",
      "Epoch 702/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 66.0101 - mae: 66.6887 - val_loss: 8822.5957 - val_mae: 8823.2900\n",
      "Epoch 703/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 64.3538 - mae: 65.0366 - val_loss: 8985.6396 - val_mae: 8986.3330\n",
      "Epoch 704/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 67.5365 - mae: 68.2174 - val_loss: 8865.4980 - val_mae: 8866.1924\n",
      "Epoch 705/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 65.7861 - mae: 66.4659 - val_loss: 8942.9248 - val_mae: 8943.6162\n",
      "Epoch 706/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 62.5375 - mae: 63.2188 - val_loss: 8997.9199 - val_mae: 8998.6133\n",
      "Epoch 707/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 66.3665 - mae: 67.0458 - val_loss: 8743.6953 - val_mae: 8744.3887\n",
      "Epoch 708/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 71.0085 - mae: 71.6864 - val_loss: 8953.7529 - val_mae: 8954.4482\n",
      "Epoch 709/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 67.1537 - mae: 67.8325 - val_loss: 8961.6748 - val_mae: 8962.3672\n",
      "Epoch 710/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 64.5390 - mae: 65.2144 - val_loss: 8811.3525 - val_mae: 8812.0479\n",
      "Epoch 711/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 67.1261 - mae: 67.8063 - val_loss: 8787.8447 - val_mae: 8788.5381\n",
      "Epoch 712/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 71.0951 - mae: 71.7718 - val_loss: 8974.7158 - val_mae: 8975.4082\n",
      "Epoch 713/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 64.3613 - mae: 65.0415 - val_loss: 8980.9375 - val_mae: 8981.6299\n",
      "Epoch 714/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 66.5047 - mae: 67.1816 - val_loss: 8918.0547 - val_mae: 8918.7490\n",
      "Epoch 715/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 58.1641 - mae: 58.8425 - val_loss: 8972.0703 - val_mae: 8972.7637\n",
      "Epoch 716/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 67.8394 - mae: 68.5175 - val_loss: 8949.8047 - val_mae: 8950.4971\n",
      "Epoch 717/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 65.7980 - mae: 66.4796 - val_loss: 8893.8105 - val_mae: 8894.5029\n",
      "Epoch 718/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 61.8633 - mae: 62.5433 - val_loss: 8839.3076 - val_mae: 8840.0000\n",
      "Epoch 719/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 63.6408 - mae: 64.3222 - val_loss: 8862.4961 - val_mae: 8863.1904\n",
      "Epoch 720/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 64.8221 - mae: 65.5040 - val_loss: 8965.3740 - val_mae: 8966.0664\n",
      "Epoch 721/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 61.6292 - mae: 62.3067 - val_loss: 8925.6309 - val_mae: 8926.3242\n",
      "Epoch 722/5000\n",
      "46/46 [==============================] - 3s 58ms/step - loss: 59.5037 - mae: 60.1796 - val_loss: 8856.5322 - val_mae: 8857.2246\n",
      "Epoch 723/5000\n",
      "46/46 [==============================] - 3s 62ms/step - loss: 60.1428 - mae: 60.8202 - val_loss: 8966.8467 - val_mae: 8967.5400\n",
      "Epoch 724/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 59.5114 - mae: 60.1899 - val_loss: 8866.2344 - val_mae: 8866.9287\n",
      "Epoch 725/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 63.8591 - mae: 64.5391 - val_loss: 8866.7822 - val_mae: 8867.4756\n",
      "Epoch 726/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 59.1986 - mae: 59.8770 - val_loss: 8897.4639 - val_mae: 8898.1572\n",
      "Epoch 727/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 65.8886 - mae: 66.5715 - val_loss: 8965.3955 - val_mae: 8966.0889\n",
      "Epoch 728/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 72.6233 - mae: 73.3048 - val_loss: 8818.5488 - val_mae: 8819.2422\n",
      "Epoch 729/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 67.6402 - mae: 68.3190 - val_loss: 8906.5957 - val_mae: 8907.2881\n",
      "Epoch 730/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 57.6608 - mae: 58.3377 - val_loss: 8973.1084 - val_mae: 8973.8018\n",
      "Epoch 731/5000\n",
      "46/46 [==============================] - 3s 62ms/step - loss: 67.5378 - mae: 68.2185 - val_loss: 8920.9170 - val_mae: 8921.6104\n",
      "Epoch 732/5000\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 66.7561 - mae: 67.4379 - val_loss: 9006.6221 - val_mae: 9007.3154\n",
      "Epoch 733/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 60.1158 - mae: 60.7927 - val_loss: 8947.3730 - val_mae: 8948.0654\n",
      "Epoch 734/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 63.5424 - mae: 64.2197 - val_loss: 8945.2734 - val_mae: 8945.9668\n",
      "Epoch 735/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 64.7612 - mae: 65.4389 - val_loss: 8948.3291 - val_mae: 8949.0215\n",
      "Epoch 736/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 59.8310 - mae: 60.5119 - val_loss: 8849.1797 - val_mae: 8849.8740\n",
      "Epoch 737/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 65.9065 - mae: 66.5847 - val_loss: 8971.8105 - val_mae: 8972.5029\n",
      "Epoch 738/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 64.6919 - mae: 65.3755 - val_loss: 9010.0146 - val_mae: 9010.7080\n",
      "Epoch 739/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 54ms/step - loss: 66.6329 - mae: 67.3115 - val_loss: 8956.5469 - val_mae: 8957.2393\n",
      "Epoch 740/5000\n",
      "46/46 [==============================] - 3s 61ms/step - loss: 63.6259 - mae: 64.3037 - val_loss: 8976.2461 - val_mae: 8976.9395\n",
      "Epoch 741/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 72.7244 - mae: 73.4039 - val_loss: 8835.1504 - val_mae: 8835.8438\n",
      "Epoch 742/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 57.5095 - mae: 58.1881 - val_loss: 8968.2119 - val_mae: 8968.9053\n",
      "Epoch 743/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 63.3013 - mae: 63.9810 - val_loss: 8900.6357 - val_mae: 8901.3291\n",
      "Epoch 744/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 64.5013 - mae: 65.1796 - val_loss: 8775.4785 - val_mae: 8776.1719\n",
      "Epoch 745/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 58.7780 - mae: 59.4565 - val_loss: 8924.9170 - val_mae: 8925.6104\n",
      "Epoch 746/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 57.3959 - mae: 58.0767 - val_loss: 8957.1172 - val_mae: 8957.8096\n",
      "Epoch 747/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 60.8129 - mae: 61.4921 - val_loss: 8967.4434 - val_mae: 8968.1367\n",
      "Epoch 748/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 66.3683 - mae: 67.0477 - val_loss: 8964.7949 - val_mae: 8965.4873\n",
      "Epoch 749/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 57.8365 - mae: 58.5107 - val_loss: 8897.1475 - val_mae: 8897.8408\n",
      "Epoch 750/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 61.1595 - mae: 61.8379 - val_loss: 8944.9229 - val_mae: 8945.6172\n",
      "Epoch 751/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 64.5358 - mae: 65.2132 - val_loss: 8978.4258 - val_mae: 8979.1182\n",
      "Epoch 752/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 68.0803 - mae: 68.7639 - val_loss: 8938.5068 - val_mae: 8939.2002\n",
      "Epoch 753/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 66.0481 - mae: 66.7245 - val_loss: 9003.4424 - val_mae: 9004.1348\n",
      "Epoch 754/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 63.6189 - mae: 64.2981 - val_loss: 8947.2080 - val_mae: 8947.8994\n",
      "Epoch 755/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 57.3229 - mae: 57.9990 - val_loss: 9052.8457 - val_mae: 9053.5381\n",
      "Epoch 756/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 63.0473 - mae: 63.7241 - val_loss: 8965.1670 - val_mae: 8965.8604\n",
      "Epoch 757/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 61.3745 - mae: 62.0536 - val_loss: 8878.8516 - val_mae: 8879.5449\n",
      "Epoch 758/5000\n",
      "46/46 [==============================] - 3s 58ms/step - loss: 62.1943 - mae: 62.8697 - val_loss: 8908.3877 - val_mae: 8909.0820\n",
      "Epoch 759/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 59.4284 - mae: 60.1030 - val_loss: 8866.4111 - val_mae: 8867.1045\n",
      "Epoch 760/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 62.6561 - mae: 63.3338 - val_loss: 8809.6201 - val_mae: 8810.3135\n",
      "Epoch 761/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 62.0699 - mae: 62.7489 - val_loss: 9007.6523 - val_mae: 9008.3457\n",
      "Epoch 762/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 62.1441 - mae: 62.8194 - val_loss: 8984.1846 - val_mae: 8984.8770\n",
      "Epoch 763/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 61.9740 - mae: 62.6534 - val_loss: 8934.1211 - val_mae: 8934.8135\n",
      "Epoch 764/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 61.8060 - mae: 62.4848 - val_loss: 8937.6426 - val_mae: 8938.3359\n",
      "Epoch 765/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 58.7367 - mae: 59.4136 - val_loss: 8919.5107 - val_mae: 8920.2041\n",
      "Epoch 766/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 62.5763 - mae: 63.2521 - val_loss: 8898.1250 - val_mae: 8898.8193\n",
      "Epoch 767/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 66.5042 - mae: 67.1814 - val_loss: 8850.7500 - val_mae: 8851.4434\n",
      "Epoch 768/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 74.9490 - mae: 75.6283 - val_loss: 8967.4287 - val_mae: 8968.1221\n",
      "Epoch 769/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 62.0361 - mae: 62.7164 - val_loss: 8872.7490 - val_mae: 8873.4424\n",
      "Epoch 770/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 57.2842 - mae: 57.9623 - val_loss: 8989.0225 - val_mae: 8989.7158\n",
      "Epoch 771/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 58.9345 - mae: 59.6097 - val_loss: 8972.7559 - val_mae: 8973.4502\n",
      "Epoch 772/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 60.8412 - mae: 61.5179 - val_loss: 8959.3242 - val_mae: 8960.0186\n",
      "Epoch 773/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 68.0276 - mae: 68.7085 - val_loss: 8957.4697 - val_mae: 8958.1641\n",
      "Epoch 774/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 60.4131 - mae: 61.0918 - val_loss: 8888.7949 - val_mae: 8889.4883\n",
      "Epoch 775/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 57.6804 - mae: 58.3545 - val_loss: 8920.0762 - val_mae: 8920.7695\n",
      "Epoch 776/5000\n",
      "46/46 [==============================] - 1s 33ms/step - loss: 59.5294 - mae: 60.2091 - val_loss: 8966.7549 - val_mae: 8967.4492\n",
      "Epoch 777/5000\n",
      "46/46 [==============================] - 1s 31ms/step - loss: 54.5989 - mae: 55.2777 - val_loss: 8901.0342 - val_mae: 8901.7285\n",
      "Epoch 778/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 64.0856 - mae: 64.7612 - val_loss: 8925.4287 - val_mae: 8926.1201\n",
      "Epoch 779/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 61.3939 - mae: 62.0668 - val_loss: 8896.5400 - val_mae: 8897.2334\n",
      "Epoch 780/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 60.4374 - mae: 61.1145 - val_loss: 9005.0664 - val_mae: 9005.7598\n",
      "Epoch 781/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 70.9726 - mae: 71.6558 - val_loss: 8881.5215 - val_mae: 8882.2139\n",
      "Epoch 782/5000\n",
      "46/46 [==============================] - 3s 59ms/step - loss: 61.8737 - mae: 62.5510 - val_loss: 8908.6143 - val_mae: 8909.3066\n",
      "Epoch 783/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 61.4823 - mae: 62.1625 - val_loss: 8949.2041 - val_mae: 8949.8965\n",
      "Epoch 784/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 60.0656 - mae: 60.7421 - val_loss: 8883.6943 - val_mae: 8884.3867\n",
      "Epoch 785/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 60.2275 - mae: 60.9086 - val_loss: 8886.9971 - val_mae: 8887.6895\n",
      "Epoch 786/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 59.6207 - mae: 60.2931 - val_loss: 8954.4209 - val_mae: 8955.1143\n",
      "Epoch 787/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 57.3652 - mae: 58.0416 - val_loss: 8924.9834 - val_mae: 8925.6768\n",
      "Epoch 788/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 60.3509 - mae: 61.0317 - val_loss: 8876.5303 - val_mae: 8877.2227\n",
      "Epoch 789/5000\n",
      "46/46 [==============================] - 1s 32ms/step - loss: 60.9490 - mae: 61.6280 - val_loss: 8929.4629 - val_mae: 8930.1553\n",
      "Epoch 790/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 65.6736 - mae: 66.3531 - val_loss: 8903.2090 - val_mae: 8903.9014\n",
      "Epoch 791/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 65.4051 - mae: 66.0781 - val_loss: 8915.6250 - val_mae: 8916.3184\n",
      "Epoch 792/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 60.2859 - mae: 60.9668 - val_loss: 8869.2783 - val_mae: 8869.9717\n",
      "Epoch 793/5000\n",
      "46/46 [==============================] - 3s 61ms/step - loss: 62.9857 - mae: 63.6618 - val_loss: 8844.9736 - val_mae: 8845.6670\n",
      "Epoch 794/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 65.4298 - mae: 66.1093 - val_loss: 8893.9805 - val_mae: 8894.6738\n",
      "Epoch 795/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 68.4143 - mae: 69.0943 - val_loss: 8914.3643 - val_mae: 8915.0586\n",
      "Epoch 796/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 48ms/step - loss: 64.2785 - mae: 64.9577 - val_loss: 8866.9648 - val_mae: 8867.6582\n",
      "Epoch 797/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 59.3613 - mae: 60.0397 - val_loss: 8912.0391 - val_mae: 8912.7324\n",
      "Epoch 798/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 56.9956 - mae: 57.6771 - val_loss: 8836.0498 - val_mae: 8836.7441\n",
      "Epoch 799/5000\n",
      "46/46 [==============================] - 1s 30ms/step - loss: 58.8872 - mae: 59.5643 - val_loss: 8977.8418 - val_mae: 8978.5332\n",
      "Epoch 800/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 56.0318 - mae: 56.7081 - val_loss: 8944.1670 - val_mae: 8944.8604\n",
      "Epoch 801/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 58.4192 - mae: 59.0967 - val_loss: 8983.8701 - val_mae: 8984.5645\n",
      "Epoch 802/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 63.2317 - mae: 63.9072 - val_loss: 8833.6230 - val_mae: 8834.3154\n",
      "Epoch 803/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 63.0881 - mae: 63.7628 - val_loss: 8889.3486 - val_mae: 8890.0410\n",
      "Epoch 804/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 54.1970 - mae: 54.8716 - val_loss: 8879.2744 - val_mae: 8879.9678\n",
      "Epoch 805/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 58.7873 - mae: 59.4624 - val_loss: 8872.8770 - val_mae: 8873.5703\n",
      "Epoch 806/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 53.8679 - mae: 54.5428 - val_loss: 9005.6436 - val_mae: 9006.3369\n",
      "Epoch 807/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 53.6486 - mae: 54.3282 - val_loss: 8997.7871 - val_mae: 8998.4814\n",
      "Epoch 808/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 59.9533 - mae: 60.6305 - val_loss: 8910.0479 - val_mae: 8910.7412\n",
      "Epoch 809/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 56.7456 - mae: 57.4258 - val_loss: 8908.3594 - val_mae: 8909.0518\n",
      "Epoch 810/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 54.3901 - mae: 55.0679 - val_loss: 8883.3379 - val_mae: 8884.0312\n",
      "Epoch 811/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 66.5428 - mae: 67.2231 - val_loss: 8948.5137 - val_mae: 8949.2070\n",
      "Epoch 812/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 59.6794 - mae: 60.3553 - val_loss: 8895.3896 - val_mae: 8896.0830\n",
      "Epoch 813/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 60.0844 - mae: 60.7624 - val_loss: 8916.0801 - val_mae: 8916.7744\n",
      "Epoch 814/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 55.8265 - mae: 56.5029 - val_loss: 8964.8643 - val_mae: 8965.5586\n",
      "Epoch 815/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 60.6388 - mae: 61.3228 - val_loss: 8912.8721 - val_mae: 8913.5645\n",
      "Epoch 816/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 56.8924 - mae: 57.5700 - val_loss: 8874.7949 - val_mae: 8875.4883\n",
      "Epoch 817/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 60.8341 - mae: 61.5167 - val_loss: 8835.0771 - val_mae: 8835.7695\n",
      "Epoch 818/5000\n",
      "46/46 [==============================] - 2s 33ms/step - loss: 56.7351 - mae: 57.4131 - val_loss: 9012.2383 - val_mae: 9012.9316\n",
      "Epoch 819/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 56.5540 - mae: 57.2304 - val_loss: 9001.4160 - val_mae: 9002.1084\n",
      "Epoch 820/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 59.1860 - mae: 59.8614 - val_loss: 8932.6816 - val_mae: 8933.3740\n",
      "Epoch 821/5000\n",
      "46/46 [==============================] - 2s 33ms/step - loss: 57.4654 - mae: 58.1427 - val_loss: 8833.1553 - val_mae: 8833.8496\n",
      "Epoch 822/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 61.6734 - mae: 62.3510 - val_loss: 8940.9141 - val_mae: 8941.6064\n",
      "Epoch 823/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 56.5427 - mae: 57.2216 - val_loss: 8940.0400 - val_mae: 8940.7314\n",
      "Epoch 824/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 58.1670 - mae: 58.8495 - val_loss: 8909.7178 - val_mae: 8910.4102\n",
      "Epoch 825/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 61.0087 - mae: 61.6925 - val_loss: 8931.4648 - val_mae: 8932.1582\n",
      "Epoch 826/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 61.8503 - mae: 62.5316 - val_loss: 8826.2314 - val_mae: 8826.9238\n",
      "Epoch 827/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 58.3243 - mae: 59.0006 - val_loss: 8936.1123 - val_mae: 8936.8057\n",
      "Epoch 828/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 56.7177 - mae: 57.3937 - val_loss: 8899.2100 - val_mae: 8899.9033\n",
      "Epoch 829/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 59.4203 - mae: 60.1008 - val_loss: 8936.0273 - val_mae: 8936.7197\n",
      "Epoch 830/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 56.8277 - mae: 57.5100 - val_loss: 8878.8936 - val_mae: 8879.5869\n",
      "Epoch 831/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 55.7309 - mae: 56.4086 - val_loss: 8875.8496 - val_mae: 8876.5420\n",
      "Epoch 832/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 57.9625 - mae: 58.6398 - val_loss: 8921.1377 - val_mae: 8921.8291\n",
      "Epoch 833/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 57.6436 - mae: 58.3236 - val_loss: 8908.7354 - val_mae: 8909.4287\n",
      "Epoch 834/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 59.0375 - mae: 59.7136 - val_loss: 8898.7451 - val_mae: 8899.4375\n",
      "Epoch 835/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 59.0695 - mae: 59.7478 - val_loss: 8956.7227 - val_mae: 8957.4150\n",
      "Epoch 836/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 60.8484 - mae: 61.5259 - val_loss: 8939.3994 - val_mae: 8940.0938\n",
      "Epoch 837/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 61.5815 - mae: 62.2606 - val_loss: 8876.3984 - val_mae: 8877.0918\n",
      "Epoch 838/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 61.6708 - mae: 62.3507 - val_loss: 9024.8516 - val_mae: 9025.5459\n",
      "Epoch 839/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 63.9592 - mae: 64.6385 - val_loss: 9012.0811 - val_mae: 9012.7725\n",
      "Epoch 840/5000\n",
      "46/46 [==============================] - 3s 68ms/step - loss: 56.5295 - mae: 57.2094 - val_loss: 8892.5537 - val_mae: 8893.2461\n",
      "Epoch 841/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 57.3811 - mae: 58.0610 - val_loss: 8801.4355 - val_mae: 8802.1289\n",
      "Epoch 842/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 60.1881 - mae: 60.8687 - val_loss: 8939.8096 - val_mae: 8940.5020\n",
      "Epoch 843/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 58.0286 - mae: 58.7039 - val_loss: 8881.8760 - val_mae: 8882.5693\n",
      "Epoch 844/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 56.1885 - mae: 56.8664 - val_loss: 8919.5635 - val_mae: 8920.2568\n",
      "Epoch 845/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 58.6201 - mae: 59.2966 - val_loss: 8987.4082 - val_mae: 8988.0986\n",
      "Epoch 846/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 61.3549 - mae: 62.0381 - val_loss: 8972.9609 - val_mae: 8973.6533\n",
      "Epoch 847/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 61.4058 - mae: 62.0842 - val_loss: 8917.8535 - val_mae: 8918.5488\n",
      "Epoch 848/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 58.8366 - mae: 59.5113 - val_loss: 8929.3506 - val_mae: 8930.0449\n",
      "Epoch 849/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 58.5164 - mae: 59.1967 - val_loss: 8942.7383 - val_mae: 8943.4316\n",
      "Epoch 850/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 53.2366 - mae: 53.9142 - val_loss: 8957.5889 - val_mae: 8958.2822\n",
      "Epoch 851/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 54.8038 - mae: 55.4803 - val_loss: 8894.9375 - val_mae: 8895.6318\n",
      "Epoch 852/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 56.5510 - mae: 57.2315 - val_loss: 8905.6797 - val_mae: 8906.3721\n",
      "Epoch 853/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 33ms/step - loss: 55.6499 - mae: 56.3271 - val_loss: 8925.8027 - val_mae: 8926.4961\n",
      "Epoch 854/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 59.1194 - mae: 59.7919 - val_loss: 8904.7559 - val_mae: 8905.4492\n",
      "Epoch 855/5000\n",
      "46/46 [==============================] - 1s 31ms/step - loss: 56.3238 - mae: 57.0020 - val_loss: 8957.1514 - val_mae: 8957.8438\n",
      "Epoch 856/5000\n",
      "46/46 [==============================] - 2s 33ms/step - loss: 52.7834 - mae: 53.4566 - val_loss: 8984.2285 - val_mae: 8984.9219\n",
      "Epoch 857/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 61.1340 - mae: 61.8125 - val_loss: 8947.3418 - val_mae: 8948.0361\n",
      "Epoch 858/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 53.9471 - mae: 54.6226 - val_loss: 8956.1367 - val_mae: 8956.8311\n",
      "Epoch 859/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 52.3263 - mae: 53.0031 - val_loss: 8913.5527 - val_mae: 8914.2461\n",
      "Epoch 860/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 56.2382 - mae: 56.9156 - val_loss: 8969.5215 - val_mae: 8970.2139\n",
      "Epoch 861/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 56.0089 - mae: 56.6865 - val_loss: 8928.3789 - val_mae: 8929.0723\n",
      "Epoch 862/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 58.9732 - mae: 59.6485 - val_loss: 8897.4707 - val_mae: 8898.1631\n",
      "Epoch 863/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 59.0023 - mae: 59.6812 - val_loss: 8801.6719 - val_mae: 8802.3643\n",
      "Epoch 864/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 58.0870 - mae: 58.7631 - val_loss: 8899.0312 - val_mae: 8899.7246\n",
      "Epoch 865/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 59.8112 - mae: 60.4892 - val_loss: 8973.9404 - val_mae: 8974.6328\n",
      "Epoch 866/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 55.2530 - mae: 55.9307 - val_loss: 8914.1748 - val_mae: 8914.8682\n",
      "Epoch 867/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 56.9400 - mae: 57.6203 - val_loss: 8917.5010 - val_mae: 8918.1943\n",
      "Epoch 868/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 58.8665 - mae: 59.5445 - val_loss: 8952.8076 - val_mae: 8953.5000\n",
      "Epoch 869/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 56.4480 - mae: 57.1268 - val_loss: 8904.1201 - val_mae: 8904.8145\n",
      "Epoch 870/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 58.0321 - mae: 58.7059 - val_loss: 8901.8516 - val_mae: 8902.5459\n",
      "Epoch 871/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 56.6878 - mae: 57.3686 - val_loss: 8868.6309 - val_mae: 8869.3223\n",
      "Epoch 872/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 55.7829 - mae: 56.4615 - val_loss: 8921.5322 - val_mae: 8922.2236\n",
      "Epoch 873/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 56.3439 - mae: 57.0220 - val_loss: 8956.2393 - val_mae: 8956.9316\n",
      "Epoch 874/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 58.5534 - mae: 59.2311 - val_loss: 8942.4756 - val_mae: 8943.1689\n",
      "Epoch 875/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 62.1428 - mae: 62.8200 - val_loss: 8965.4883 - val_mae: 8966.1826\n",
      "Epoch 876/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 63.9539 - mae: 64.6315 - val_loss: 9011.3838 - val_mae: 9012.0762\n",
      "Epoch 877/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 62.3494 - mae: 63.0233 - val_loss: 8923.7158 - val_mae: 8924.4092\n",
      "Epoch 878/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 59.4786 - mae: 60.1548 - val_loss: 8925.2725 - val_mae: 8925.9658\n",
      "Epoch 879/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 55.8028 - mae: 56.4795 - val_loss: 8988.5234 - val_mae: 8989.2168\n",
      "Epoch 880/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 61.3562 - mae: 62.0351 - val_loss: 8920.5625 - val_mae: 8921.2539\n",
      "Epoch 881/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 56.9439 - mae: 57.6240 - val_loss: 8847.8262 - val_mae: 8848.5195\n",
      "Epoch 882/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 61.2028 - mae: 61.8821 - val_loss: 8937.0957 - val_mae: 8937.7881\n",
      "Epoch 883/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 53.6049 - mae: 54.2761 - val_loss: 8890.6895 - val_mae: 8891.3809\n",
      "Epoch 884/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 57.8699 - mae: 58.5451 - val_loss: 8960.8867 - val_mae: 8961.5801\n",
      "Epoch 885/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 59.3506 - mae: 60.0295 - val_loss: 8867.4121 - val_mae: 8868.1025\n",
      "Epoch 886/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 54.0263 - mae: 54.7037 - val_loss: 9015.0547 - val_mae: 9015.7490\n",
      "Epoch 887/5000\n",
      "46/46 [==============================] - 2s 33ms/step - loss: 54.5441 - mae: 55.2193 - val_loss: 8941.4756 - val_mae: 8942.1689\n",
      "Epoch 888/5000\n",
      "46/46 [==============================] - 1s 32ms/step - loss: 55.9239 - mae: 56.6009 - val_loss: 8985.5381 - val_mae: 8986.2314\n",
      "Epoch 889/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 56.3568 - mae: 57.0337 - val_loss: 8959.2559 - val_mae: 8959.9502\n",
      "Epoch 890/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 55.6624 - mae: 56.3455 - val_loss: 8887.4062 - val_mae: 8888.0996\n",
      "Epoch 891/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 56.7194 - mae: 57.3987 - val_loss: 8863.0928 - val_mae: 8863.7852\n",
      "Epoch 892/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 52.3552 - mae: 53.0354 - val_loss: 8869.1475 - val_mae: 8869.8398\n",
      "Epoch 893/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 51.6121 - mae: 52.2882 - val_loss: 8911.3535 - val_mae: 8912.0469\n",
      "Epoch 894/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 54.9250 - mae: 55.6014 - val_loss: 8919.0527 - val_mae: 8919.7461\n",
      "Epoch 895/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 64.7440 - mae: 65.4263 - val_loss: 8935.7715 - val_mae: 8936.4629\n",
      "Epoch 896/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 52.9502 - mae: 53.6257 - val_loss: 8933.5566 - val_mae: 8934.2500\n",
      "Epoch 897/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 53.8923 - mae: 54.5677 - val_loss: 8896.1016 - val_mae: 8896.7939\n",
      "Epoch 898/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 52.2568 - mae: 52.9339 - val_loss: 8880.6582 - val_mae: 8881.3516\n",
      "Epoch 899/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 54.4574 - mae: 55.1400 - val_loss: 8931.2832 - val_mae: 8931.9756\n",
      "Epoch 900/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 56.8802 - mae: 57.5599 - val_loss: 8984.5049 - val_mae: 8985.1992\n",
      "Epoch 901/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 56.9751 - mae: 57.6557 - val_loss: 8934.8545 - val_mae: 8935.5488\n",
      "Epoch 902/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 58.7422 - mae: 59.4179 - val_loss: 8912.9316 - val_mae: 8913.6250\n",
      "Epoch 903/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 54.3610 - mae: 55.0394 - val_loss: 8950.1709 - val_mae: 8950.8643\n",
      "Epoch 904/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 54.6253 - mae: 55.3010 - val_loss: 8902.5938 - val_mae: 8903.2861\n",
      "Epoch 905/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 63.0564 - mae: 63.7369 - val_loss: 8853.4385 - val_mae: 8854.1299\n",
      "Epoch 906/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 59.9407 - mae: 60.6193 - val_loss: 8952.5166 - val_mae: 8953.2100\n",
      "Epoch 907/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 53.0426 - mae: 53.7164 - val_loss: 8938.0342 - val_mae: 8938.7275\n",
      "Epoch 908/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 51.3017 - mae: 51.9777 - val_loss: 8832.0205 - val_mae: 8832.7148\n",
      "Epoch 909/5000\n",
      "46/46 [==============================] - 3s 58ms/step - loss: 53.7719 - mae: 54.4456 - val_loss: 8946.5889 - val_mae: 8947.2822\n",
      "Epoch 910/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 47ms/step - loss: 52.8373 - mae: 53.5107 - val_loss: 8909.9268 - val_mae: 8910.6191\n",
      "Epoch 911/5000\n",
      "46/46 [==============================] - 1s 32ms/step - loss: 50.1719 - mae: 50.8486 - val_loss: 8898.7871 - val_mae: 8899.4805\n",
      "Epoch 912/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 51.4710 - mae: 52.1477 - val_loss: 8864.4951 - val_mae: 8865.1875\n",
      "Epoch 913/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 55.2241 - mae: 55.9040 - val_loss: 8860.8105 - val_mae: 8861.5039\n",
      "Epoch 914/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 49.8681 - mae: 50.5437 - val_loss: 8937.6191 - val_mae: 8938.3135\n",
      "Epoch 915/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 52.3376 - mae: 53.0171 - val_loss: 8872.2891 - val_mae: 8872.9814\n",
      "Epoch 916/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 59.5177 - mae: 60.1967 - val_loss: 8891.6289 - val_mae: 8892.3232\n",
      "Epoch 917/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 53.9366 - mae: 54.6175 - val_loss: 8929.9688 - val_mae: 8930.6621\n",
      "Epoch 918/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 52.9008 - mae: 53.5764 - val_loss: 8915.7041 - val_mae: 8916.3975\n",
      "Epoch 919/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 55.4690 - mae: 56.1464 - val_loss: 8844.2686 - val_mae: 8844.9629\n",
      "Epoch 920/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 57.7966 - mae: 58.4747 - val_loss: 8932.1006 - val_mae: 8932.7939\n",
      "Epoch 921/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 50.7779 - mae: 51.4530 - val_loss: 8948.7832 - val_mae: 8949.4766\n",
      "Epoch 922/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 54.1588 - mae: 54.8383 - val_loss: 8852.6846 - val_mae: 8853.3770\n",
      "Epoch 923/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 54.0660 - mae: 54.7423 - val_loss: 8872.2900 - val_mae: 8872.9834\n",
      "Epoch 924/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 54.6158 - mae: 55.2964 - val_loss: 8922.8320 - val_mae: 8923.5244\n",
      "Epoch 925/5000\n",
      "46/46 [==============================] - 3s 65ms/step - loss: 54.4168 - mae: 55.0988 - val_loss: 8860.7373 - val_mae: 8861.4307\n",
      "Epoch 926/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 51.4654 - mae: 52.1428 - val_loss: 8850.9023 - val_mae: 8851.5957\n",
      "Epoch 927/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 56.0464 - mae: 56.7259 - val_loss: 8890.4922 - val_mae: 8891.1836\n",
      "Epoch 928/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 61.1542 - mae: 61.8328 - val_loss: 8876.8291 - val_mae: 8877.5215\n",
      "Epoch 929/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 63.3461 - mae: 64.0238 - val_loss: 8925.8418 - val_mae: 8926.5342\n",
      "Epoch 930/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 55.3852 - mae: 56.0612 - val_loss: 8956.7295 - val_mae: 8957.4238\n",
      "Epoch 931/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 56.0498 - mae: 56.7273 - val_loss: 8905.3838 - val_mae: 8906.0781\n",
      "Epoch 932/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 57.0048 - mae: 57.6818 - val_loss: 8861.3848 - val_mae: 8862.0771\n",
      "Epoch 933/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 57.1526 - mae: 57.8310 - val_loss: 8928.6162 - val_mae: 8929.3096\n",
      "Epoch 934/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 53.5081 - mae: 54.1844 - val_loss: 8878.5576 - val_mae: 8879.2510\n",
      "Epoch 935/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 55.3289 - mae: 56.0087 - val_loss: 8878.8164 - val_mae: 8879.5098\n",
      "Epoch 936/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 54.4972 - mae: 55.1744 - val_loss: 8775.8574 - val_mae: 8776.5508\n",
      "Epoch 937/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 53.8052 - mae: 54.4827 - val_loss: 8883.3389 - val_mae: 8884.0312\n",
      "Epoch 938/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 55.9291 - mae: 56.6043 - val_loss: 8953.0137 - val_mae: 8953.7070\n",
      "Epoch 939/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 55.9524 - mae: 56.6301 - val_loss: 8891.1172 - val_mae: 8891.8096\n",
      "Epoch 940/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 53.1951 - mae: 53.8712 - val_loss: 8839.4150 - val_mae: 8840.1074\n",
      "Epoch 941/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 62.6384 - mae: 63.3155 - val_loss: 8814.0566 - val_mae: 8814.7500\n",
      "Epoch 942/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 55.9746 - mae: 56.6519 - val_loss: 8938.2783 - val_mae: 8938.9717\n",
      "Epoch 943/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 49.6632 - mae: 50.3427 - val_loss: 8852.8818 - val_mae: 8853.5762\n",
      "Epoch 944/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 50.9679 - mae: 51.6459 - val_loss: 8926.7041 - val_mae: 8927.3975\n",
      "Epoch 945/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 56.2927 - mae: 56.9719 - val_loss: 8874.5830 - val_mae: 8875.2764\n",
      "Epoch 946/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 50.5500 - mae: 51.2284 - val_loss: 8870.3604 - val_mae: 8871.0537\n",
      "Epoch 947/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 53.4014 - mae: 54.0811 - val_loss: 8821.5117 - val_mae: 8822.2051\n",
      "Epoch 948/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 54.0473 - mae: 54.7256 - val_loss: 8934.3789 - val_mae: 8935.0723\n",
      "Epoch 949/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 61.4004 - mae: 62.0808 - val_loss: 8889.8594 - val_mae: 8890.5518\n",
      "Epoch 950/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 52.8198 - mae: 53.4977 - val_loss: 8971.5234 - val_mae: 8972.2158\n",
      "Epoch 951/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 55.9022 - mae: 56.5835 - val_loss: 8859.0420 - val_mae: 8859.7354\n",
      "Epoch 952/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 54.7608 - mae: 55.4398 - val_loss: 8920.7148 - val_mae: 8921.4082\n",
      "Epoch 953/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 57.5463 - mae: 58.2241 - val_loss: 8886.2832 - val_mae: 8886.9775\n",
      "Epoch 954/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 50.7015 - mae: 51.3725 - val_loss: 9066.3447 - val_mae: 9067.0371\n",
      "Epoch 955/5000\n",
      "46/46 [==============================] - 3s 58ms/step - loss: 57.5928 - mae: 58.2678 - val_loss: 8899.0215 - val_mae: 8899.7158\n",
      "Epoch 956/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 55.2812 - mae: 55.9621 - val_loss: 8927.1650 - val_mae: 8927.8584\n",
      "Epoch 957/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 53.6115 - mae: 54.2858 - val_loss: 8828.0605 - val_mae: 8828.7529\n",
      "Epoch 958/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 56.3912 - mae: 57.0678 - val_loss: 8934.5586 - val_mae: 8935.2510\n",
      "Epoch 959/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 51.9363 - mae: 52.6109 - val_loss: 8941.5117 - val_mae: 8942.2041\n",
      "Epoch 960/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 59.8052 - mae: 60.4775 - val_loss: 8909.7500 - val_mae: 8910.4443\n",
      "Epoch 961/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 51.9549 - mae: 52.6241 - val_loss: 8901.7275 - val_mae: 8902.4199\n",
      "Epoch 962/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 52.4675 - mae: 53.1421 - val_loss: 8781.4287 - val_mae: 8782.1211\n",
      "Epoch 963/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 55.7788 - mae: 56.4491 - val_loss: 8942.5791 - val_mae: 8943.2725\n",
      "Epoch 964/5000\n",
      "46/46 [==============================] - 1s 30ms/step - loss: 57.8973 - mae: 58.5750 - val_loss: 8872.8418 - val_mae: 8873.5332\n",
      "Epoch 965/5000\n",
      "46/46 [==============================] - 1s 31ms/step - loss: 53.9948 - mae: 54.6682 - val_loss: 8928.5908 - val_mae: 8929.2842\n",
      "Epoch 966/5000\n",
      "46/46 [==============================] - 1s 31ms/step - loss: 57.0141 - mae: 57.6918 - val_loss: 8929.6406 - val_mae: 8930.3330\n",
      "Epoch 967/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 1s 32ms/step - loss: 56.4971 - mae: 57.1714 - val_loss: 8957.4316 - val_mae: 8958.1260\n",
      "Epoch 968/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 55.6343 - mae: 56.3115 - val_loss: 9033.4531 - val_mae: 9034.1455\n",
      "Epoch 969/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 58.4364 - mae: 59.1170 - val_loss: 8918.6953 - val_mae: 8919.3877\n",
      "Epoch 970/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 58.4129 - mae: 59.0940 - val_loss: 8943.6377 - val_mae: 8944.3301\n",
      "Epoch 971/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 53.8769 - mae: 54.5543 - val_loss: 8798.3877 - val_mae: 8799.0820\n",
      "Epoch 972/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 51.6287 - mae: 52.3048 - val_loss: 8896.6182 - val_mae: 8897.3115\n",
      "Epoch 973/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 55.6475 - mae: 56.3295 - val_loss: 8795.9395 - val_mae: 8796.6309\n",
      "Epoch 974/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 50.3401 - mae: 51.0180 - val_loss: 8885.6494 - val_mae: 8886.3408\n",
      "Epoch 975/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 54.5689 - mae: 55.2446 - val_loss: 9021.4590 - val_mae: 9022.1523\n",
      "Epoch 976/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 53.8177 - mae: 54.4969 - val_loss: 8950.3037 - val_mae: 8950.9980\n",
      "Epoch 977/5000\n",
      "46/46 [==============================] - 3s 54ms/step - loss: 54.2059 - mae: 54.8842 - val_loss: 8937.7197 - val_mae: 8938.4111\n",
      "Epoch 978/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 52.6539 - mae: 53.3342 - val_loss: 8872.9150 - val_mae: 8873.6094\n",
      "Epoch 979/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 53.2928 - mae: 53.9690 - val_loss: 8890.0059 - val_mae: 8890.6992\n",
      "Epoch 980/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 55.6733 - mae: 56.3523 - val_loss: 9005.8496 - val_mae: 9006.5439\n",
      "Epoch 981/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 54.2276 - mae: 54.9056 - val_loss: 8945.7871 - val_mae: 8946.4795\n",
      "Epoch 982/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 49.9481 - mae: 50.6250 - val_loss: 8943.9590 - val_mae: 8944.6514\n",
      "Epoch 983/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 51.2748 - mae: 51.9523 - val_loss: 8935.7949 - val_mae: 8936.4863\n",
      "Epoch 984/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 59.7217 - mae: 60.4005 - val_loss: 8964.7939 - val_mae: 8965.4873\n",
      "Epoch 985/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 56.8080 - mae: 57.4868 - val_loss: 8976.6309 - val_mae: 8977.3242\n",
      "Epoch 986/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 52.1574 - mae: 52.8373 - val_loss: 8944.7783 - val_mae: 8945.4697\n",
      "Epoch 987/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 52.8213 - mae: 53.4972 - val_loss: 8947.1465 - val_mae: 8947.8389\n",
      "Epoch 988/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 50.0116 - mae: 50.6867 - val_loss: 8886.2715 - val_mae: 8886.9639\n",
      "Epoch 989/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 59.2121 - mae: 59.8878 - val_loss: 8900.0342 - val_mae: 8900.7275\n",
      "Epoch 990/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 51.3053 - mae: 51.9775 - val_loss: 8911.9277 - val_mae: 8912.6201\n",
      "Epoch 991/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 55.5604 - mae: 56.2423 - val_loss: 8937.1895 - val_mae: 8937.8828\n",
      "Epoch 992/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 51.1638 - mae: 51.8389 - val_loss: 8924.1641 - val_mae: 8924.8564\n",
      "Epoch 993/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 49.0800 - mae: 49.7574 - val_loss: 8985.7529 - val_mae: 8986.4482\n",
      "Epoch 994/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 55.5304 - mae: 56.2093 - val_loss: 9006.0654 - val_mae: 9006.7578\n",
      "Epoch 995/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 51.9847 - mae: 52.6629 - val_loss: 8959.5244 - val_mae: 8960.2168\n",
      "Epoch 996/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 50.7112 - mae: 51.3908 - val_loss: 8861.8193 - val_mae: 8862.5117\n",
      "Epoch 997/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 50.1630 - mae: 50.8397 - val_loss: 8980.6533 - val_mae: 8981.3467\n",
      "Epoch 998/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 54.8914 - mae: 55.5646 - val_loss: 8945.7822 - val_mae: 8946.4766\n",
      "Epoch 999/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 58.4747 - mae: 59.1539 - val_loss: 8957.2461 - val_mae: 8957.9395\n",
      "Epoch 1000/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 53.2828 - mae: 53.9567 - val_loss: 8974.3184 - val_mae: 8975.0137\n",
      "Epoch 1001/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 55.0300 - mae: 55.7055 - val_loss: 8930.4736 - val_mae: 8931.1660\n",
      "Epoch 1002/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 50.4439 - mae: 51.1155 - val_loss: 8942.6162 - val_mae: 8943.3086\n",
      "Epoch 1003/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 52.2949 - mae: 52.9702 - val_loss: 8928.9531 - val_mae: 8929.6484\n",
      "Epoch 1003: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc61c34f850>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train,Y_train, epochs=5000, batch_size=32, validation_data=(X_val,Y_val), callbacks=[earlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adf8814a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 1s 5ms/step\n",
      "18/18 [==============================] - 0s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_train_pred=regressor.predict(X_train)\n",
    "y_pred=regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.ravel()\n",
    "Y_train_pred = Y_train_pred.ravel().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train.ravel()\n",
    "Y_test = Y_test.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b0f090b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992463937917375"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for check\n",
    "r2_score(Y_train, Y_train_pred) #training score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e757ef47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2:0.36840732956924405\n"
     ]
    }
   ],
   "source": [
    "r2=r2_score(Y_test[:-30],y_pred[:-30]) #score/ r^2\n",
    "print(f'r2:{r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00ef1c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2_oos\n",
    "def r2_oos(ret, pred):\n",
    "    sum_of_sq_res = np.nansum(np.power((ret-pred), 2))\n",
    "    sum_of_sq_total = np.nansum(np.power(ret, 2))\n",
    "    \n",
    "    return 1-sum_of_sq_res/sum_of_sq_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8969a6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_oos:0.9229837433430483\n"
     ]
    }
   ],
   "source": [
    "r2_oos = r2_oos(Y_test[:-30], y_pred[:-30])\n",
    "print(f'r2_oos:{r2_oos}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70b87143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae:8796.191353258237\n",
      "rmse:10753.722330603252\n",
      "mape:27.21430715435315\n"
     ]
    }
   ],
   "source": [
    "mae=mean_absolute_error(Y_test[:-30],y_pred[:-30]) #mae\n",
    "print(f'mae:{mae}')\n",
    "\n",
    "rmse=np.sqrt(mean_squared_error(Y_test[:-30],y_pred[:-30])) #rmse\n",
    "print(f'rmse:{rmse}')\n",
    "\n",
    "mape=mean_absolute_percentage_error(Y_test[:-30],y_pred[:-30]) #mape\n",
    "print(f'mape:{mape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb36caf",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5641115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-06-01</th>\n",
       "      <td>33731.0</td>\n",
       "      <td>33262.433594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-02</th>\n",
       "      <td>33285.0</td>\n",
       "      <td>33003.417969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-03</th>\n",
       "      <td>34298.0</td>\n",
       "      <td>32665.574219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-04</th>\n",
       "      <td>35271.0</td>\n",
       "      <td>32651.976562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-05</th>\n",
       "      <td>34100.0</td>\n",
       "      <td>32141.748047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>24033.003906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>22899.986328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>23111.199219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>22990.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>22613.310547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>546 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Y_test        y_pred\n",
       "Date                             \n",
       "2021-06-01  33731.0  33262.433594\n",
       "2021-06-02  33285.0  33003.417969\n",
       "2021-06-03  34298.0  32665.574219\n",
       "2021-06-04  35271.0  32651.976562\n",
       "2021-06-05  34100.0  32141.748047\n",
       "...             ...           ...\n",
       "2022-11-24      NaN  24033.003906\n",
       "2022-11-25      NaN  22899.986328\n",
       "2022-11-26      NaN  23111.199219\n",
       "2022-11-27      NaN  22990.546875\n",
       "2022-11-28      NaN  22613.310547\n",
       "\n",
       "[546 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_df = pd.DataFrame(zip(Y_test,y_pred),columns=['Y_test','y_pred'])\n",
    "pre_df.index = tmp_index\n",
    "pre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f4bd2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df['pred_returns'] = pre_df['y_pred'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b94aa95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_test</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>pred_returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-06-01</th>\n",
       "      <td>33731.0</td>\n",
       "      <td>33262.433594</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-02</th>\n",
       "      <td>33285.0</td>\n",
       "      <td>33003.417969</td>\n",
       "      <td>-0.007787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-03</th>\n",
       "      <td>34298.0</td>\n",
       "      <td>32665.574219</td>\n",
       "      <td>-0.010237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-04</th>\n",
       "      <td>35271.0</td>\n",
       "      <td>32651.976562</td>\n",
       "      <td>-0.000416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-05</th>\n",
       "      <td>34100.0</td>\n",
       "      <td>32141.748047</td>\n",
       "      <td>-0.015626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>24033.003906</td>\n",
       "      <td>0.000415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>22899.986328</td>\n",
       "      <td>-0.047144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>23111.199219</td>\n",
       "      <td>0.009223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>22990.546875</td>\n",
       "      <td>-0.005221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>22613.310547</td>\n",
       "      <td>-0.016408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>546 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Y_test        y_pred  pred_returns\n",
       "Date                                           \n",
       "2021-06-01  33731.0  33262.433594           NaN\n",
       "2021-06-02  33285.0  33003.417969     -0.007787\n",
       "2021-06-03  34298.0  32665.574219     -0.010237\n",
       "2021-06-04  35271.0  32651.976562     -0.000416\n",
       "2021-06-05  34100.0  32141.748047     -0.015626\n",
       "...             ...           ...           ...\n",
       "2022-11-24      NaN  24033.003906      0.000415\n",
       "2022-11-25      NaN  22899.986328     -0.047144\n",
       "2022-11-26      NaN  23111.199219      0.009223\n",
       "2022-11-27      NaN  22990.546875     -0.005221\n",
       "2022-11-28      NaN  22613.310547     -0.016408\n",
       "\n",
       "[546 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d9674c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(zip(Y_test,y_pred),columns=['Y_test','y_pred']).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "732393ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df.to_csv(\"../result/LSTM/btc_NN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!kdeconnect-cli -n TAS-AN00 --ping-msg 'Script complete!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Stock Market Predictor.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "0a952188e4bab49300a5758bda39ddc90e91f41f35dfe6ea820e496e515be371"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
