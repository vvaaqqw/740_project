{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TKAxbUFku8lD"
   },
   "source": [
    "# **Dependancies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oFJOnSzBk_uB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 16:25:05.756706: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import *\n",
    "from keras.callbacks import *\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from keras.layers import *\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "22PseW2xqQET"
   },
   "source": [
    "# **Loading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = pd.read_csv(\"../Data/train_eth_selected_features.csv\")\n",
    "eth = pd.read_csv(\"../Data/ethereum_Data.csv\")\n",
    "eth['Date'] = pd.to_datetime(eth['Date'])\n",
    "eth = eth.set_index(\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2945570/2726769664.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ethData['returns'] = ethData['priceUSD'].pct_change().copy()\n"
     ]
    }
   ],
   "source": [
    "ethData = eth[selected.columns]\n",
    "ethData['returns'] = ethData['priceUSD'].pct_change().copy()\n",
    "Data = ethData.drop(columns=['priceUSD'])\n",
    "Data = Data[1:]\n",
    "# divide X and Y\n",
    "X = Data.iloc[:,0:]\n",
    "#Y = Data['returns']   # 用returns的话就用这一行，然后把下一行comment掉\n",
    "Y = ethData['priceUSD'].shift(-30)[1:] # 反之亦然\n",
    "# Split into three data sets\n",
    "X_train = X['2016-01-01':'2019-12-31']\n",
    "X_val = X['2020-01-01':'2021-05-31']\n",
    "X_test = X['2021-06-01':'2023-01-01']\n",
    "\n",
    "Y_train = Y['2016-01-01':'2019-12-31']\n",
    "Y_val = Y['2020-01-01':'2021-05-31']\n",
    "Y_test = Y['2021-06-01':'2023-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing mixmax, total=   0.0s\n",
      "[Pipeline] ............ (step 2 of 2) Processing robust, total=   0.0s\n"
     ]
    }
   ],
   "source": [
    "estimators=[]\n",
    "estimators.append(['mixmax',MinMaxScaler()])\n",
    "estimators.append(['robust',RobustScaler()])\n",
    "scale=Pipeline(estimators,verbose=True)\n",
    "scale.fit(X_train)\n",
    "X_train=scale.transform(X_train)\n",
    "X_test=scale.transform(X_test)\n",
    "X_val = scale.transform(X_val)\n",
    "tmp_index = Y_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.reshape(X_train,(X_train.shape[0],1,X_train.shape[1]))\n",
    "X_val=np.reshape(X_val,(X_val.shape[0],1,X_val.shape[1]))\n",
    "X_test=np.reshape(X_test,(X_test.shape[0],1,X_test.shape[1]))\n",
    "Y_train=Y_train.values\n",
    "Y_train=np.reshape(Y_train, (Y_train.shape[0],1,1))\n",
    "Y_val=Y_val.values\n",
    "Y_val=np.reshape(Y_val, (Y_val.shape[0],1,1))\n",
    "Y_test=Y_test.values\n",
    "Y_test=np.reshape(Y_test, (Y_test.shape[0],1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "NBZ9JgDTrHwV",
    "outputId": "40d0a5ca-682d-42d1-e08b-fd28df246868"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spectre/anaconda3/envs/tensorplustorch/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "adam=optimizers.Adam(lr=lr_schedule(0),amsgrad=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://medium.com/analytics-vidhya/hypertuning-a-lstm-with-keras-tuner-to-forecast-solar-irradiance-7da7577e96eb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 16:25:06.904101: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-04 16:25:06.905244: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "regressor = Sequential()\n",
    "regressor.add(Bidirectional(LSTM(350, return_sequences=True, activation='relu'), input_shape=(1, X_train.shape[2])))\n",
    "regressor.add(Bidirectional(LSTM(350, return_sequences=True, activation='relu')))\n",
    "regressor.add(Dense(1))\n",
    "regressor.compile(loss=\"logcosh\", optimizer=adam, metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0WWSdc7AxKV6"
   },
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=1000, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "46/46 [==============================] - 5s 54ms/step - loss: 205.3097 - mae: 205.9992 - val_loss: 479.2905 - val_mae: 479.9822\n",
      "Epoch 2/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 158.1485 - mae: 158.8334 - val_loss: 997.7256 - val_mae: 998.4182\n",
      "Epoch 3/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 98.0582 - mae: 98.7398 - val_loss: 1660.2296 - val_mae: 1660.9224\n",
      "Epoch 4/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 71.2730 - mae: 71.9533 - val_loss: 1630.1525 - val_mae: 1630.8455\n",
      "Epoch 5/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 58.2023 - mae: 58.8785 - val_loss: 1540.8849 - val_mae: 1541.5769\n",
      "Epoch 6/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 54.7877 - mae: 55.4644 - val_loss: 1422.1608 - val_mae: 1422.8524\n",
      "Epoch 7/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 51.3169 - mae: 51.9895 - val_loss: 1208.2787 - val_mae: 1208.9716\n",
      "Epoch 8/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 47.5831 - mae: 48.2563 - val_loss: 1078.1534 - val_mae: 1078.8447\n",
      "Epoch 9/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 45.4003 - mae: 46.0682 - val_loss: 1029.6260 - val_mae: 1030.3185\n",
      "Epoch 10/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 43.8076 - mae: 44.4742 - val_loss: 819.5009 - val_mae: 820.1929\n",
      "Epoch 11/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 41.7006 - mae: 42.3689 - val_loss: 836.8078 - val_mae: 837.5009\n",
      "Epoch 12/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 40.7187 - mae: 41.3880 - val_loss: 735.4263 - val_mae: 736.1180\n",
      "Epoch 13/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 40.0604 - mae: 40.7256 - val_loss: 580.3235 - val_mae: 581.0161\n",
      "Epoch 14/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 38.7980 - mae: 39.4625 - val_loss: 494.0187 - val_mae: 494.7086\n",
      "Epoch 15/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 37.0993 - mae: 37.7621 - val_loss: 500.6397 - val_mae: 501.3321\n",
      "Epoch 16/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 36.3636 - mae: 37.0261 - val_loss: 388.4067 - val_mae: 389.0962\n",
      "Epoch 17/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 36.5813 - mae: 37.2450 - val_loss: 368.8503 - val_mae: 369.5391\n",
      "Epoch 18/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 33.6529 - mae: 34.3101 - val_loss: 346.3866 - val_mae: 347.0787\n",
      "Epoch 19/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 32.9309 - mae: 33.5838 - val_loss: 356.9079 - val_mae: 357.6004\n",
      "Epoch 20/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 33.4723 - mae: 34.1300 - val_loss: 351.8988 - val_mae: 352.5898\n",
      "Epoch 21/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 31.6394 - mae: 32.2910 - val_loss: 359.9099 - val_mae: 360.6013\n",
      "Epoch 22/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 30.1787 - mae: 30.8281 - val_loss: 365.5305 - val_mae: 366.2225\n",
      "Epoch 23/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 29.7676 - mae: 30.4191 - val_loss: 382.8997 - val_mae: 383.5906\n",
      "Epoch 24/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 29.3596 - mae: 30.0096 - val_loss: 443.0616 - val_mae: 443.7510\n",
      "Epoch 25/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 29.7191 - mae: 30.3708 - val_loss: 429.3908 - val_mae: 430.0818\n",
      "Epoch 26/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 28.3534 - mae: 28.9982 - val_loss: 459.2830 - val_mae: 459.9730\n",
      "Epoch 27/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 27.4218 - mae: 28.0689 - val_loss: 452.7764 - val_mae: 453.4665\n",
      "Epoch 28/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 26.9547 - mae: 27.5984 - val_loss: 492.0983 - val_mae: 492.7883\n",
      "Epoch 29/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 25.9118 - mae: 26.5541 - val_loss: 564.0875 - val_mae: 564.7802\n",
      "Epoch 30/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 25.6636 - mae: 26.3122 - val_loss: 528.2064 - val_mae: 528.8967\n",
      "Epoch 31/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 25.1273 - mae: 25.7667 - val_loss: 592.9367 - val_mae: 593.6282\n",
      "Epoch 32/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 24.3449 - mae: 24.9854 - val_loss: 606.8104 - val_mae: 607.5025\n",
      "Epoch 33/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 24.7518 - mae: 25.4023 - val_loss: 633.4058 - val_mae: 634.0972\n",
      "Epoch 34/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 23.7077 - mae: 24.3478 - val_loss: 518.7734 - val_mae: 519.4663\n",
      "Epoch 35/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 23.9254 - mae: 24.5612 - val_loss: 636.5274 - val_mae: 637.2180\n",
      "Epoch 36/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 23.4879 - mae: 24.1362 - val_loss: 637.5208 - val_mae: 638.2136\n",
      "Epoch 37/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 22.2720 - mae: 22.9116 - val_loss: 665.5359 - val_mae: 666.2262\n",
      "Epoch 38/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 22.2967 - mae: 22.9376 - val_loss: 670.5346 - val_mae: 671.2268\n",
      "Epoch 39/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 21.4283 - mae: 22.0644 - val_loss: 661.8638 - val_mae: 662.5561\n",
      "Epoch 40/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 21.5415 - mae: 22.1835 - val_loss: 649.1149 - val_mae: 649.8073\n",
      "Epoch 41/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 21.5420 - mae: 22.1835 - val_loss: 639.5443 - val_mae: 640.2361\n",
      "Epoch 42/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 21.0845 - mae: 21.7195 - val_loss: 705.3046 - val_mae: 705.9962\n",
      "Epoch 43/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 21.2777 - mae: 21.9219 - val_loss: 640.9186 - val_mae: 641.6104\n",
      "Epoch 44/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 20.3763 - mae: 21.0157 - val_loss: 639.1666 - val_mae: 639.8590\n",
      "Epoch 45/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 20.1161 - mae: 20.7537 - val_loss: 677.7653 - val_mae: 678.4568\n",
      "Epoch 46/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 19.8500 - mae: 20.4833 - val_loss: 667.4356 - val_mae: 668.1271\n",
      "Epoch 47/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 20.1925 - mae: 20.8279 - val_loss: 613.0966 - val_mae: 613.7877\n",
      "Epoch 48/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 19.3493 - mae: 19.9810 - val_loss: 653.5606 - val_mae: 654.2499\n",
      "Epoch 49/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 19.2102 - mae: 19.8415 - val_loss: 682.8792 - val_mae: 683.5705\n",
      "Epoch 50/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 19.1697 - mae: 19.8006 - val_loss: 660.5732 - val_mae: 661.2642\n",
      "Epoch 51/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 18.4463 - mae: 19.0752 - val_loss: 635.7353 - val_mae: 636.4277\n",
      "Epoch 52/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 18.7676 - mae: 19.3968 - val_loss: 646.6619 - val_mae: 647.3515\n",
      "Epoch 53/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 18.9416 - mae: 19.5801 - val_loss: 644.5169 - val_mae: 645.2085\n",
      "Epoch 54/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 18.3205 - mae: 18.9476 - val_loss: 633.8987 - val_mae: 634.5894\n",
      "Epoch 55/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 18.4782 - mae: 19.1160 - val_loss: 683.3021 - val_mae: 683.9907\n",
      "Epoch 56/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 17.8611 - mae: 18.4889 - val_loss: 636.9459 - val_mae: 637.6372\n",
      "Epoch 57/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 17.8585 - mae: 18.4843 - val_loss: 651.0436 - val_mae: 651.7353\n",
      "Epoch 58/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 17.2747 - mae: 17.9016 - val_loss: 626.1335 - val_mae: 626.8253\n",
      "Epoch 59/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 45ms/step - loss: 17.2263 - mae: 17.8516 - val_loss: 641.7980 - val_mae: 642.4904\n",
      "Epoch 60/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 17.1174 - mae: 17.7491 - val_loss: 640.7739 - val_mae: 641.4646\n",
      "Epoch 61/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 17.2991 - mae: 17.9266 - val_loss: 626.3276 - val_mae: 627.0182\n",
      "Epoch 62/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 16.8465 - mae: 17.4741 - val_loss: 650.7587 - val_mae: 651.4501\n",
      "Epoch 63/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 17.2927 - mae: 17.9235 - val_loss: 650.7735 - val_mae: 651.4652\n",
      "Epoch 64/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 16.2040 - mae: 16.8229 - val_loss: 631.3648 - val_mae: 632.0570\n",
      "Epoch 65/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 16.9102 - mae: 17.5354 - val_loss: 641.4578 - val_mae: 642.1492\n",
      "Epoch 66/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 16.8191 - mae: 17.4437 - val_loss: 647.7761 - val_mae: 648.4676\n",
      "Epoch 67/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 16.1600 - mae: 16.7804 - val_loss: 663.9651 - val_mae: 664.6553\n",
      "Epoch 68/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 16.3325 - mae: 16.9571 - val_loss: 656.8463 - val_mae: 657.5377\n",
      "Epoch 69/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 15.8947 - mae: 16.5121 - val_loss: 659.2112 - val_mae: 659.9034\n",
      "Epoch 70/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 15.5534 - mae: 16.1711 - val_loss: 660.4347 - val_mae: 661.1251\n",
      "Epoch 71/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 15.4915 - mae: 16.1106 - val_loss: 614.7173 - val_mae: 615.4083\n",
      "Epoch 72/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 15.5758 - mae: 16.1933 - val_loss: 641.2421 - val_mae: 641.9349\n",
      "Epoch 73/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 15.3906 - mae: 16.0109 - val_loss: 678.9984 - val_mae: 679.6899\n",
      "Epoch 74/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 15.1529 - mae: 15.7738 - val_loss: 649.8132 - val_mae: 650.5034\n",
      "Epoch 75/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 15.5260 - mae: 16.1446 - val_loss: 634.6425 - val_mae: 635.3353\n",
      "Epoch 76/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 16.1902 - mae: 16.8163 - val_loss: 608.9692 - val_mae: 609.6603\n",
      "Epoch 77/5000\n",
      "46/46 [==============================] - 2s 33ms/step - loss: 15.0339 - mae: 15.6532 - val_loss: 628.3277 - val_mae: 629.0189\n",
      "Epoch 78/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 15.6441 - mae: 16.2615 - val_loss: 648.9980 - val_mae: 649.6896\n",
      "Epoch 79/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 14.6778 - mae: 15.3023 - val_loss: 669.2277 - val_mae: 669.9160\n",
      "Epoch 80/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 15.1787 - mae: 15.7992 - val_loss: 620.6091 - val_mae: 621.3019\n",
      "Epoch 81/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 14.0355 - mae: 14.6485 - val_loss: 655.9781 - val_mae: 656.6699\n",
      "Epoch 82/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 14.9961 - mae: 15.6233 - val_loss: 619.7778 - val_mae: 620.4676\n",
      "Epoch 83/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 14.9303 - mae: 15.5455 - val_loss: 688.6888 - val_mae: 689.3792\n",
      "Epoch 84/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 15.3932 - mae: 16.0197 - val_loss: 603.2117 - val_mae: 603.9022\n",
      "Epoch 85/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 14.5269 - mae: 15.1356 - val_loss: 616.3066 - val_mae: 616.9953\n",
      "Epoch 86/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 14.4391 - mae: 15.0555 - val_loss: 628.6044 - val_mae: 629.2960\n",
      "Epoch 87/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 13.9514 - mae: 14.5695 - val_loss: 651.9898 - val_mae: 652.6809\n",
      "Epoch 88/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 14.1861 - mae: 14.8071 - val_loss: 603.4398 - val_mae: 604.1328\n",
      "Epoch 89/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 15.1424 - mae: 15.7639 - val_loss: 580.9443 - val_mae: 581.6338\n",
      "Epoch 90/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 14.5791 - mae: 15.1948 - val_loss: 602.9600 - val_mae: 603.6517\n",
      "Epoch 91/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 13.9715 - mae: 14.5835 - val_loss: 587.4656 - val_mae: 588.1554\n",
      "Epoch 92/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 13.6343 - mae: 14.2525 - val_loss: 631.0913 - val_mae: 631.7833\n",
      "Epoch 93/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 13.9395 - mae: 14.5677 - val_loss: 624.4588 - val_mae: 625.1511\n",
      "Epoch 94/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 14.1182 - mae: 14.7339 - val_loss: 627.5621 - val_mae: 628.2537\n",
      "Epoch 95/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 13.8375 - mae: 14.4509 - val_loss: 665.0300 - val_mae: 665.7216\n",
      "Epoch 96/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 13.4023 - mae: 14.0169 - val_loss: 602.3977 - val_mae: 603.0897\n",
      "Epoch 97/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 12.9044 - mae: 13.5058 - val_loss: 638.9719 - val_mae: 639.6635\n",
      "Epoch 98/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 12.7328 - mae: 13.3492 - val_loss: 628.8180 - val_mae: 629.5088\n",
      "Epoch 99/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 13.2465 - mae: 13.8611 - val_loss: 624.8856 - val_mae: 625.5764\n",
      "Epoch 100/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 13.1446 - mae: 13.7525 - val_loss: 665.0703 - val_mae: 665.7628\n",
      "Epoch 101/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 13.3581 - mae: 13.9704 - val_loss: 678.3153 - val_mae: 679.0072\n",
      "Epoch 102/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 14.4877 - mae: 15.1030 - val_loss: 642.8898 - val_mae: 643.5806\n",
      "Epoch 103/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 13.0850 - mae: 13.6932 - val_loss: 657.3167 - val_mae: 658.0092\n",
      "Epoch 104/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 13.3964 - mae: 14.0058 - val_loss: 662.2490 - val_mae: 662.9407\n",
      "Epoch 105/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 13.1256 - mae: 13.7345 - val_loss: 654.5739 - val_mae: 655.2662\n",
      "Epoch 106/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 12.2070 - mae: 12.8182 - val_loss: 650.0254 - val_mae: 650.7153\n",
      "Epoch 107/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 12.4153 - mae: 13.0123 - val_loss: 613.4210 - val_mae: 614.1116\n",
      "Epoch 108/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 12.4920 - mae: 13.1071 - val_loss: 620.9440 - val_mae: 621.6349\n",
      "Epoch 109/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 12.1771 - mae: 12.7817 - val_loss: 641.8355 - val_mae: 642.5258\n",
      "Epoch 110/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 11.8606 - mae: 12.4671 - val_loss: 646.2868 - val_mae: 646.9755\n",
      "Epoch 111/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 11.9274 - mae: 12.5280 - val_loss: 655.8434 - val_mae: 656.5321\n",
      "Epoch 112/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 12.6153 - mae: 13.2165 - val_loss: 605.3059 - val_mae: 605.9951\n",
      "Epoch 113/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 12.1788 - mae: 12.7841 - val_loss: 667.8666 - val_mae: 668.5547\n",
      "Epoch 114/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 12.1508 - mae: 12.7683 - val_loss: 654.4877 - val_mae: 655.1791\n",
      "Epoch 115/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 12.4835 - mae: 13.0888 - val_loss: 601.9205 - val_mae: 602.6114\n",
      "Epoch 116/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 12.3022 - mae: 12.9100 - val_loss: 601.4507 - val_mae: 602.1412\n",
      "Epoch 117/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 36ms/step - loss: 12.1938 - mae: 12.7959 - val_loss: 625.9512 - val_mae: 626.6435\n",
      "Epoch 118/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 11.9436 - mae: 12.5461 - val_loss: 620.1013 - val_mae: 620.7908\n",
      "Epoch 119/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 11.7500 - mae: 12.3575 - val_loss: 631.4391 - val_mae: 632.1304\n",
      "Epoch 120/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 12.0772 - mae: 12.6843 - val_loss: 625.8458 - val_mae: 626.5385\n",
      "Epoch 121/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 11.2984 - mae: 11.9007 - val_loss: 630.6619 - val_mae: 631.3535\n",
      "Epoch 122/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 11.5702 - mae: 12.1725 - val_loss: 639.0504 - val_mae: 639.7435\n",
      "Epoch 123/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 11.6381 - mae: 12.2429 - val_loss: 608.6068 - val_mae: 609.2996\n",
      "Epoch 124/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 11.7304 - mae: 12.3337 - val_loss: 598.9699 - val_mae: 599.6608\n",
      "Epoch 125/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 11.6198 - mae: 12.2167 - val_loss: 612.3110 - val_mae: 613.0020\n",
      "Epoch 126/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 12.0394 - mae: 12.6433 - val_loss: 640.3551 - val_mae: 641.0472\n",
      "Epoch 127/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 11.1874 - mae: 11.7895 - val_loss: 637.5344 - val_mae: 638.2271\n",
      "Epoch 128/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 11.5891 - mae: 12.1906 - val_loss: 609.6907 - val_mae: 610.3830\n",
      "Epoch 129/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 11.3719 - mae: 11.9752 - val_loss: 606.1873 - val_mae: 606.8760\n",
      "Epoch 130/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 11.3083 - mae: 11.9137 - val_loss: 613.3945 - val_mae: 614.0845\n",
      "Epoch 131/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 11.2422 - mae: 11.8415 - val_loss: 659.0627 - val_mae: 659.7540\n",
      "Epoch 132/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 11.6731 - mae: 12.2820 - val_loss: 647.7859 - val_mae: 648.4778\n",
      "Epoch 133/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 11.4900 - mae: 12.0925 - val_loss: 645.2112 - val_mae: 645.9038\n",
      "Epoch 134/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 11.2942 - mae: 11.8959 - val_loss: 649.4543 - val_mae: 650.1464\n",
      "Epoch 135/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 10.8932 - mae: 11.4994 - val_loss: 658.6871 - val_mae: 659.3786\n",
      "Epoch 136/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 10.6649 - mae: 11.2694 - val_loss: 648.1917 - val_mae: 648.8833\n",
      "Epoch 137/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 11.3998 - mae: 11.9994 - val_loss: 623.3469 - val_mae: 624.0372\n",
      "Epoch 138/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 11.1090 - mae: 11.7092 - val_loss: 653.5494 - val_mae: 654.2413\n",
      "Epoch 139/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 11.2305 - mae: 11.8308 - val_loss: 665.9212 - val_mae: 666.6120\n",
      "Epoch 140/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 10.5703 - mae: 11.1644 - val_loss: 667.0046 - val_mae: 667.6966\n",
      "Epoch 141/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 10.5036 - mae: 11.1018 - val_loss: 652.9460 - val_mae: 653.6371\n",
      "Epoch 142/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 10.5045 - mae: 11.1007 - val_loss: 662.9545 - val_mae: 663.6465\n",
      "Epoch 143/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 10.3924 - mae: 10.9920 - val_loss: 682.5143 - val_mae: 683.2048\n",
      "Epoch 144/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 10.8456 - mae: 11.4484 - val_loss: 681.1465 - val_mae: 681.8384\n",
      "Epoch 145/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 10.4593 - mae: 11.0557 - val_loss: 642.7706 - val_mae: 643.4628\n",
      "Epoch 146/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 10.7163 - mae: 11.3204 - val_loss: 691.3191 - val_mae: 692.0120\n",
      "Epoch 147/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 10.3797 - mae: 10.9798 - val_loss: 681.7543 - val_mae: 682.4454\n",
      "Epoch 148/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 10.8954 - mae: 11.4902 - val_loss: 716.9819 - val_mae: 717.6733\n",
      "Epoch 149/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 10.1483 - mae: 10.7376 - val_loss: 672.8222 - val_mae: 673.5131\n",
      "Epoch 150/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 10.0273 - mae: 10.6195 - val_loss: 689.0858 - val_mae: 689.7750\n",
      "Epoch 151/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 10.3293 - mae: 10.9406 - val_loss: 672.1379 - val_mae: 672.8296\n",
      "Epoch 152/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 9.6828 - mae: 10.2758 - val_loss: 672.2861 - val_mae: 672.9781\n",
      "Epoch 153/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 10.2546 - mae: 10.8478 - val_loss: 677.2129 - val_mae: 677.9041\n",
      "Epoch 154/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 9.6698 - mae: 10.2652 - val_loss: 667.5451 - val_mae: 668.2371\n",
      "Epoch 155/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 10.5447 - mae: 11.1374 - val_loss: 674.1840 - val_mae: 674.8770\n",
      "Epoch 156/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 10.3496 - mae: 10.9474 - val_loss: 657.8588 - val_mae: 658.5505\n",
      "Epoch 157/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 10.2122 - mae: 10.8004 - val_loss: 660.7128 - val_mae: 661.4045\n",
      "Epoch 158/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 9.9105 - mae: 10.5126 - val_loss: 685.9252 - val_mae: 686.6180\n",
      "Epoch 159/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 10.2475 - mae: 10.8450 - val_loss: 682.8497 - val_mae: 683.5421\n",
      "Epoch 160/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 10.3749 - mae: 10.9749 - val_loss: 684.4236 - val_mae: 685.1145\n",
      "Epoch 161/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 10.8599 - mae: 11.4515 - val_loss: 691.9156 - val_mae: 692.6081\n",
      "Epoch 162/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 10.2379 - mae: 10.8496 - val_loss: 687.8413 - val_mae: 688.5319\n",
      "Epoch 163/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 10.2238 - mae: 10.8224 - val_loss: 679.7788 - val_mae: 680.4697\n",
      "Epoch 164/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 10.3703 - mae: 10.9674 - val_loss: 685.4304 - val_mae: 686.1215\n",
      "Epoch 165/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 9.1029 - mae: 9.6908 - val_loss: 661.5971 - val_mae: 662.2888\n",
      "Epoch 166/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 9.4352 - mae: 10.0256 - val_loss: 667.6575 - val_mae: 668.3502\n",
      "Epoch 167/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 9.9224 - mae: 10.5179 - val_loss: 689.1077 - val_mae: 689.8007\n",
      "Epoch 168/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 9.5825 - mae: 10.1737 - val_loss: 704.4563 - val_mae: 705.1484\n",
      "Epoch 169/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 9.6675 - mae: 10.2554 - val_loss: 709.3788 - val_mae: 710.0710\n",
      "Epoch 170/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 9.2193 - mae: 9.8104 - val_loss: 702.5571 - val_mae: 703.2497\n",
      "Epoch 171/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 9.5744 - mae: 10.1664 - val_loss: 706.0364 - val_mae: 706.7280\n",
      "Epoch 172/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 9.4374 - mae: 10.0246 - val_loss: 679.2861 - val_mae: 679.9773\n",
      "Epoch 173/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 8.9950 - mae: 9.5807 - val_loss: 705.5854 - val_mae: 706.2766\n",
      "Epoch 174/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 9.1100 - mae: 9.6971 - val_loss: 687.9662 - val_mae: 688.6580\n",
      "Epoch 175/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 43ms/step - loss: 9.8147 - mae: 10.4043 - val_loss: 664.8485 - val_mae: 665.5389\n",
      "Epoch 176/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 9.6749 - mae: 10.2705 - val_loss: 685.8866 - val_mae: 686.5784\n",
      "Epoch 177/5000\n",
      "46/46 [==============================] - 3s 62ms/step - loss: 9.4890 - mae: 10.0793 - val_loss: 701.1275 - val_mae: 701.8192\n",
      "Epoch 178/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 9.1611 - mae: 9.7486 - val_loss: 700.5168 - val_mae: 701.2078\n",
      "Epoch 179/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 9.2060 - mae: 9.7910 - val_loss: 688.4312 - val_mae: 689.1229\n",
      "Epoch 180/5000\n",
      "46/46 [==============================] - 2s 33ms/step - loss: 8.9157 - mae: 9.4940 - val_loss: 682.8079 - val_mae: 683.4991\n",
      "Epoch 181/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 9.4448 - mae: 10.0363 - val_loss: 697.3322 - val_mae: 698.0237\n",
      "Epoch 182/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 9.2214 - mae: 9.8145 - val_loss: 710.5402 - val_mae: 711.2319\n",
      "Epoch 183/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 8.9565 - mae: 9.5450 - val_loss: 683.3853 - val_mae: 684.0771\n",
      "Epoch 184/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 8.7241 - mae: 9.3142 - val_loss: 690.6699 - val_mae: 691.3617\n",
      "Epoch 185/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 8.7322 - mae: 9.3190 - val_loss: 680.8079 - val_mae: 681.4990\n",
      "Epoch 186/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 8.7648 - mae: 9.3466 - val_loss: 712.8951 - val_mae: 713.5872\n",
      "Epoch 187/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 8.9524 - mae: 9.5565 - val_loss: 705.4028 - val_mae: 706.0950\n",
      "Epoch 188/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 9.2686 - mae: 9.8646 - val_loss: 693.2316 - val_mae: 693.9230\n",
      "Epoch 189/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 8.6158 - mae: 9.2048 - val_loss: 691.6480 - val_mae: 692.3410\n",
      "Epoch 190/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 8.5355 - mae: 9.1205 - val_loss: 674.7461 - val_mae: 675.4385\n",
      "Epoch 191/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 8.5286 - mae: 9.1136 - val_loss: 698.3889 - val_mae: 699.0797\n",
      "Epoch 192/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 8.7855 - mae: 9.3713 - val_loss: 697.2288 - val_mae: 697.9207\n",
      "Epoch 193/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 8.8453 - mae: 9.4335 - val_loss: 678.0604 - val_mae: 678.7534\n",
      "Epoch 194/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 8.9887 - mae: 9.5771 - val_loss: 732.1187 - val_mae: 732.8109\n",
      "Epoch 195/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 8.6973 - mae: 9.2863 - val_loss: 697.1148 - val_mae: 697.8058\n",
      "Epoch 196/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 8.5906 - mae: 9.1770 - val_loss: 702.7192 - val_mae: 703.4117\n",
      "Epoch 197/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 8.5122 - mae: 9.1021 - val_loss: 710.0270 - val_mae: 710.7189\n",
      "Epoch 198/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 8.5973 - mae: 9.1832 - val_loss: 702.8531 - val_mae: 703.5450\n",
      "Epoch 199/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 8.3454 - mae: 8.9356 - val_loss: 693.5091 - val_mae: 694.2009\n",
      "Epoch 200/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 8.3373 - mae: 8.9190 - val_loss: 697.7321 - val_mae: 698.4245\n",
      "Epoch 201/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 8.3521 - mae: 8.9376 - val_loss: 708.6479 - val_mae: 709.3383\n",
      "Epoch 202/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 7.9902 - mae: 8.5850 - val_loss: 702.2868 - val_mae: 702.9781\n",
      "Epoch 203/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 8.5267 - mae: 9.1061 - val_loss: 692.9302 - val_mae: 693.6225\n",
      "Epoch 204/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 8.0762 - mae: 8.6482 - val_loss: 708.6450 - val_mae: 709.3370\n",
      "Epoch 205/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 8.3127 - mae: 8.9008 - val_loss: 700.1008 - val_mae: 700.7935\n",
      "Epoch 206/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 8.2177 - mae: 8.8102 - val_loss: 701.0032 - val_mae: 701.6951\n",
      "Epoch 207/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 8.2234 - mae: 8.8073 - val_loss: 708.1198 - val_mae: 708.8127\n",
      "Epoch 208/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 7.9969 - mae: 8.5787 - val_loss: 697.3709 - val_mae: 698.0627\n",
      "Epoch 209/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 8.3284 - mae: 8.9137 - val_loss: 703.4731 - val_mae: 704.1649\n",
      "Epoch 210/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 8.2410 - mae: 8.8201 - val_loss: 690.9662 - val_mae: 691.6578\n",
      "Epoch 211/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 8.0816 - mae: 8.6679 - val_loss: 725.0292 - val_mae: 725.7216\n",
      "Epoch 212/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 7.9651 - mae: 8.5473 - val_loss: 697.2838 - val_mae: 697.9767\n",
      "Epoch 213/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 7.6344 - mae: 8.2122 - val_loss: 701.2793 - val_mae: 701.9721\n",
      "Epoch 214/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 8.3254 - mae: 8.9133 - val_loss: 698.4619 - val_mae: 699.1525\n",
      "Epoch 215/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 8.2065 - mae: 8.7971 - val_loss: 673.5580 - val_mae: 674.2507\n",
      "Epoch 216/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 7.9362 - mae: 8.5152 - val_loss: 714.4483 - val_mae: 715.1406\n",
      "Epoch 217/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 7.7962 - mae: 8.3860 - val_loss: 714.2711 - val_mae: 714.9622\n",
      "Epoch 218/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 7.5539 - mae: 8.1290 - val_loss: 710.0845 - val_mae: 710.7755\n",
      "Epoch 219/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 7.5339 - mae: 8.1092 - val_loss: 706.8912 - val_mae: 707.5839\n",
      "Epoch 220/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 8.0259 - mae: 8.6083 - val_loss: 708.4233 - val_mae: 709.1143\n",
      "Epoch 221/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 7.5418 - mae: 8.1352 - val_loss: 712.9124 - val_mae: 713.6051\n",
      "Epoch 222/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 7.5038 - mae: 8.0817 - val_loss: 696.2333 - val_mae: 696.9260\n",
      "Epoch 223/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 7.5160 - mae: 8.0931 - val_loss: 710.4628 - val_mae: 711.1547\n",
      "Epoch 224/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 7.9260 - mae: 8.5063 - val_loss: 720.7307 - val_mae: 721.4224\n",
      "Epoch 225/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 7.4612 - mae: 8.0384 - val_loss: 723.3252 - val_mae: 724.0168\n",
      "Epoch 226/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 7.8194 - mae: 8.3953 - val_loss: 720.2495 - val_mae: 720.9412\n",
      "Epoch 227/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 8.0369 - mae: 8.6134 - val_loss: 711.9805 - val_mae: 712.6725\n",
      "Epoch 228/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 7.8370 - mae: 8.4142 - val_loss: 714.7061 - val_mae: 715.3977\n",
      "Epoch 229/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 7.1734 - mae: 7.7498 - val_loss: 738.8647 - val_mae: 739.5567\n",
      "Epoch 230/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 7.1958 - mae: 7.7785 - val_loss: 711.4167 - val_mae: 712.1062\n",
      "Epoch 231/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 7.2785 - mae: 7.8531 - val_loss: 720.9454 - val_mae: 721.6378\n",
      "Epoch 232/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 8.1031 - mae: 8.6931 - val_loss: 693.6176 - val_mae: 694.3096\n",
      "Epoch 233/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 7.4954 - mae: 8.0734 - val_loss: 695.0279 - val_mae: 695.7187\n",
      "Epoch 234/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 37ms/step - loss: 7.5299 - mae: 8.1135 - val_loss: 713.5746 - val_mae: 714.2656\n",
      "Epoch 235/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 7.8797 - mae: 8.4681 - val_loss: 707.3416 - val_mae: 708.0337\n",
      "Epoch 236/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 7.1552 - mae: 7.7270 - val_loss: 714.4093 - val_mae: 715.1011\n",
      "Epoch 237/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 6.9845 - mae: 7.5529 - val_loss: 713.2850 - val_mae: 713.9752\n",
      "Epoch 238/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 6.8686 - mae: 7.4454 - val_loss: 711.8165 - val_mae: 712.5087\n",
      "Epoch 239/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 7.4044 - mae: 7.9823 - val_loss: 690.2474 - val_mae: 690.9388\n",
      "Epoch 240/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 8.0303 - mae: 8.6083 - val_loss: 713.0116 - val_mae: 713.7027\n",
      "Epoch 241/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 7.1001 - mae: 7.6714 - val_loss: 718.2079 - val_mae: 718.8994\n",
      "Epoch 242/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 7.3867 - mae: 7.9614 - val_loss: 711.2466 - val_mae: 711.9385\n",
      "Epoch 243/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 7.0180 - mae: 7.5957 - val_loss: 720.5350 - val_mae: 721.2273\n",
      "Epoch 244/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 6.9480 - mae: 7.5161 - val_loss: 717.2693 - val_mae: 717.9618\n",
      "Epoch 245/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 6.7981 - mae: 7.3738 - val_loss: 734.3502 - val_mae: 735.0423\n",
      "Epoch 246/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 7.2619 - mae: 7.8354 - val_loss: 696.4642 - val_mae: 697.1555\n",
      "Epoch 247/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 7.0374 - mae: 7.6081 - val_loss: 692.3021 - val_mae: 692.9950\n",
      "Epoch 248/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 6.6907 - mae: 7.2665 - val_loss: 728.9009 - val_mae: 729.5941\n",
      "Epoch 249/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 6.7347 - mae: 7.3118 - val_loss: 713.1959 - val_mae: 713.8872\n",
      "Epoch 250/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 7.0319 - mae: 7.6098 - val_loss: 743.6953 - val_mae: 744.3856\n",
      "Epoch 251/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 6.4139 - mae: 6.9798 - val_loss: 724.3395 - val_mae: 725.0312\n",
      "Epoch 252/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 6.7688 - mae: 7.3380 - val_loss: 742.4711 - val_mae: 743.1634\n",
      "Epoch 253/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 6.8327 - mae: 7.4020 - val_loss: 727.3817 - val_mae: 728.0726\n",
      "Epoch 254/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 6.4593 - mae: 7.0165 - val_loss: 732.8456 - val_mae: 733.5369\n",
      "Epoch 255/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 6.6426 - mae: 7.2147 - val_loss: 712.2261 - val_mae: 712.9160\n",
      "Epoch 256/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 6.3507 - mae: 6.9191 - val_loss: 726.1271 - val_mae: 726.8182\n",
      "Epoch 257/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 6.9640 - mae: 7.5406 - val_loss: 720.9564 - val_mae: 721.6472\n",
      "Epoch 258/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 6.5357 - mae: 7.1052 - val_loss: 705.9814 - val_mae: 706.6722\n",
      "Epoch 259/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 6.9428 - mae: 7.5118 - val_loss: 722.5897 - val_mae: 723.2816\n",
      "Epoch 260/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 6.4441 - mae: 7.0016 - val_loss: 719.1672 - val_mae: 719.8580\n",
      "Epoch 261/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 7.2167 - mae: 7.7851 - val_loss: 744.9572 - val_mae: 745.6497\n",
      "Epoch 262/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 6.3323 - mae: 6.8944 - val_loss: 725.0027 - val_mae: 725.6954\n",
      "Epoch 263/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 6.3326 - mae: 6.8973 - val_loss: 751.4797 - val_mae: 752.1715\n",
      "Epoch 264/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 6.8293 - mae: 7.4162 - val_loss: 733.9417 - val_mae: 734.6336\n",
      "Epoch 265/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 6.9879 - mae: 7.5685 - val_loss: 733.3515 - val_mae: 734.0441\n",
      "Epoch 266/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 6.4481 - mae: 7.0048 - val_loss: 731.2615 - val_mae: 731.9539\n",
      "Epoch 267/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 6.6443 - mae: 7.2127 - val_loss: 731.0750 - val_mae: 731.7681\n",
      "Epoch 268/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 6.9121 - mae: 7.4789 - val_loss: 726.4141 - val_mae: 727.1062\n",
      "Epoch 269/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5.9670 - mae: 6.5385 - val_loss: 726.3708 - val_mae: 727.0639\n",
      "Epoch 270/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 7.1007 - mae: 7.6683 - val_loss: 714.1523 - val_mae: 714.8423\n",
      "Epoch 271/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 6.9454 - mae: 7.5281 - val_loss: 733.9615 - val_mae: 734.6530\n",
      "Epoch 272/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 6.5633 - mae: 7.1314 - val_loss: 745.8724 - val_mae: 746.5646\n",
      "Epoch 273/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 6.3877 - mae: 6.9529 - val_loss: 725.0032 - val_mae: 725.6962\n",
      "Epoch 274/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 6.5191 - mae: 7.0851 - val_loss: 737.6735 - val_mae: 738.3663\n",
      "Epoch 275/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 6.3454 - mae: 6.9074 - val_loss: 736.9797 - val_mae: 737.6711\n",
      "Epoch 276/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 6.4746 - mae: 7.0438 - val_loss: 737.6700 - val_mae: 738.3627\n",
      "Epoch 277/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 6.1914 - mae: 6.7622 - val_loss: 739.2884 - val_mae: 739.9809\n",
      "Epoch 278/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 6.1902 - mae: 6.7537 - val_loss: 735.9836 - val_mae: 736.6763\n",
      "Epoch 279/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 6.2810 - mae: 6.8501 - val_loss: 745.6664 - val_mae: 746.3583\n",
      "Epoch 280/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 6.1370 - mae: 6.7129 - val_loss: 743.5343 - val_mae: 744.2271\n",
      "Epoch 281/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 6.3481 - mae: 6.9130 - val_loss: 722.0834 - val_mae: 722.7749\n",
      "Epoch 282/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 6.4223 - mae: 6.9893 - val_loss: 740.6367 - val_mae: 741.3283\n",
      "Epoch 283/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5.8470 - mae: 6.4066 - val_loss: 722.9341 - val_mae: 723.6271\n",
      "Epoch 284/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5.9618 - mae: 6.5244 - val_loss: 723.5818 - val_mae: 724.2737\n",
      "Epoch 285/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5.8753 - mae: 6.4415 - val_loss: 729.3047 - val_mae: 729.9976\n",
      "Epoch 286/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 6.0213 - mae: 6.5920 - val_loss: 717.1949 - val_mae: 717.8845\n",
      "Epoch 287/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 6.3531 - mae: 6.9194 - val_loss: 756.1166 - val_mae: 756.8075\n",
      "Epoch 288/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 6.1105 - mae: 6.6729 - val_loss: 742.9775 - val_mae: 743.6695\n",
      "Epoch 289/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 6.1930 - mae: 6.7710 - val_loss: 732.6315 - val_mae: 733.3246\n",
      "Epoch 290/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5.9467 - mae: 6.5113 - val_loss: 724.3752 - val_mae: 725.0676\n",
      "Epoch 291/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 6.3624 - mae: 6.9296 - val_loss: 733.0393 - val_mae: 733.7301\n",
      "Epoch 292/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5.8166 - mae: 6.3775 - val_loss: 707.5343 - val_mae: 708.2266\n",
      "Epoch 293/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 39ms/step - loss: 5.9992 - mae: 6.5619 - val_loss: 724.9225 - val_mae: 725.6147\n",
      "Epoch 294/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 5.7824 - mae: 6.3410 - val_loss: 738.6639 - val_mae: 739.3554\n",
      "Epoch 295/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5.8041 - mae: 6.3545 - val_loss: 718.8043 - val_mae: 719.4971\n",
      "Epoch 296/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 5.8164 - mae: 6.3746 - val_loss: 713.5778 - val_mae: 714.2702\n",
      "Epoch 297/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 6.3798 - mae: 6.9396 - val_loss: 715.0382 - val_mae: 715.7296\n",
      "Epoch 298/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5.8030 - mae: 6.3729 - val_loss: 733.1605 - val_mae: 733.8522\n",
      "Epoch 299/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5.8369 - mae: 6.4009 - val_loss: 725.4589 - val_mae: 726.1516\n",
      "Epoch 300/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5.5162 - mae: 6.0647 - val_loss: 745.7682 - val_mae: 746.4606\n",
      "Epoch 301/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5.4581 - mae: 6.0011 - val_loss: 737.5386 - val_mae: 738.2315\n",
      "Epoch 302/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5.9531 - mae: 6.5127 - val_loss: 733.8038 - val_mae: 734.4964\n",
      "Epoch 303/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5.9054 - mae: 6.4573 - val_loss: 703.5699 - val_mae: 704.2625\n",
      "Epoch 304/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5.9379 - mae: 6.5031 - val_loss: 725.7674 - val_mae: 726.4595\n",
      "Epoch 305/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 6.0737 - mae: 6.6386 - val_loss: 710.2880 - val_mae: 710.9793\n",
      "Epoch 306/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5.7428 - mae: 6.3057 - val_loss: 732.9678 - val_mae: 733.6595\n",
      "Epoch 307/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5.5362 - mae: 6.0954 - val_loss: 715.2935 - val_mae: 715.9833\n",
      "Epoch 308/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 5.6528 - mae: 6.2196 - val_loss: 724.2665 - val_mae: 724.9592\n",
      "Epoch 309/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5.9562 - mae: 6.5253 - val_loss: 734.8011 - val_mae: 735.4932\n",
      "Epoch 310/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5.9188 - mae: 6.4822 - val_loss: 723.4257 - val_mae: 724.1163\n",
      "Epoch 311/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 5.9687 - mae: 6.5332 - val_loss: 737.9814 - val_mae: 738.6732\n",
      "Epoch 312/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5.8068 - mae: 6.3539 - val_loss: 730.5192 - val_mae: 731.2104\n",
      "Epoch 313/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5.8524 - mae: 6.4080 - val_loss: 721.7844 - val_mae: 722.4772\n",
      "Epoch 314/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 6.0003 - mae: 6.5635 - val_loss: 742.8019 - val_mae: 743.4939\n",
      "Epoch 315/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5.5001 - mae: 6.0557 - val_loss: 723.6578 - val_mae: 724.3491\n",
      "Epoch 316/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 5.8614 - mae: 6.4202 - val_loss: 714.3807 - val_mae: 715.0712\n",
      "Epoch 317/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5.3914 - mae: 5.9393 - val_loss: 720.0263 - val_mae: 720.7187\n",
      "Epoch 318/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 5.1918 - mae: 5.7372 - val_loss: 743.3417 - val_mae: 744.0331\n",
      "Epoch 319/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 5.1941 - mae: 5.7415 - val_loss: 731.2865 - val_mae: 731.9786\n",
      "Epoch 320/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5.3844 - mae: 5.9378 - val_loss: 744.7845 - val_mae: 745.4777\n",
      "Epoch 321/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 5.0419 - mae: 5.6131 - val_loss: 754.4981 - val_mae: 755.1900\n",
      "Epoch 322/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 5.5339 - mae: 6.0923 - val_loss: 746.1848 - val_mae: 746.8772\n",
      "Epoch 323/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5.4347 - mae: 5.9936 - val_loss: 712.6138 - val_mae: 713.3049\n",
      "Epoch 324/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5.0599 - mae: 5.6032 - val_loss: 708.0266 - val_mae: 708.7172\n",
      "Epoch 325/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 5.6728 - mae: 6.2150 - val_loss: 737.6500 - val_mae: 738.3417\n",
      "Epoch 326/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 6.1580 - mae: 6.7284 - val_loss: 721.0835 - val_mae: 721.7760\n",
      "Epoch 327/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5.9259 - mae: 6.4874 - val_loss: 730.9809 - val_mae: 731.6729\n",
      "Epoch 328/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5.2328 - mae: 5.7822 - val_loss: 725.2034 - val_mae: 725.8954\n",
      "Epoch 329/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 5.4248 - mae: 5.9902 - val_loss: 727.8559 - val_mae: 728.5481\n",
      "Epoch 330/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 5.4901 - mae: 6.0439 - val_loss: 731.9974 - val_mae: 732.6889\n",
      "Epoch 331/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5.4681 - mae: 6.0399 - val_loss: 718.3922 - val_mae: 719.0840\n",
      "Epoch 332/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5.1743 - mae: 5.7227 - val_loss: 715.1551 - val_mae: 715.8466\n",
      "Epoch 333/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5.5295 - mae: 6.0848 - val_loss: 713.6981 - val_mae: 714.3907\n",
      "Epoch 334/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 5.3144 - mae: 5.8695 - val_loss: 736.1018 - val_mae: 736.7930\n",
      "Epoch 335/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5.3046 - mae: 5.8549 - val_loss: 725.3571 - val_mae: 726.0479\n",
      "Epoch 336/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 5.7245 - mae: 6.2780 - val_loss: 745.2588 - val_mae: 745.9517\n",
      "Epoch 337/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5.1433 - mae: 5.6920 - val_loss: 728.2160 - val_mae: 728.9088\n",
      "Epoch 338/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5.5009 - mae: 6.0602 - val_loss: 739.1946 - val_mae: 739.8875\n",
      "Epoch 339/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 4.8431 - mae: 5.3934 - val_loss: 716.1321 - val_mae: 716.8239\n",
      "Epoch 340/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5.1089 - mae: 5.6587 - val_loss: 708.8855 - val_mae: 709.5781\n",
      "Epoch 341/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 4.9680 - mae: 5.5172 - val_loss: 723.3044 - val_mae: 723.9969\n",
      "Epoch 342/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5.6292 - mae: 6.1888 - val_loss: 719.2405 - val_mae: 719.9314\n",
      "Epoch 343/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5.5026 - mae: 6.0690 - val_loss: 730.1223 - val_mae: 730.8145\n",
      "Epoch 344/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 4.8409 - mae: 5.3847 - val_loss: 730.4109 - val_mae: 731.1030\n",
      "Epoch 345/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5.0487 - mae: 5.6016 - val_loss: 724.6530 - val_mae: 725.3450\n",
      "Epoch 346/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5.2327 - mae: 5.7709 - val_loss: 716.9208 - val_mae: 717.6128\n",
      "Epoch 347/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5.4562 - mae: 6.0181 - val_loss: 707.2888 - val_mae: 707.9799\n",
      "Epoch 348/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5.6848 - mae: 6.2430 - val_loss: 712.7766 - val_mae: 713.4678\n",
      "Epoch 349/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5.7135 - mae: 6.2632 - val_loss: 723.0163 - val_mae: 723.7094\n",
      "Epoch 350/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 5.1220 - mae: 5.6661 - val_loss: 725.4965 - val_mae: 726.1874\n",
      "Epoch 351/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 5.3676 - mae: 5.9236 - val_loss: 703.8636 - val_mae: 704.5554\n",
      "Epoch 352/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 46ms/step - loss: 5.0894 - mae: 5.6399 - val_loss: 703.0249 - val_mae: 703.7156\n",
      "Epoch 353/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 4.5806 - mae: 5.1176 - val_loss: 704.2102 - val_mae: 704.9030\n",
      "Epoch 354/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 4.5927 - mae: 5.1262 - val_loss: 701.5660 - val_mae: 702.2572\n",
      "Epoch 355/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 5.2532 - mae: 5.8042 - val_loss: 717.3843 - val_mae: 718.0772\n",
      "Epoch 356/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 4.7777 - mae: 5.3154 - val_loss: 710.8506 - val_mae: 711.5421\n",
      "Epoch 357/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5.4414 - mae: 6.0040 - val_loss: 734.8595 - val_mae: 735.5507\n",
      "Epoch 358/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 5.5085 - mae: 6.0624 - val_loss: 692.8844 - val_mae: 693.5760\n",
      "Epoch 359/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 5.1974 - mae: 5.7536 - val_loss: 735.8648 - val_mae: 736.5579\n",
      "Epoch 360/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5.6004 - mae: 6.1482 - val_loss: 705.7457 - val_mae: 706.4377\n",
      "Epoch 361/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 4.8051 - mae: 5.3366 - val_loss: 702.4412 - val_mae: 703.1323\n",
      "Epoch 362/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 4.6682 - mae: 5.2116 - val_loss: 675.0065 - val_mae: 675.6978\n",
      "Epoch 363/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 4.8585 - mae: 5.3970 - val_loss: 707.6412 - val_mae: 708.3342\n",
      "Epoch 364/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 4.9149 - mae: 5.4608 - val_loss: 700.9026 - val_mae: 701.5916\n",
      "Epoch 365/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 4.5142 - mae: 5.0485 - val_loss: 684.7762 - val_mae: 685.4688\n",
      "Epoch 366/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 4.8946 - mae: 5.4340 - val_loss: 695.9581 - val_mae: 696.6503\n",
      "Epoch 367/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 4.9473 - mae: 5.4952 - val_loss: 712.7406 - val_mae: 713.4330\n",
      "Epoch 368/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 5.0298 - mae: 5.5710 - val_loss: 660.7145 - val_mae: 661.4046\n",
      "Epoch 369/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 4.6774 - mae: 5.2142 - val_loss: 708.1122 - val_mae: 708.8034\n",
      "Epoch 370/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 4.6036 - mae: 5.1351 - val_loss: 684.5418 - val_mae: 685.2302\n",
      "Epoch 371/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 4.7979 - mae: 5.3421 - val_loss: 693.4906 - val_mae: 694.1804\n",
      "Epoch 372/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 4.3496 - mae: 4.8837 - val_loss: 689.5891 - val_mae: 690.2814\n",
      "Epoch 373/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 5.0899 - mae: 5.6362 - val_loss: 705.6411 - val_mae: 706.3333\n",
      "Epoch 374/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 4.4679 - mae: 5.0001 - val_loss: 701.5168 - val_mae: 702.2095\n",
      "Epoch 375/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 4.7863 - mae: 5.3283 - val_loss: 726.8161 - val_mae: 727.5071\n",
      "Epoch 376/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 4.7760 - mae: 5.3233 - val_loss: 692.0856 - val_mae: 692.7776\n",
      "Epoch 377/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 4.6360 - mae: 5.1858 - val_loss: 735.9378 - val_mae: 736.6281\n",
      "Epoch 378/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 4.6323 - mae: 5.1832 - val_loss: 689.4340 - val_mae: 690.1254\n",
      "Epoch 379/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 4.3111 - mae: 4.8497 - val_loss: 715.4810 - val_mae: 716.1735\n",
      "Epoch 380/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 4.9799 - mae: 5.5321 - val_loss: 686.5907 - val_mae: 687.2817\n",
      "Epoch 381/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 4.7652 - mae: 5.3068 - val_loss: 682.6331 - val_mae: 683.3232\n",
      "Epoch 382/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 4.6958 - mae: 5.2417 - val_loss: 708.4618 - val_mae: 709.1540\n",
      "Epoch 383/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 4.6961 - mae: 5.2337 - val_loss: 706.1239 - val_mae: 706.8166\n",
      "Epoch 384/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 4.5838 - mae: 5.1415 - val_loss: 685.6884 - val_mae: 686.3807\n",
      "Epoch 385/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 4.2192 - mae: 4.7454 - val_loss: 683.7260 - val_mae: 684.4186\n",
      "Epoch 386/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 4.5398 - mae: 5.0858 - val_loss: 673.0835 - val_mae: 673.7735\n",
      "Epoch 387/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 4.2392 - mae: 4.7705 - val_loss: 686.2543 - val_mae: 686.9445\n",
      "Epoch 388/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 4.4942 - mae: 5.0220 - val_loss: 679.2827 - val_mae: 679.9744\n",
      "Epoch 389/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 4.5683 - mae: 5.1167 - val_loss: 697.2061 - val_mae: 697.8981\n",
      "Epoch 390/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 4.4328 - mae: 4.9798 - val_loss: 678.5087 - val_mae: 679.2009\n",
      "Epoch 391/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 5.0684 - mae: 5.6122 - val_loss: 702.1033 - val_mae: 702.7943\n",
      "Epoch 392/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 4.8766 - mae: 5.4170 - val_loss: 670.3081 - val_mae: 670.9989\n",
      "Epoch 393/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 4.6494 - mae: 5.1858 - val_loss: 652.8795 - val_mae: 653.5715\n",
      "Epoch 394/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 4.7035 - mae: 5.2380 - val_loss: 696.2138 - val_mae: 696.9055\n",
      "Epoch 395/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 4.2746 - mae: 4.8076 - val_loss: 706.6199 - val_mae: 707.3096\n",
      "Epoch 396/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 4.8017 - mae: 5.3488 - val_loss: 700.5095 - val_mae: 701.1994\n",
      "Epoch 397/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 4.8959 - mae: 5.4417 - val_loss: 658.9810 - val_mae: 659.6737\n",
      "Epoch 398/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 4.8184 - mae: 5.3468 - val_loss: 696.6819 - val_mae: 697.3725\n",
      "Epoch 399/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 4.7307 - mae: 5.2712 - val_loss: 694.2620 - val_mae: 694.9551\n",
      "Epoch 400/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 4.7791 - mae: 5.3219 - val_loss: 685.7628 - val_mae: 686.4513\n",
      "Epoch 401/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 4.1943 - mae: 4.7314 - val_loss: 666.3262 - val_mae: 667.0186\n",
      "Epoch 402/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 4.7253 - mae: 5.2593 - val_loss: 673.7385 - val_mae: 674.4292\n",
      "Epoch 403/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 4.3801 - mae: 4.9313 - val_loss: 678.3124 - val_mae: 679.0045\n",
      "Epoch 404/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 4.6999 - mae: 5.2396 - val_loss: 697.2209 - val_mae: 697.9125\n",
      "Epoch 405/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 4.1093 - mae: 4.6466 - val_loss: 693.9453 - val_mae: 694.6357\n",
      "Epoch 406/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 4.3757 - mae: 4.9135 - val_loss: 644.1724 - val_mae: 644.8649\n",
      "Epoch 407/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 4.9316 - mae: 5.5197 - val_loss: 677.7639 - val_mae: 678.4539\n",
      "Epoch 408/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 4.4215 - mae: 4.9773 - val_loss: 680.7029 - val_mae: 681.3956\n",
      "Epoch 409/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 4.4032 - mae: 4.9474 - val_loss: 685.4699 - val_mae: 686.1602\n",
      "Epoch 410/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 4.3719 - mae: 4.9026 - val_loss: 658.9066 - val_mae: 659.5976\n",
      "Epoch 411/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 42ms/step - loss: 4.3559 - mae: 4.8859 - val_loss: 691.2191 - val_mae: 691.9097\n",
      "Epoch 412/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 4.3136 - mae: 4.8454 - val_loss: 652.6356 - val_mae: 653.3273\n",
      "Epoch 413/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 4.4683 - mae: 5.0176 - val_loss: 674.5459 - val_mae: 675.2363\n",
      "Epoch 414/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 4.5047 - mae: 5.0555 - val_loss: 686.8934 - val_mae: 687.5843\n",
      "Epoch 415/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 4.3357 - mae: 4.8767 - val_loss: 680.0890 - val_mae: 680.7805\n",
      "Epoch 416/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 4.6731 - mae: 5.2134 - val_loss: 673.8912 - val_mae: 674.5782\n",
      "Epoch 417/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 4.5855 - mae: 5.1266 - val_loss: 643.8129 - val_mae: 644.5022\n",
      "Epoch 418/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 4.2944 - mae: 4.8321 - val_loss: 685.1423 - val_mae: 685.8328\n",
      "Epoch 419/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 4.2772 - mae: 4.8052 - val_loss: 691.8964 - val_mae: 692.5877\n",
      "Epoch 420/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 4.2776 - mae: 4.8185 - val_loss: 651.9651 - val_mae: 652.6573\n",
      "Epoch 421/5000\n",
      "46/46 [==============================] - 3s 67ms/step - loss: 3.7710 - mae: 4.2868 - val_loss: 663.9865 - val_mae: 664.6775\n",
      "Epoch 422/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 3.9617 - mae: 4.4798 - val_loss: 660.6556 - val_mae: 661.3474\n",
      "Epoch 423/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 3.7103 - mae: 4.2323 - val_loss: 654.4903 - val_mae: 655.1813\n",
      "Epoch 424/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 4.0256 - mae: 4.5399 - val_loss: 652.4877 - val_mae: 653.1795\n",
      "Epoch 425/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 4.5742 - mae: 5.1246 - val_loss: 639.1127 - val_mae: 639.8037\n",
      "Epoch 426/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 4.5517 - mae: 5.0966 - val_loss: 662.3771 - val_mae: 663.0701\n",
      "Epoch 427/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 4.1095 - mae: 4.6419 - val_loss: 656.2310 - val_mae: 656.9237\n",
      "Epoch 428/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 4.2866 - mae: 4.8150 - val_loss: 630.3492 - val_mae: 631.0403\n",
      "Epoch 429/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 4.4475 - mae: 4.9866 - val_loss: 644.6169 - val_mae: 645.3066\n",
      "Epoch 430/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 4.2980 - mae: 4.8418 - val_loss: 660.1076 - val_mae: 660.7993\n",
      "Epoch 431/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 4.6357 - mae: 5.1737 - val_loss: 651.6720 - val_mae: 652.3642\n",
      "Epoch 432/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 3.9880 - mae: 4.5285 - val_loss: 638.4953 - val_mae: 639.1855\n",
      "Epoch 433/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 4.2977 - mae: 4.8495 - val_loss: 642.0216 - val_mae: 642.7136\n",
      "Epoch 434/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 4.1908 - mae: 4.7229 - val_loss: 695.8388 - val_mae: 696.5315\n",
      "Epoch 435/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 4.5516 - mae: 5.0985 - val_loss: 664.9051 - val_mae: 665.5963\n",
      "Epoch 436/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 4.3090 - mae: 4.8673 - val_loss: 637.0932 - val_mae: 637.7850\n",
      "Epoch 437/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 3.9175 - mae: 4.4544 - val_loss: 648.0453 - val_mae: 648.7375\n",
      "Epoch 438/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 4.0493 - mae: 4.5761 - val_loss: 629.4622 - val_mae: 630.1543\n",
      "Epoch 439/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 3.7815 - mae: 4.3051 - val_loss: 642.7198 - val_mae: 643.4096\n",
      "Epoch 440/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 3.9347 - mae: 4.4583 - val_loss: 638.0120 - val_mae: 638.7028\n",
      "Epoch 441/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 3.8527 - mae: 4.3766 - val_loss: 643.0541 - val_mae: 643.7461\n",
      "Epoch 442/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 4.4675 - mae: 4.9921 - val_loss: 640.4958 - val_mae: 641.1874\n",
      "Epoch 443/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 4.2008 - mae: 4.7272 - val_loss: 623.7521 - val_mae: 624.4440\n",
      "Epoch 444/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 4.0081 - mae: 4.5324 - val_loss: 643.8364 - val_mae: 644.5275\n",
      "Epoch 445/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.8539 - mae: 4.3783 - val_loss: 629.8184 - val_mae: 630.5103\n",
      "Epoch 446/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 4.1624 - mae: 4.6850 - val_loss: 630.2872 - val_mae: 630.9797\n",
      "Epoch 447/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 3.8867 - mae: 4.4028 - val_loss: 632.7900 - val_mae: 633.4788\n",
      "Epoch 448/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 4.0271 - mae: 4.5609 - val_loss: 619.5846 - val_mae: 620.2748\n",
      "Epoch 449/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 4.1635 - mae: 4.6943 - val_loss: 640.3960 - val_mae: 641.0885\n",
      "Epoch 450/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.8740 - mae: 4.3948 - val_loss: 640.2413 - val_mae: 640.9317\n",
      "Epoch 451/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 3.6510 - mae: 4.1731 - val_loss: 639.0000 - val_mae: 639.6915\n",
      "Epoch 452/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 3.9245 - mae: 4.4432 - val_loss: 613.9913 - val_mae: 614.6823\n",
      "Epoch 453/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.9292 - mae: 4.4517 - val_loss: 643.2537 - val_mae: 643.9455\n",
      "Epoch 454/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 3.8400 - mae: 4.3766 - val_loss: 622.5743 - val_mae: 623.2653\n",
      "Epoch 455/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.9120 - mae: 4.4349 - val_loss: 636.5053 - val_mae: 637.1978\n",
      "Epoch 456/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 3.6636 - mae: 4.1828 - val_loss: 636.3478 - val_mae: 637.0376\n",
      "Epoch 457/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 4.5098 - mae: 5.0504 - val_loss: 622.2873 - val_mae: 622.9785\n",
      "Epoch 458/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.6742 - mae: 4.2029 - val_loss: 624.6475 - val_mae: 625.3385\n",
      "Epoch 459/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 3.9846 - mae: 4.5178 - val_loss: 653.1837 - val_mae: 653.8750\n",
      "Epoch 460/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 4.2630 - mae: 4.7986 - val_loss: 632.9820 - val_mae: 633.6730\n",
      "Epoch 461/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 4.0837 - mae: 4.6165 - val_loss: 636.1127 - val_mae: 636.8057\n",
      "Epoch 462/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 4.4511 - mae: 4.9839 - val_loss: 624.7278 - val_mae: 625.4178\n",
      "Epoch 463/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 4.0572 - mae: 4.5917 - val_loss: 650.4525 - val_mae: 651.1423\n",
      "Epoch 464/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 3.3175 - mae: 3.8303 - val_loss: 627.7994 - val_mae: 628.4913\n",
      "Epoch 465/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 3.2573 - mae: 3.7728 - val_loss: 625.0819 - val_mae: 625.7720\n",
      "Epoch 466/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 4.0989 - mae: 4.6264 - val_loss: 628.4390 - val_mae: 629.1312\n",
      "Epoch 467/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.6893 - mae: 4.2058 - val_loss: 618.1164 - val_mae: 618.8085\n",
      "Epoch 468/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 3.8283 - mae: 4.3540 - val_loss: 614.0117 - val_mae: 614.7045\n",
      "Epoch 469/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 3.6291 - mae: 4.1541 - val_loss: 640.4789 - val_mae: 641.1671\n",
      "Epoch 470/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 36ms/step - loss: 3.3995 - mae: 3.9199 - val_loss: 629.9278 - val_mae: 630.6184\n",
      "Epoch 471/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.4017 - mae: 3.9176 - val_loss: 606.6013 - val_mae: 607.2928\n",
      "Epoch 472/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 3.7434 - mae: 4.2684 - val_loss: 635.9435 - val_mae: 636.6351\n",
      "Epoch 473/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 3.4672 - mae: 3.9873 - val_loss: 634.5682 - val_mae: 635.2604\n",
      "Epoch 474/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 3.5626 - mae: 4.0854 - val_loss: 658.9217 - val_mae: 659.6125\n",
      "Epoch 475/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 3.2363 - mae: 3.7400 - val_loss: 632.1539 - val_mae: 632.8463\n",
      "Epoch 476/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 4.1477 - mae: 4.6769 - val_loss: 621.4102 - val_mae: 622.1022\n",
      "Epoch 477/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 3.6936 - mae: 4.2234 - val_loss: 623.7297 - val_mae: 624.4220\n",
      "Epoch 478/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 3.5910 - mae: 4.1026 - val_loss: 606.2005 - val_mae: 606.8920\n",
      "Epoch 479/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 3.6086 - mae: 4.1212 - val_loss: 637.9612 - val_mae: 638.6533\n",
      "Epoch 480/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 3.8358 - mae: 4.3764 - val_loss: 633.8062 - val_mae: 634.4973\n",
      "Epoch 481/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 4.3141 - mae: 4.8581 - val_loss: 629.8704 - val_mae: 630.5630\n",
      "Epoch 482/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 3.6280 - mae: 4.1404 - val_loss: 626.7083 - val_mae: 627.3992\n",
      "Epoch 483/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 4.0785 - mae: 4.6099 - val_loss: 596.5037 - val_mae: 597.1959\n",
      "Epoch 484/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.6098 - mae: 4.1620 - val_loss: 624.3888 - val_mae: 625.0779\n",
      "Epoch 485/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 3.7025 - mae: 4.2253 - val_loss: 622.9951 - val_mae: 623.6865\n",
      "Epoch 486/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 3.6626 - mae: 4.1843 - val_loss: 633.1102 - val_mae: 633.8021\n",
      "Epoch 487/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 3.5540 - mae: 4.0804 - val_loss: 601.8585 - val_mae: 602.5496\n",
      "Epoch 488/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 3.8202 - mae: 4.3589 - val_loss: 598.5315 - val_mae: 599.2220\n",
      "Epoch 489/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 4.2147 - mae: 4.7560 - val_loss: 585.8433 - val_mae: 586.5350\n",
      "Epoch 490/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 3.4481 - mae: 3.9618 - val_loss: 591.4940 - val_mae: 592.1846\n",
      "Epoch 491/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.4533 - mae: 3.9668 - val_loss: 615.1430 - val_mae: 615.8326\n",
      "Epoch 492/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 4.1075 - mae: 4.6297 - val_loss: 584.6370 - val_mae: 585.3295\n",
      "Epoch 493/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 3.7217 - mae: 4.2510 - val_loss: 599.8566 - val_mae: 600.5471\n",
      "Epoch 494/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 3.5820 - mae: 4.0843 - val_loss: 605.8265 - val_mae: 606.5193\n",
      "Epoch 495/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 4.2843 - mae: 4.8081 - val_loss: 540.8517 - val_mae: 541.5430\n",
      "Epoch 496/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 4.1141 - mae: 4.6349 - val_loss: 600.1813 - val_mae: 600.8715\n",
      "Epoch 497/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 4.1130 - mae: 4.6395 - val_loss: 589.6076 - val_mae: 590.3004\n",
      "Epoch 498/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 3.8866 - mae: 4.4198 - val_loss: 608.0580 - val_mae: 608.7506\n",
      "Epoch 499/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 3.4344 - mae: 3.9491 - val_loss: 623.5640 - val_mae: 624.2562\n",
      "Epoch 500/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 4.5033 - mae: 5.0427 - val_loss: 596.8994 - val_mae: 597.5889\n",
      "Epoch 501/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 3.6873 - mae: 4.2165 - val_loss: 607.2283 - val_mae: 607.9196\n",
      "Epoch 502/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 3.3136 - mae: 3.8385 - val_loss: 585.1163 - val_mae: 585.8077\n",
      "Epoch 503/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 3.3432 - mae: 3.8554 - val_loss: 568.8589 - val_mae: 569.5508\n",
      "Epoch 504/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 3.7029 - mae: 4.2340 - val_loss: 616.0418 - val_mae: 616.7347\n",
      "Epoch 505/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 4.0709 - mae: 4.5844 - val_loss: 609.7827 - val_mae: 610.4745\n",
      "Epoch 506/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.4300 - mae: 3.9329 - val_loss: 566.4638 - val_mae: 567.1555\n",
      "Epoch 507/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 3.4689 - mae: 3.9723 - val_loss: 588.4964 - val_mae: 589.1876\n",
      "Epoch 508/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 4.0860 - mae: 4.6112 - val_loss: 598.1703 - val_mae: 598.8627\n",
      "Epoch 509/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 3.5871 - mae: 4.1115 - val_loss: 616.3962 - val_mae: 617.0874\n",
      "Epoch 510/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.4642 - mae: 3.9760 - val_loss: 595.5670 - val_mae: 596.2596\n",
      "Epoch 511/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 3.6448 - mae: 4.1769 - val_loss: 594.2670 - val_mae: 594.9595\n",
      "Epoch 512/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 3.1202 - mae: 3.6324 - val_loss: 575.3797 - val_mae: 576.0696\n",
      "Epoch 513/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 3.0386 - mae: 3.5631 - val_loss: 612.0163 - val_mae: 612.7090\n",
      "Epoch 514/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 3.0528 - mae: 3.5570 - val_loss: 574.8226 - val_mae: 575.5135\n",
      "Epoch 515/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 3.5500 - mae: 4.0672 - val_loss: 596.5576 - val_mae: 597.2498\n",
      "Epoch 516/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 3.4052 - mae: 3.9210 - val_loss: 598.0267 - val_mae: 598.7172\n",
      "Epoch 517/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 3.3850 - mae: 3.8925 - val_loss: 602.4582 - val_mae: 603.1470\n",
      "Epoch 518/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 3.0788 - mae: 3.5817 - val_loss: 581.5719 - val_mae: 582.2633\n",
      "Epoch 519/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 3.4508 - mae: 3.9698 - val_loss: 584.1145 - val_mae: 584.8065\n",
      "Epoch 520/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 3.2278 - mae: 3.7281 - val_loss: 569.5569 - val_mae: 570.2496\n",
      "Epoch 521/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 3.2059 - mae: 3.7187 - val_loss: 598.5847 - val_mae: 599.2767\n",
      "Epoch 522/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 3.8693 - mae: 4.3870 - val_loss: 577.1384 - val_mae: 577.8295\n",
      "Epoch 523/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.7881 - mae: 4.3098 - val_loss: 591.7735 - val_mae: 592.4656\n",
      "Epoch 524/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 3.6427 - mae: 4.1674 - val_loss: 563.3522 - val_mae: 564.0430\n",
      "Epoch 525/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 3.2212 - mae: 3.7306 - val_loss: 593.8652 - val_mae: 594.5567\n",
      "Epoch 526/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 3.3466 - mae: 3.8612 - val_loss: 595.0032 - val_mae: 595.6943\n",
      "Epoch 527/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 3.1587 - mae: 3.6740 - val_loss: 602.5222 - val_mae: 603.2118\n",
      "Epoch 528/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 3.5392 - mae: 4.0457 - val_loss: 587.2114 - val_mae: 587.9037\n",
      "Epoch 529/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 40ms/step - loss: 3.6330 - mae: 4.1431 - val_loss: 592.1909 - val_mae: 592.8828\n",
      "Epoch 530/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 3.4557 - mae: 3.9694 - val_loss: 608.8550 - val_mae: 609.5466\n",
      "Epoch 531/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0877 - mae: 3.6078 - val_loss: 562.7769 - val_mae: 563.4673\n",
      "Epoch 532/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.2276 - mae: 3.7326 - val_loss: 570.7814 - val_mae: 571.4744\n",
      "Epoch 533/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 2.9735 - mae: 3.4811 - val_loss: 572.8763 - val_mae: 573.5679\n",
      "Epoch 534/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2572 - mae: 3.7680 - val_loss: 586.8946 - val_mae: 587.5859\n",
      "Epoch 535/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.1268 - mae: 3.6283 - val_loss: 611.3087 - val_mae: 612.0004\n",
      "Epoch 536/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 3.2839 - mae: 3.8040 - val_loss: 588.3995 - val_mae: 589.0907\n",
      "Epoch 537/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 3.0536 - mae: 3.5679 - val_loss: 592.8132 - val_mae: 593.5045\n",
      "Epoch 538/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 3.5953 - mae: 4.1185 - val_loss: 615.1981 - val_mae: 615.8891\n",
      "Epoch 539/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 3.7286 - mae: 4.2552 - val_loss: 574.1945 - val_mae: 574.8870\n",
      "Epoch 540/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.7332 - mae: 4.2717 - val_loss: 594.2649 - val_mae: 594.9551\n",
      "Epoch 541/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 3.5387 - mae: 4.0569 - val_loss: 599.0015 - val_mae: 599.6939\n",
      "Epoch 542/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 3.1549 - mae: 3.6622 - val_loss: 569.2511 - val_mae: 569.9420\n",
      "Epoch 543/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 3.4222 - mae: 3.9266 - val_loss: 587.8412 - val_mae: 588.5316\n",
      "Epoch 544/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.1348 - mae: 3.6386 - val_loss: 574.8589 - val_mae: 575.5497\n",
      "Epoch 545/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0971 - mae: 3.6052 - val_loss: 578.2175 - val_mae: 578.9092\n",
      "Epoch 546/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 3.0356 - mae: 3.5465 - val_loss: 553.2829 - val_mae: 553.9746\n",
      "Epoch 547/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 3.4935 - mae: 4.0082 - val_loss: 572.2851 - val_mae: 572.9767\n",
      "Epoch 548/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.7523 - mae: 4.2685 - val_loss: 552.1509 - val_mae: 552.8430\n",
      "Epoch 549/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 3.7266 - mae: 4.2568 - val_loss: 590.1545 - val_mae: 590.8471\n",
      "Epoch 550/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 3.1446 - mae: 3.6536 - val_loss: 568.6727 - val_mae: 569.3634\n",
      "Epoch 551/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 3.4489 - mae: 3.9717 - val_loss: 572.1426 - val_mae: 572.8330\n",
      "Epoch 552/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 3.1693 - mae: 3.6841 - val_loss: 583.0354 - val_mae: 583.7267\n",
      "Epoch 553/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 3.1022 - mae: 3.6141 - val_loss: 583.3149 - val_mae: 584.0048\n",
      "Epoch 554/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 2.9021 - mae: 3.4048 - val_loss: 592.2434 - val_mae: 592.9340\n",
      "Epoch 555/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 2.7459 - mae: 3.2433 - val_loss: 582.3433 - val_mae: 583.0348\n",
      "Epoch 556/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 3.0893 - mae: 3.5984 - val_loss: 600.8583 - val_mae: 601.5501\n",
      "Epoch 557/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 3.4220 - mae: 3.9347 - val_loss: 606.9308 - val_mae: 607.6238\n",
      "Epoch 558/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 3.1640 - mae: 3.6760 - val_loss: 591.4428 - val_mae: 592.1351\n",
      "Epoch 559/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 3.0505 - mae: 3.5583 - val_loss: 589.3338 - val_mae: 590.0255\n",
      "Epoch 560/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 2.9555 - mae: 3.4558 - val_loss: 600.7454 - val_mae: 601.4376\n",
      "Epoch 561/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 3.1487 - mae: 3.6490 - val_loss: 571.0945 - val_mae: 571.7866\n",
      "Epoch 562/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 3.3454 - mae: 3.8469 - val_loss: 554.3182 - val_mae: 555.0109\n",
      "Epoch 563/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 3.0179 - mae: 3.5187 - val_loss: 575.6874 - val_mae: 576.3790\n",
      "Epoch 564/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 3.1058 - mae: 3.6108 - val_loss: 588.1980 - val_mae: 588.8894\n",
      "Epoch 565/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 3.8447 - mae: 4.3772 - val_loss: 590.8521 - val_mae: 591.5446\n",
      "Epoch 566/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 3.3916 - mae: 3.9111 - val_loss: 580.8692 - val_mae: 581.5612\n",
      "Epoch 567/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 3.1799 - mae: 3.6915 - val_loss: 583.9470 - val_mae: 584.6376\n",
      "Epoch 568/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 3.1842 - mae: 3.6932 - val_loss: 546.4308 - val_mae: 547.1227\n",
      "Epoch 569/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 3.3293 - mae: 3.8516 - val_loss: 558.2316 - val_mae: 558.9218\n",
      "Epoch 570/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 3.2516 - mae: 3.7731 - val_loss: 543.7984 - val_mae: 544.4895\n",
      "Epoch 571/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 2.9320 - mae: 3.4182 - val_loss: 576.5056 - val_mae: 577.1976\n",
      "Epoch 572/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.7596 - mae: 3.2529 - val_loss: 539.2806 - val_mae: 539.9724\n",
      "Epoch 573/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 3.0541 - mae: 3.5452 - val_loss: 565.0522 - val_mae: 565.7449\n",
      "Epoch 574/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 3.0783 - mae: 3.5810 - val_loss: 556.9115 - val_mae: 557.6035\n",
      "Epoch 575/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 3.0999 - mae: 3.6103 - val_loss: 546.2635 - val_mae: 546.9541\n",
      "Epoch 576/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 3.0233 - mae: 3.5313 - val_loss: 570.3615 - val_mae: 571.0532\n",
      "Epoch 577/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9521 - mae: 3.4642 - val_loss: 563.7013 - val_mae: 564.3919\n",
      "Epoch 578/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.8634 - mae: 3.3613 - val_loss: 538.7116 - val_mae: 539.4013\n",
      "Epoch 579/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 3.1633 - mae: 3.6633 - val_loss: 564.9984 - val_mae: 565.6903\n",
      "Epoch 580/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6125 - mae: 3.1054 - val_loss: 559.4578 - val_mae: 560.1473\n",
      "Epoch 581/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 2.7285 - mae: 3.2353 - val_loss: 557.5804 - val_mae: 558.2726\n",
      "Epoch 582/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 2.9688 - mae: 3.4724 - val_loss: 560.0700 - val_mae: 560.7615\n",
      "Epoch 583/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 3.4306 - mae: 3.9371 - val_loss: 564.4402 - val_mae: 565.1315\n",
      "Epoch 584/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 3.4457 - mae: 3.9509 - val_loss: 537.4595 - val_mae: 538.1502\n",
      "Epoch 585/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 3.1838 - mae: 3.6978 - val_loss: 554.5501 - val_mae: 555.2417\n",
      "Epoch 586/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 2.8843 - mae: 3.3810 - val_loss: 560.3928 - val_mae: 561.0835\n",
      "Epoch 587/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.8661 - mae: 3.3810 - val_loss: 525.1822 - val_mae: 525.8726\n",
      "Epoch 588/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 36ms/step - loss: 2.8280 - mae: 3.3263 - val_loss: 545.9696 - val_mae: 546.6605\n",
      "Epoch 589/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6188 - mae: 3.1158 - val_loss: 565.5567 - val_mae: 566.2497\n",
      "Epoch 590/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 3.1566 - mae: 3.6760 - val_loss: 534.3760 - val_mae: 535.0656\n",
      "Epoch 591/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 2.8090 - mae: 3.3126 - val_loss: 552.4144 - val_mae: 553.1067\n",
      "Epoch 592/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 2.8591 - mae: 3.3597 - val_loss: 533.2811 - val_mae: 533.9734\n",
      "Epoch 593/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 2.9454 - mae: 3.4502 - val_loss: 560.6622 - val_mae: 561.3532\n",
      "Epoch 594/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.9714 - mae: 3.4752 - val_loss: 552.0024 - val_mae: 552.6946\n",
      "Epoch 595/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.8052 - mae: 3.3043 - val_loss: 556.0133 - val_mae: 556.7054\n",
      "Epoch 596/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 3.2490 - mae: 3.7709 - val_loss: 564.0674 - val_mae: 564.7564\n",
      "Epoch 597/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7198 - mae: 3.2414 - val_loss: 532.9842 - val_mae: 533.6771\n",
      "Epoch 598/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.7121 - mae: 3.2092 - val_loss: 557.8282 - val_mae: 558.5170\n",
      "Epoch 599/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 3.5881 - mae: 4.1038 - val_loss: 530.6960 - val_mae: 531.3874\n",
      "Epoch 600/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7744 - mae: 3.2748 - val_loss: 545.3869 - val_mae: 546.0765\n",
      "Epoch 601/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 3.2867 - mae: 3.7938 - val_loss: 531.4405 - val_mae: 532.1288\n",
      "Epoch 602/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.1059 - mae: 3.6140 - val_loss: 535.1085 - val_mae: 535.8009\n",
      "Epoch 603/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 3.2020 - mae: 3.7043 - val_loss: 503.5489 - val_mae: 504.2406\n",
      "Epoch 604/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 2.8090 - mae: 3.3051 - val_loss: 514.1031 - val_mae: 514.7951\n",
      "Epoch 605/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.9021 - mae: 3.3894 - val_loss: 534.0223 - val_mae: 534.7141\n",
      "Epoch 606/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7053 - mae: 3.1972 - val_loss: 568.6571 - val_mae: 569.3490\n",
      "Epoch 607/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 2.5633 - mae: 3.0617 - val_loss: 557.7015 - val_mae: 558.3938\n",
      "Epoch 608/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 3.0298 - mae: 3.5546 - val_loss: 560.9605 - val_mae: 561.6515\n",
      "Epoch 609/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 2.9260 - mae: 3.4357 - val_loss: 563.4915 - val_mae: 564.1814\n",
      "Epoch 610/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 3.0447 - mae: 3.5502 - val_loss: 567.1556 - val_mae: 567.8467\n",
      "Epoch 611/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9423 - mae: 3.4393 - val_loss: 537.7709 - val_mae: 538.4622\n",
      "Epoch 612/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 3.0792 - mae: 3.5848 - val_loss: 536.8363 - val_mae: 537.5288\n",
      "Epoch 613/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 3.0974 - mae: 3.6027 - val_loss: 557.4084 - val_mae: 558.0992\n",
      "Epoch 614/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 2.8930 - mae: 3.4006 - val_loss: 541.0026 - val_mae: 541.6937\n",
      "Epoch 615/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.9861 - mae: 3.4983 - val_loss: 550.8699 - val_mae: 551.5621\n",
      "Epoch 616/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.8317 - mae: 3.3257 - val_loss: 550.3493 - val_mae: 551.0407\n",
      "Epoch 617/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 3.0864 - mae: 3.5840 - val_loss: 533.8705 - val_mae: 534.5610\n",
      "Epoch 618/5000\n",
      "46/46 [==============================] - 3s 57ms/step - loss: 2.9417 - mae: 3.4438 - val_loss: 552.8484 - val_mae: 553.5414\n",
      "Epoch 619/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.9020 - mae: 4.4295 - val_loss: 519.5351 - val_mae: 520.2277\n",
      "Epoch 620/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 3.3013 - mae: 3.8223 - val_loss: 548.1076 - val_mae: 548.7990\n",
      "Epoch 621/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 2.8992 - mae: 3.4095 - val_loss: 534.4573 - val_mae: 535.1481\n",
      "Epoch 622/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 2.8473 - mae: 3.3490 - val_loss: 534.0031 - val_mae: 534.6943\n",
      "Epoch 623/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5420 - mae: 3.0200 - val_loss: 539.2286 - val_mae: 539.9200\n",
      "Epoch 624/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 2.9604 - mae: 3.4526 - val_loss: 551.8248 - val_mae: 552.5159\n",
      "Epoch 625/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 2.5987 - mae: 3.0931 - val_loss: 539.2698 - val_mae: 539.9597\n",
      "Epoch 626/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 2.7200 - mae: 3.2264 - val_loss: 526.3198 - val_mae: 527.0110\n",
      "Epoch 627/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 2.9107 - mae: 3.4127 - val_loss: 514.2496 - val_mae: 514.9395\n",
      "Epoch 628/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 2.8753 - mae: 3.3757 - val_loss: 522.6465 - val_mae: 523.3366\n",
      "Epoch 629/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 2.7701 - mae: 3.2656 - val_loss: 557.9219 - val_mae: 558.6143\n",
      "Epoch 630/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6625 - mae: 3.1610 - val_loss: 538.9186 - val_mae: 539.6116\n",
      "Epoch 631/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 2.9800 - mae: 3.5097 - val_loss: 539.4860 - val_mae: 540.1765\n",
      "Epoch 632/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 2.7452 - mae: 3.2418 - val_loss: 527.4403 - val_mae: 528.1292\n",
      "Epoch 633/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 2.6183 - mae: 3.0982 - val_loss: 560.3453 - val_mae: 561.0356\n",
      "Epoch 634/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 2.8390 - mae: 3.3503 - val_loss: 531.4041 - val_mae: 532.0967\n",
      "Epoch 635/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5894 - mae: 3.0882 - val_loss: 543.8906 - val_mae: 544.5830\n",
      "Epoch 636/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 3.0267 - mae: 3.5336 - val_loss: 515.9724 - val_mae: 516.6649\n",
      "Epoch 637/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 2.7631 - mae: 3.2561 - val_loss: 549.3377 - val_mae: 550.0297\n",
      "Epoch 638/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.0173 - mae: 3.5221 - val_loss: 540.4960 - val_mae: 541.1865\n",
      "Epoch 639/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 3.0910 - mae: 3.5962 - val_loss: 558.4116 - val_mae: 559.1020\n",
      "Epoch 640/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 2.9525 - mae: 3.4452 - val_loss: 551.7019 - val_mae: 552.3936\n",
      "Epoch 641/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.9675 - mae: 3.4706 - val_loss: 557.2302 - val_mae: 557.9221\n",
      "Epoch 642/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.8149 - mae: 3.3206 - val_loss: 564.7560 - val_mae: 565.4483\n",
      "Epoch 643/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 2.8233 - mae: 3.3182 - val_loss: 538.2545 - val_mae: 538.9443\n",
      "Epoch 644/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7589 - mae: 3.2465 - val_loss: 555.2902 - val_mae: 555.9820\n",
      "Epoch 645/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5641 - mae: 3.0470 - val_loss: 541.6891 - val_mae: 542.3788\n",
      "Epoch 646/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6871 - mae: 3.1880 - val_loss: 533.2643 - val_mae: 533.9531\n",
      "Epoch 647/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 40ms/step - loss: 2.6317 - mae: 3.1444 - val_loss: 520.3425 - val_mae: 521.0316\n",
      "Epoch 648/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 2.6952 - mae: 3.2164 - val_loss: 548.8998 - val_mae: 549.5916\n",
      "Epoch 649/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.6587 - mae: 3.1540 - val_loss: 516.5460 - val_mae: 517.2380\n",
      "Epoch 650/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5816 - mae: 3.0884 - val_loss: 516.7899 - val_mae: 517.4795\n",
      "Epoch 651/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6516 - mae: 3.1457 - val_loss: 542.6608 - val_mae: 543.3512\n",
      "Epoch 652/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.7593 - mae: 3.2581 - val_loss: 520.7119 - val_mae: 521.4043\n",
      "Epoch 653/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 2.4776 - mae: 2.9572 - val_loss: 561.1478 - val_mae: 561.8392\n",
      "Epoch 654/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.7938 - mae: 3.2824 - val_loss: 512.7294 - val_mae: 513.4204\n",
      "Epoch 655/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.6225 - mae: 4.1328 - val_loss: 521.8676 - val_mae: 522.5546\n",
      "Epoch 656/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.0804 - mae: 3.5830 - val_loss: 548.5762 - val_mae: 549.2686\n",
      "Epoch 657/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 2.4592 - mae: 2.9690 - val_loss: 526.7147 - val_mae: 527.4051\n",
      "Epoch 658/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 2.6974 - mae: 3.1963 - val_loss: 524.4564 - val_mae: 525.1462\n",
      "Epoch 659/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7168 - mae: 3.1944 - val_loss: 534.0193 - val_mae: 534.7087\n",
      "Epoch 660/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 3.7955 - mae: 4.3034 - val_loss: 516.9089 - val_mae: 517.5997\n",
      "Epoch 661/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7512 - mae: 3.2559 - val_loss: 525.8086 - val_mae: 526.5002\n",
      "Epoch 662/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 2.7554 - mae: 3.2517 - val_loss: 530.1849 - val_mae: 530.8758\n",
      "Epoch 663/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.6417 - mae: 3.1249 - val_loss: 509.8610 - val_mae: 510.5518\n",
      "Epoch 664/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 2.7847 - mae: 3.2952 - val_loss: 520.5751 - val_mae: 521.2646\n",
      "Epoch 665/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 2.4928 - mae: 2.9806 - val_loss: 517.8701 - val_mae: 518.5607\n",
      "Epoch 666/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.5867 - mae: 3.0618 - val_loss: 513.0068 - val_mae: 513.6977\n",
      "Epoch 667/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 2.5084 - mae: 2.9953 - val_loss: 515.6524 - val_mae: 516.3441\n",
      "Epoch 668/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5748 - mae: 3.0620 - val_loss: 524.8077 - val_mae: 525.4992\n",
      "Epoch 669/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 2.6011 - mae: 3.0859 - val_loss: 525.4446 - val_mae: 526.1357\n",
      "Epoch 670/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 2.6712 - mae: 3.1815 - val_loss: 526.1851 - val_mae: 526.8760\n",
      "Epoch 671/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 2.5055 - mae: 2.9894 - val_loss: 514.5989 - val_mae: 515.2874\n",
      "Epoch 672/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 2.8644 - mae: 3.3665 - val_loss: 512.2518 - val_mae: 512.9427\n",
      "Epoch 673/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 3.1269 - mae: 3.6371 - val_loss: 524.8688 - val_mae: 525.5596\n",
      "Epoch 674/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 2.6553 - mae: 3.1519 - val_loss: 507.0933 - val_mae: 507.7840\n",
      "Epoch 675/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 2.4278 - mae: 2.8964 - val_loss: 514.4141 - val_mae: 515.1026\n",
      "Epoch 676/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 2.5955 - mae: 3.1003 - val_loss: 538.6647 - val_mae: 539.3550\n",
      "Epoch 677/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.5672 - mae: 3.0619 - val_loss: 518.0915 - val_mae: 518.7821\n",
      "Epoch 678/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.7111 - mae: 3.2123 - val_loss: 503.1549 - val_mae: 503.8451\n",
      "Epoch 679/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 2.8683 - mae: 3.3770 - val_loss: 486.2921 - val_mae: 486.9837\n",
      "Epoch 680/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 2.8934 - mae: 3.4094 - val_loss: 517.5568 - val_mae: 518.2476\n",
      "Epoch 681/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 2.7372 - mae: 3.2499 - val_loss: 511.7303 - val_mae: 512.4213\n",
      "Epoch 682/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 2.7034 - mae: 3.1956 - val_loss: 527.6526 - val_mae: 528.3450\n",
      "Epoch 683/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.8235 - mae: 3.3254 - val_loss: 525.7500 - val_mae: 526.4408\n",
      "Epoch 684/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.5168 - mae: 3.0031 - val_loss: 521.4745 - val_mae: 522.1661\n",
      "Epoch 685/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.1586 - mae: 2.6399 - val_loss: 529.3500 - val_mae: 530.0399\n",
      "Epoch 686/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.3462 - mae: 2.8165 - val_loss: 509.2616 - val_mae: 509.9535\n",
      "Epoch 687/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.9644 - mae: 3.4355 - val_loss: 524.2357 - val_mae: 524.9263\n",
      "Epoch 688/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 2.8756 - mae: 3.3830 - val_loss: 542.2601 - val_mae: 542.9519\n",
      "Epoch 689/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 2.7179 - mae: 3.2250 - val_loss: 541.4784 - val_mae: 542.1679\n",
      "Epoch 690/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 2.6079 - mae: 3.1185 - val_loss: 521.1216 - val_mae: 521.8141\n",
      "Epoch 691/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.7486 - mae: 3.2441 - val_loss: 517.4266 - val_mae: 518.1167\n",
      "Epoch 692/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.7363 - mae: 3.2238 - val_loss: 522.8546 - val_mae: 523.5469\n",
      "Epoch 693/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.6614 - mae: 3.1769 - val_loss: 516.6548 - val_mae: 517.3456\n",
      "Epoch 694/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 2.6785 - mae: 3.1777 - val_loss: 503.2682 - val_mae: 503.9600\n",
      "Epoch 695/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.4647 - mae: 2.9550 - val_loss: 522.5080 - val_mae: 523.2009\n",
      "Epoch 696/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.5645 - mae: 3.0636 - val_loss: 512.7396 - val_mae: 513.4312\n",
      "Epoch 697/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.6557 - mae: 3.1611 - val_loss: 515.9438 - val_mae: 516.6357\n",
      "Epoch 698/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.6446 - mae: 3.1375 - val_loss: 509.9485 - val_mae: 510.6387\n",
      "Epoch 699/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 2.6607 - mae: 3.1731 - val_loss: 506.1274 - val_mae: 506.8186\n",
      "Epoch 700/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 3.1319 - mae: 3.6294 - val_loss: 507.4495 - val_mae: 508.1416\n",
      "Epoch 701/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 2.8999 - mae: 3.4116 - val_loss: 508.1480 - val_mae: 508.8394\n",
      "Epoch 702/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 3.0663 - mae: 3.5646 - val_loss: 505.0113 - val_mae: 505.7012\n",
      "Epoch 703/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 2.6889 - mae: 3.1790 - val_loss: 495.3758 - val_mae: 496.0667\n",
      "Epoch 704/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 2.4122 - mae: 2.8899 - val_loss: 509.6235 - val_mae: 510.3153\n",
      "Epoch 705/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.1416 - mae: 2.6124 - val_loss: 529.4851 - val_mae: 530.1767\n",
      "Epoch 706/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 38ms/step - loss: 2.2134 - mae: 2.6878 - val_loss: 520.2076 - val_mae: 520.8987\n",
      "Epoch 707/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 2.8425 - mae: 3.3282 - val_loss: 495.9177 - val_mae: 496.6080\n",
      "Epoch 708/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 3.0479 - mae: 3.5336 - val_loss: 500.1483 - val_mae: 500.8389\n",
      "Epoch 709/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 2.8145 - mae: 3.3141 - val_loss: 511.6517 - val_mae: 512.3442\n",
      "Epoch 710/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.8547 - mae: 3.3574 - val_loss: 518.5391 - val_mae: 519.2311\n",
      "Epoch 711/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.7488 - mae: 3.2533 - val_loss: 548.5066 - val_mae: 549.1962\n",
      "Epoch 712/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 3.2925 - mae: 3.7969 - val_loss: 491.6582 - val_mae: 492.3494\n",
      "Epoch 713/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.3999 - mae: 2.8943 - val_loss: 512.4915 - val_mae: 513.1819\n",
      "Epoch 714/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 2.7271 - mae: 3.2287 - val_loss: 492.7649 - val_mae: 493.4561\n",
      "Epoch 715/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 2.6680 - mae: 3.1651 - val_loss: 525.1039 - val_mae: 525.7955\n",
      "Epoch 716/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 2.6532 - mae: 3.1454 - val_loss: 479.6326 - val_mae: 480.3212\n",
      "Epoch 717/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.1663 - mae: 2.6451 - val_loss: 511.1435 - val_mae: 511.8346\n",
      "Epoch 718/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.2550 - mae: 2.7392 - val_loss: 508.5563 - val_mae: 509.2470\n",
      "Epoch 719/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 2.7056 - mae: 3.1937 - val_loss: 524.3139 - val_mae: 525.0059\n",
      "Epoch 720/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 3.1884 - mae: 3.6959 - val_loss: 513.8831 - val_mae: 514.5737\n",
      "Epoch 721/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 2.6747 - mae: 3.1617 - val_loss: 498.3502 - val_mae: 499.0423\n",
      "Epoch 722/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 2.4344 - mae: 2.9103 - val_loss: 507.4979 - val_mae: 508.1883\n",
      "Epoch 723/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 2.3234 - mae: 2.7893 - val_loss: 510.5428 - val_mae: 511.2343\n",
      "Epoch 724/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 2.6154 - mae: 3.0826 - val_loss: 509.5542 - val_mae: 510.2448\n",
      "Epoch 725/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 2.6709 - mae: 3.1614 - val_loss: 508.8664 - val_mae: 509.5581\n",
      "Epoch 726/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 2.3051 - mae: 2.7850 - val_loss: 503.6903 - val_mae: 504.3816\n",
      "Epoch 727/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 2.5163 - mae: 3.0089 - val_loss: 497.1217 - val_mae: 497.8128\n",
      "Epoch 728/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 2.3479 - mae: 2.8276 - val_loss: 518.6422 - val_mae: 519.3343\n",
      "Epoch 729/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 2.8989 - mae: 3.3878 - val_loss: 508.2798 - val_mae: 508.9716\n",
      "Epoch 730/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 2.3179 - mae: 2.7950 - val_loss: 510.3062 - val_mae: 510.9976\n",
      "Epoch 731/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.3534 - mae: 2.8418 - val_loss: 514.3768 - val_mae: 515.0684\n",
      "Epoch 732/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 2.3343 - mae: 2.8315 - val_loss: 520.7863 - val_mae: 521.4760\n",
      "Epoch 733/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.2835 - mae: 2.7684 - val_loss: 497.7929 - val_mae: 498.4849\n",
      "Epoch 734/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.7953 - mae: 3.2969 - val_loss: 517.5678 - val_mae: 518.2593\n",
      "Epoch 735/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.4405 - mae: 2.9254 - val_loss: 526.1198 - val_mae: 526.8119\n",
      "Epoch 736/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 2.5077 - mae: 2.9874 - val_loss: 530.1848 - val_mae: 530.8765\n",
      "Epoch 737/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 2.4167 - mae: 2.9032 - val_loss: 501.2100 - val_mae: 501.9007\n",
      "Epoch 738/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 3.1689 - mae: 3.6709 - val_loss: 508.9297 - val_mae: 509.6204\n",
      "Epoch 739/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.4612 - mae: 2.9534 - val_loss: 494.0161 - val_mae: 494.7082\n",
      "Epoch 740/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 2.7634 - mae: 3.2656 - val_loss: 499.7075 - val_mae: 500.3985\n",
      "Epoch 741/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 2.5144 - mae: 3.0006 - val_loss: 507.2213 - val_mae: 507.9139\n",
      "Epoch 742/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 2.3626 - mae: 2.8532 - val_loss: 499.1807 - val_mae: 499.8713\n",
      "Epoch 743/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.2817 - mae: 2.7604 - val_loss: 508.7534 - val_mae: 509.4446\n",
      "Epoch 744/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.3506 - mae: 2.8278 - val_loss: 508.2942 - val_mae: 508.9868\n",
      "Epoch 745/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 2.7873 - mae: 3.2907 - val_loss: 517.4139 - val_mae: 518.1056\n",
      "Epoch 746/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 2.2526 - mae: 2.7354 - val_loss: 507.1277 - val_mae: 507.8188\n",
      "Epoch 747/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.1271 - mae: 2.6033 - val_loss: 519.6885 - val_mae: 520.3810\n",
      "Epoch 748/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 2.3133 - mae: 2.7926 - val_loss: 483.8200 - val_mae: 484.5115\n",
      "Epoch 749/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.5398 - mae: 3.0194 - val_loss: 495.6955 - val_mae: 496.3854\n",
      "Epoch 750/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.4685 - mae: 2.9574 - val_loss: 489.8664 - val_mae: 490.5587\n",
      "Epoch 751/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6110 - mae: 3.0939 - val_loss: 476.0703 - val_mae: 476.7611\n",
      "Epoch 752/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 2.7943 - mae: 3.3028 - val_loss: 509.6815 - val_mae: 510.3734\n",
      "Epoch 753/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 2.4069 - mae: 2.8924 - val_loss: 503.4166 - val_mae: 504.1082\n",
      "Epoch 754/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 2.5129 - mae: 2.9959 - val_loss: 500.4681 - val_mae: 501.1608\n",
      "Epoch 755/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.4997 - mae: 2.9845 - val_loss: 475.8560 - val_mae: 476.5486\n",
      "Epoch 756/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 2.1860 - mae: 2.6689 - val_loss: 487.3231 - val_mae: 488.0162\n",
      "Epoch 757/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.3428 - mae: 2.8287 - val_loss: 501.5432 - val_mae: 502.2359\n",
      "Epoch 758/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 2.1453 - mae: 2.6142 - val_loss: 498.2336 - val_mae: 498.9250\n",
      "Epoch 759/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 2.6113 - mae: 3.1117 - val_loss: 496.3641 - val_mae: 497.0564\n",
      "Epoch 760/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 2.3129 - mae: 2.7968 - val_loss: 496.7678 - val_mae: 497.4590\n",
      "Epoch 761/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 2.4826 - mae: 2.9741 - val_loss: 515.1982 - val_mae: 515.8893\n",
      "Epoch 762/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.1725 - mae: 2.6561 - val_loss: 485.0999 - val_mae: 485.7902\n",
      "Epoch 763/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 2.5270 - mae: 3.0100 - val_loss: 496.9087 - val_mae: 497.5989\n",
      "Epoch 764/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 2.4533 - mae: 2.9458 - val_loss: 505.9133 - val_mae: 506.6049\n",
      "Epoch 765/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 43ms/step - loss: 2.5854 - mae: 3.0733 - val_loss: 504.2257 - val_mae: 504.9182\n",
      "Epoch 766/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.1952 - mae: 2.6620 - val_loss: 492.7347 - val_mae: 493.4260\n",
      "Epoch 767/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 2.2650 - mae: 2.7481 - val_loss: 502.9972 - val_mae: 503.6897\n",
      "Epoch 768/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 2.2169 - mae: 2.6967 - val_loss: 493.9789 - val_mae: 494.6711\n",
      "Epoch 769/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.1023 - mae: 2.5888 - val_loss: 507.1130 - val_mae: 507.8036\n",
      "Epoch 770/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.2278 - mae: 2.7059 - val_loss: 499.9326 - val_mae: 500.6247\n",
      "Epoch 771/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.3321 - mae: 2.8239 - val_loss: 510.2798 - val_mae: 510.9722\n",
      "Epoch 772/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.3078 - mae: 2.7856 - val_loss: 500.7628 - val_mae: 501.4533\n",
      "Epoch 773/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 3.0986 - mae: 3.6069 - val_loss: 499.2650 - val_mae: 499.9555\n",
      "Epoch 774/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 2.4841 - mae: 2.9685 - val_loss: 494.7765 - val_mae: 495.4663\n",
      "Epoch 775/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 2.3180 - mae: 2.7936 - val_loss: 498.7486 - val_mae: 499.4388\n",
      "Epoch 776/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 2.1968 - mae: 2.6581 - val_loss: 511.5598 - val_mae: 512.2520\n",
      "Epoch 777/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 2.5589 - mae: 3.0503 - val_loss: 510.8645 - val_mae: 511.5560\n",
      "Epoch 778/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 2.5835 - mae: 3.0601 - val_loss: 507.3514 - val_mae: 508.0421\n",
      "Epoch 779/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.1306 - mae: 2.5972 - val_loss: 495.9744 - val_mae: 496.6668\n",
      "Epoch 780/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 2.0508 - mae: 2.5183 - val_loss: 491.7542 - val_mae: 492.4457\n",
      "Epoch 781/5000\n",
      "46/46 [==============================] - 3s 56ms/step - loss: 2.3527 - mae: 2.8260 - val_loss: 516.1594 - val_mae: 516.8507\n",
      "Epoch 782/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 2.1332 - mae: 2.5989 - val_loss: 526.6063 - val_mae: 527.2991\n",
      "Epoch 783/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 2.2862 - mae: 2.7709 - val_loss: 501.6321 - val_mae: 502.3245\n",
      "Epoch 784/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.0521 - mae: 2.5231 - val_loss: 512.4459 - val_mae: 513.1365\n",
      "Epoch 785/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 2.2854 - mae: 2.7562 - val_loss: 505.8893 - val_mae: 506.5803\n",
      "Epoch 786/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.0860 - mae: 2.5677 - val_loss: 508.0099 - val_mae: 508.6992\n",
      "Epoch 787/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 2.2230 - mae: 2.6857 - val_loss: 506.2310 - val_mae: 506.9225\n",
      "Epoch 788/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.4064 - mae: 2.8799 - val_loss: 485.8153 - val_mae: 486.5071\n",
      "Epoch 789/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 2.0833 - mae: 2.5556 - val_loss: 514.3284 - val_mae: 515.0192\n",
      "Epoch 790/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 1.9345 - mae: 2.3937 - val_loss: 516.8251 - val_mae: 517.5167\n",
      "Epoch 791/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 2.1589 - mae: 2.6328 - val_loss: 513.8493 - val_mae: 514.5413\n",
      "Epoch 792/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 2.4042 - mae: 2.8909 - val_loss: 498.4875 - val_mae: 499.1797\n",
      "Epoch 793/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 2.6697 - mae: 3.1612 - val_loss: 501.1356 - val_mae: 501.8246\n",
      "Epoch 794/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 2.5849 - mae: 3.0644 - val_loss: 508.2644 - val_mae: 508.9567\n",
      "Epoch 795/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 2.1438 - mae: 2.6267 - val_loss: 511.0667 - val_mae: 511.7571\n",
      "Epoch 796/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 2.4051 - mae: 2.8830 - val_loss: 490.6411 - val_mae: 491.3325\n",
      "Epoch 797/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.2187 - mae: 2.6873 - val_loss: 491.6312 - val_mae: 492.3234\n",
      "Epoch 798/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 2.2178 - mae: 2.6877 - val_loss: 500.9013 - val_mae: 501.5935\n",
      "Epoch 799/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 2.3444 - mae: 2.8392 - val_loss: 492.0388 - val_mae: 492.7314\n",
      "Epoch 800/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 2.2924 - mae: 2.7696 - val_loss: 494.3167 - val_mae: 495.0074\n",
      "Epoch 801/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 1.9909 - mae: 2.4441 - val_loss: 492.7462 - val_mae: 493.4378\n",
      "Epoch 802/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.4180 - mae: 2.9020 - val_loss: 504.1364 - val_mae: 504.8287\n",
      "Epoch 803/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.0980 - mae: 2.5897 - val_loss: 499.4063 - val_mae: 500.0982\n",
      "Epoch 804/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 2.2904 - mae: 2.7827 - val_loss: 477.7350 - val_mae: 478.4250\n",
      "Epoch 805/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 2.5403 - mae: 3.0341 - val_loss: 503.8755 - val_mae: 504.5668\n",
      "Epoch 806/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 2.4796 - mae: 2.9615 - val_loss: 492.4252 - val_mae: 493.1156\n",
      "Epoch 807/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 2.1264 - mae: 2.5912 - val_loss: 485.4791 - val_mae: 486.1704\n",
      "Epoch 808/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 2.2968 - mae: 2.7698 - val_loss: 496.3852 - val_mae: 497.0747\n",
      "Epoch 809/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 2.4177 - mae: 2.9022 - val_loss: 493.4324 - val_mae: 494.1232\n",
      "Epoch 810/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 1.9647 - mae: 2.4256 - val_loss: 526.7262 - val_mae: 527.4180\n",
      "Epoch 811/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.3818 - mae: 2.8584 - val_loss: 485.6955 - val_mae: 486.3882\n",
      "Epoch 812/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.7962 - mae: 3.2839 - val_loss: 502.4538 - val_mae: 503.1467\n",
      "Epoch 813/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.0416 - mae: 2.5126 - val_loss: 484.4549 - val_mae: 485.1454\n",
      "Epoch 814/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.1649 - mae: 2.6404 - val_loss: 486.7801 - val_mae: 487.4704\n",
      "Epoch 815/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 2.1708 - mae: 2.6267 - val_loss: 500.0934 - val_mae: 500.7855\n",
      "Epoch 816/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 2.0352 - mae: 2.5023 - val_loss: 480.8507 - val_mae: 481.5422\n",
      "Epoch 817/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.5489 - mae: 3.0437 - val_loss: 493.2177 - val_mae: 493.9095\n",
      "Epoch 818/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 2.0659 - mae: 2.5371 - val_loss: 497.5268 - val_mae: 498.2185\n",
      "Epoch 819/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 1.9483 - mae: 2.4033 - val_loss: 512.2383 - val_mae: 512.9302\n",
      "Epoch 820/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 1.8228 - mae: 2.2741 - val_loss: 499.3662 - val_mae: 500.0573\n",
      "Epoch 821/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.5116 - mae: 2.9861 - val_loss: 488.9490 - val_mae: 489.6407\n",
      "Epoch 822/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 2.3001 - mae: 2.7678 - val_loss: 503.9555 - val_mae: 504.6465\n",
      "Epoch 823/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 2.3317 - mae: 2.8114 - val_loss: 494.2492 - val_mae: 494.9416\n",
      "Epoch 824/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 46ms/step - loss: 2.4799 - mae: 2.9628 - val_loss: 494.4502 - val_mae: 495.1404\n",
      "Epoch 825/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 1.9673 - mae: 2.4374 - val_loss: 482.2236 - val_mae: 482.9150\n",
      "Epoch 826/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 1.9528 - mae: 2.4135 - val_loss: 486.6599 - val_mae: 487.3516\n",
      "Epoch 827/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 2.1902 - mae: 2.6877 - val_loss: 503.4198 - val_mae: 504.1128\n",
      "Epoch 828/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 2.1177 - mae: 2.6028 - val_loss: 489.5002 - val_mae: 490.1917\n",
      "Epoch 829/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 2.1224 - mae: 2.6141 - val_loss: 491.9387 - val_mae: 492.6286\n",
      "Epoch 830/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 2.1649 - mae: 2.6417 - val_loss: 484.2917 - val_mae: 484.9839\n",
      "Epoch 831/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.0928 - mae: 2.5694 - val_loss: 496.9359 - val_mae: 497.6265\n",
      "Epoch 832/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 1.8780 - mae: 2.3380 - val_loss: 481.1336 - val_mae: 481.8261\n",
      "Epoch 833/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.4246 - mae: 2.9086 - val_loss: 492.7117 - val_mae: 493.4030\n",
      "Epoch 834/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 2.8515 - mae: 3.3521 - val_loss: 497.9932 - val_mae: 498.6832\n",
      "Epoch 835/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 2.2633 - mae: 2.7409 - val_loss: 502.2773 - val_mae: 502.9680\n",
      "Epoch 836/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 1.8960 - mae: 2.3584 - val_loss: 492.4635 - val_mae: 493.1555\n",
      "Epoch 837/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.1368 - mae: 2.6242 - val_loss: 490.9375 - val_mae: 491.6290\n",
      "Epoch 838/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 2.7358 - mae: 3.2427 - val_loss: 506.2129 - val_mae: 506.9046\n",
      "Epoch 839/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.8234 - mae: 3.3206 - val_loss: 489.0206 - val_mae: 489.7127\n",
      "Epoch 840/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 1.9496 - mae: 2.4219 - val_loss: 474.8527 - val_mae: 475.5443\n",
      "Epoch 841/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 2.0284 - mae: 2.4904 - val_loss: 489.8716 - val_mae: 490.5638\n",
      "Epoch 842/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.3488 - mae: 2.8297 - val_loss: 486.2907 - val_mae: 486.9813\n",
      "Epoch 843/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 2.0985 - mae: 2.5693 - val_loss: 487.8109 - val_mae: 488.5022\n",
      "Epoch 844/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 2.6428 - mae: 3.1361 - val_loss: 503.1139 - val_mae: 503.8061\n",
      "Epoch 845/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 2.4322 - mae: 2.9067 - val_loss: 498.8659 - val_mae: 499.5586\n",
      "Epoch 846/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.2712 - mae: 2.7615 - val_loss: 498.0541 - val_mae: 498.7435\n",
      "Epoch 847/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 2.0932 - mae: 2.5680 - val_loss: 484.0259 - val_mae: 484.7162\n",
      "Epoch 848/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7588 - mae: 3.2491 - val_loss: 485.0796 - val_mae: 485.7715\n",
      "Epoch 849/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 2.2489 - mae: 2.7245 - val_loss: 472.2494 - val_mae: 472.9401\n",
      "Epoch 850/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 2.3265 - mae: 2.8105 - val_loss: 501.7680 - val_mae: 502.4597\n",
      "Epoch 851/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.0875 - mae: 2.5461 - val_loss: 484.7836 - val_mae: 485.4755\n",
      "Epoch 852/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 1.9427 - mae: 2.4005 - val_loss: 478.7814 - val_mae: 479.4711\n",
      "Epoch 853/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.1605 - mae: 2.6393 - val_loss: 474.4976 - val_mae: 475.1891\n",
      "Epoch 854/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 2.1930 - mae: 2.6567 - val_loss: 480.5471 - val_mae: 481.2393\n",
      "Epoch 855/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.1786 - mae: 2.6535 - val_loss: 477.8076 - val_mae: 478.4994\n",
      "Epoch 856/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 1.9411 - mae: 2.4089 - val_loss: 478.9865 - val_mae: 479.6776\n",
      "Epoch 857/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 1.8115 - mae: 2.2748 - val_loss: 486.3839 - val_mae: 487.0762\n",
      "Epoch 858/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 2.0699 - mae: 2.5396 - val_loss: 487.1934 - val_mae: 487.8855\n",
      "Epoch 859/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 1.7688 - mae: 2.2245 - val_loss: 482.2648 - val_mae: 482.9555\n",
      "Epoch 860/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 2.1619 - mae: 2.6282 - val_loss: 486.3718 - val_mae: 487.0634\n",
      "Epoch 861/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.0310 - mae: 2.5097 - val_loss: 478.3956 - val_mae: 479.0873\n",
      "Epoch 862/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 2.1676 - mae: 2.6383 - val_loss: 467.5888 - val_mae: 468.2805\n",
      "Epoch 863/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.3068 - mae: 2.7824 - val_loss: 472.8673 - val_mae: 473.5580\n",
      "Epoch 864/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.1764 - mae: 2.6535 - val_loss: 472.2353 - val_mae: 472.9275\n",
      "Epoch 865/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 1.8556 - mae: 2.3243 - val_loss: 481.0399 - val_mae: 481.7318\n",
      "Epoch 866/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.8094 - mae: 2.2634 - val_loss: 462.3029 - val_mae: 462.9945\n",
      "Epoch 867/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 1.7163 - mae: 2.1681 - val_loss: 477.3736 - val_mae: 478.0630\n",
      "Epoch 868/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 1.9845 - mae: 2.4434 - val_loss: 488.2805 - val_mae: 488.9720\n",
      "Epoch 869/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.0315 - mae: 2.4959 - val_loss: 482.7288 - val_mae: 483.4196\n",
      "Epoch 870/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.3350 - mae: 2.8212 - val_loss: 466.2502 - val_mae: 466.9415\n",
      "Epoch 871/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 2.1170 - mae: 2.5807 - val_loss: 473.2688 - val_mae: 473.9594\n",
      "Epoch 872/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.2890 - mae: 2.7659 - val_loss: 471.3118 - val_mae: 472.0032\n",
      "Epoch 873/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 2.0590 - mae: 2.5198 - val_loss: 491.8390 - val_mae: 492.5296\n",
      "Epoch 874/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 1.9536 - mae: 2.4069 - val_loss: 481.2498 - val_mae: 481.9399\n",
      "Epoch 875/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 2.0626 - mae: 2.5208 - val_loss: 477.7233 - val_mae: 478.4158\n",
      "Epoch 876/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.8178 - mae: 2.2645 - val_loss: 500.8886 - val_mae: 501.5798\n",
      "Epoch 877/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 2.4825 - mae: 2.9788 - val_loss: 480.1869 - val_mae: 480.8783\n",
      "Epoch 878/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 2.1895 - mae: 2.6528 - val_loss: 487.5592 - val_mae: 488.2497\n",
      "Epoch 879/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.2160 - mae: 2.6937 - val_loss: 482.1906 - val_mae: 482.8812\n",
      "Epoch 880/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 2.1036 - mae: 2.5729 - val_loss: 483.4567 - val_mae: 484.1476\n",
      "Epoch 881/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 2.0073 - mae: 2.4811 - val_loss: 476.8239 - val_mae: 477.5156\n",
      "Epoch 882/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 2.1476 - mae: 2.6312 - val_loss: 477.5798 - val_mae: 478.2711\n",
      "Epoch 883/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 40ms/step - loss: 2.2363 - mae: 2.7089 - val_loss: 476.2572 - val_mae: 476.9476\n",
      "Epoch 884/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.0597 - mae: 2.5304 - val_loss: 482.3515 - val_mae: 483.0418\n",
      "Epoch 885/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 1.9820 - mae: 2.4330 - val_loss: 473.9040 - val_mae: 474.5969\n",
      "Epoch 886/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 1.9565 - mae: 2.4223 - val_loss: 488.7750 - val_mae: 489.4667\n",
      "Epoch 887/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 1.7128 - mae: 2.1711 - val_loss: 466.4124 - val_mae: 467.1021\n",
      "Epoch 888/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 1.7936 - mae: 2.2510 - val_loss: 459.1736 - val_mae: 459.8641\n",
      "Epoch 889/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 1.9396 - mae: 2.3991 - val_loss: 472.7050 - val_mae: 473.3956\n",
      "Epoch 890/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 1.9564 - mae: 2.4251 - val_loss: 482.3160 - val_mae: 483.0063\n",
      "Epoch 891/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 2.2879 - mae: 2.7763 - val_loss: 445.2245 - val_mae: 445.9162\n",
      "Epoch 892/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.1957 - mae: 2.6730 - val_loss: 482.0774 - val_mae: 482.7690\n",
      "Epoch 893/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 1.8188 - mae: 2.2760 - val_loss: 451.6564 - val_mae: 452.3485\n",
      "Epoch 894/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 2.1040 - mae: 2.5713 - val_loss: 471.6115 - val_mae: 472.3020\n",
      "Epoch 895/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 1.8112 - mae: 2.2859 - val_loss: 477.3584 - val_mae: 478.0510\n",
      "Epoch 896/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 2.0264 - mae: 2.4882 - val_loss: 465.1095 - val_mae: 465.8013\n",
      "Epoch 897/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 2.0283 - mae: 2.5026 - val_loss: 470.3894 - val_mae: 471.0812\n",
      "Epoch 898/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.6899 - mae: 2.1283 - val_loss: 468.0609 - val_mae: 468.7524\n",
      "Epoch 899/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 1.7353 - mae: 2.1873 - val_loss: 461.5059 - val_mae: 462.1980\n",
      "Epoch 900/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 1.8404 - mae: 2.3109 - val_loss: 468.9575 - val_mae: 469.6481\n",
      "Epoch 901/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.2574 - mae: 2.7391 - val_loss: 466.2788 - val_mae: 466.9700\n",
      "Epoch 902/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 1.8290 - mae: 2.2958 - val_loss: 483.2068 - val_mae: 483.8986\n",
      "Epoch 903/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.0446 - mae: 2.5095 - val_loss: 460.6827 - val_mae: 461.3747\n",
      "Epoch 904/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 1.8982 - mae: 2.3606 - val_loss: 478.5017 - val_mae: 479.1935\n",
      "Epoch 905/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 2.2559 - mae: 2.7382 - val_loss: 483.2063 - val_mae: 483.8981\n",
      "Epoch 906/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 1.9795 - mae: 2.4512 - val_loss: 460.9790 - val_mae: 461.6697\n",
      "Epoch 907/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.0314 - mae: 2.5034 - val_loss: 468.8345 - val_mae: 469.5266\n",
      "Epoch 908/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.3847 - mae: 2.8708 - val_loss: 470.6241 - val_mae: 471.3159\n",
      "Epoch 909/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.1482 - mae: 2.6132 - val_loss: 479.4132 - val_mae: 480.1057\n",
      "Epoch 910/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.2455 - mae: 2.7254 - val_loss: 468.2869 - val_mae: 468.9770\n",
      "Epoch 911/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.5974 - mae: 3.0974 - val_loss: 469.7217 - val_mae: 470.4130\n",
      "Epoch 912/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.5190 - mae: 3.0156 - val_loss: 466.5435 - val_mae: 467.2350\n",
      "Epoch 913/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 2.5112 - mae: 3.0121 - val_loss: 472.0056 - val_mae: 472.6967\n",
      "Epoch 914/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.9751 - mae: 3.4677 - val_loss: 448.0893 - val_mae: 448.7810\n",
      "Epoch 915/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.8208 - mae: 3.3104 - val_loss: 453.1349 - val_mae: 453.8252\n",
      "Epoch 916/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.4711 - mae: 2.9533 - val_loss: 476.6480 - val_mae: 477.3399\n",
      "Epoch 917/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.3224 - mae: 2.8091 - val_loss: 459.1055 - val_mae: 459.7975\n",
      "Epoch 918/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 2.3853 - mae: 2.8668 - val_loss: 450.5569 - val_mae: 451.2495\n",
      "Epoch 919/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 2.0223 - mae: 2.4963 - val_loss: 468.0615 - val_mae: 468.7545\n",
      "Epoch 920/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.1054 - mae: 2.5657 - val_loss: 468.0650 - val_mae: 468.7551\n",
      "Epoch 921/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 1.9804 - mae: 2.4582 - val_loss: 467.4039 - val_mae: 468.0912\n",
      "Epoch 922/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 2.4332 - mae: 2.9071 - val_loss: 464.8376 - val_mae: 465.5299\n",
      "Epoch 923/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.1697 - mae: 2.6391 - val_loss: 465.8538 - val_mae: 466.5454\n",
      "Epoch 924/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 2.1819 - mae: 2.6490 - val_loss: 466.1241 - val_mae: 466.8169\n",
      "Epoch 925/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 2.3607 - mae: 2.8477 - val_loss: 464.5649 - val_mae: 465.2577\n",
      "Epoch 926/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 1.9750 - mae: 2.4425 - val_loss: 471.1144 - val_mae: 471.8046\n",
      "Epoch 927/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 1.9073 - mae: 2.3755 - val_loss: 484.5115 - val_mae: 485.2044\n",
      "Epoch 928/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 2.1564 - mae: 2.6327 - val_loss: 457.0040 - val_mae: 457.6938\n",
      "Epoch 929/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 2.2230 - mae: 2.7098 - val_loss: 461.5142 - val_mae: 462.2038\n",
      "Epoch 930/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.2309 - mae: 2.7185 - val_loss: 465.0639 - val_mae: 465.7546\n",
      "Epoch 931/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 1.7346 - mae: 2.1792 - val_loss: 464.1957 - val_mae: 464.8874\n",
      "Epoch 932/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.0566 - mae: 2.5133 - val_loss: 462.0348 - val_mae: 462.7270\n",
      "Epoch 933/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 2.0127 - mae: 2.4934 - val_loss: 458.7785 - val_mae: 459.4704\n",
      "Epoch 934/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.9518 - mae: 2.4256 - val_loss: 469.5438 - val_mae: 470.2359\n",
      "Epoch 935/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 1.7170 - mae: 2.1626 - val_loss: 464.1804 - val_mae: 464.8709\n",
      "Epoch 936/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 1.7919 - mae: 2.2385 - val_loss: 469.0815 - val_mae: 469.7711\n",
      "Epoch 937/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.1829 - mae: 2.6548 - val_loss: 457.3998 - val_mae: 458.0910\n",
      "Epoch 938/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 2.0891 - mae: 2.5697 - val_loss: 470.5274 - val_mae: 471.2188\n",
      "Epoch 939/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 1.9816 - mae: 2.4644 - val_loss: 467.5989 - val_mae: 468.2906\n",
      "Epoch 940/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 2.1670 - mae: 2.6400 - val_loss: 462.5367 - val_mae: 463.2267\n",
      "Epoch 941/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 2.0776 - mae: 2.5483 - val_loss: 463.9073 - val_mae: 464.5985\n",
      "Epoch 942/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 40ms/step - loss: 1.8359 - mae: 2.2815 - val_loss: 476.2221 - val_mae: 476.9140\n",
      "Epoch 943/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.7331 - mae: 2.1868 - val_loss: 464.2567 - val_mae: 464.9486\n",
      "Epoch 944/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 1.7602 - mae: 2.1997 - val_loss: 460.1455 - val_mae: 460.8370\n",
      "Epoch 945/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 2.1210 - mae: 2.5832 - val_loss: 476.1364 - val_mae: 476.8272\n",
      "Epoch 946/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 1.9777 - mae: 2.4387 - val_loss: 457.7319 - val_mae: 458.4245\n",
      "Epoch 947/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 1.8058 - mae: 2.2620 - val_loss: 473.3407 - val_mae: 474.0309\n",
      "Epoch 948/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 1.6808 - mae: 2.1225 - val_loss: 470.1144 - val_mae: 470.8070\n",
      "Epoch 949/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 1.7671 - mae: 2.2153 - val_loss: 454.0628 - val_mae: 454.7537\n",
      "Epoch 950/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 1.9580 - mae: 2.4166 - val_loss: 459.5631 - val_mae: 460.2550\n",
      "Epoch 951/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 1.7511 - mae: 2.1999 - val_loss: 458.4511 - val_mae: 459.1419\n",
      "Epoch 952/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.2471 - mae: 2.7020 - val_loss: 475.2331 - val_mae: 475.9247\n",
      "Epoch 953/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.0622 - mae: 2.5293 - val_loss: 471.0875 - val_mae: 471.7794\n",
      "Epoch 954/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 2.1508 - mae: 2.6150 - val_loss: 473.0440 - val_mae: 473.7363\n",
      "Epoch 955/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 1.6525 - mae: 2.0919 - val_loss: 464.4028 - val_mae: 465.0949\n",
      "Epoch 956/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.2783 - mae: 2.7478 - val_loss: 480.2739 - val_mae: 480.9656\n",
      "Epoch 957/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 2.2152 - mae: 2.6803 - val_loss: 462.9477 - val_mae: 463.6386\n",
      "Epoch 958/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 2.0092 - mae: 2.4653 - val_loss: 466.0682 - val_mae: 466.7611\n",
      "Epoch 959/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 2.0654 - mae: 2.5247 - val_loss: 468.9109 - val_mae: 469.6022\n",
      "Epoch 960/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 1.8935 - mae: 2.3516 - val_loss: 466.8524 - val_mae: 467.5452\n",
      "Epoch 961/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 1.9434 - mae: 2.4280 - val_loss: 463.7946 - val_mae: 464.4865\n",
      "Epoch 962/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 2.1246 - mae: 2.6089 - val_loss: 485.0262 - val_mae: 485.7180\n",
      "Epoch 963/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.2088 - mae: 2.6922 - val_loss: 464.9311 - val_mae: 465.6231\n",
      "Epoch 964/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 1.7420 - mae: 2.2044 - val_loss: 481.5566 - val_mae: 482.2474\n",
      "Epoch 965/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 1.8879 - mae: 2.3560 - val_loss: 461.5775 - val_mae: 462.2683\n",
      "Epoch 966/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 1.6698 - mae: 2.1178 - val_loss: 464.2029 - val_mae: 464.8942\n",
      "Epoch 967/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 1.9462 - mae: 2.4108 - val_loss: 458.4844 - val_mae: 459.1736\n",
      "Epoch 968/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 1.9824 - mae: 2.4604 - val_loss: 473.7068 - val_mae: 474.3986\n",
      "Epoch 969/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 1.7500 - mae: 2.2097 - val_loss: 458.0412 - val_mae: 458.7329\n",
      "Epoch 970/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 1.7790 - mae: 2.2377 - val_loss: 466.7959 - val_mae: 467.4876\n",
      "Epoch 971/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.2286 - mae: 2.7076 - val_loss: 470.7487 - val_mae: 471.4377\n",
      "Epoch 972/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.2914 - mae: 2.7853 - val_loss: 477.8022 - val_mae: 478.4951\n",
      "Epoch 973/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.1156 - mae: 2.5808 - val_loss: 452.8715 - val_mae: 453.5603\n",
      "Epoch 974/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 2.0212 - mae: 2.5033 - val_loss: 444.8271 - val_mae: 445.5181\n",
      "Epoch 975/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 1.8306 - mae: 2.2922 - val_loss: 473.6013 - val_mae: 474.2920\n",
      "Epoch 976/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 1.5671 - mae: 2.0229 - val_loss: 469.2761 - val_mae: 469.9659\n",
      "Epoch 977/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 2.0624 - mae: 2.5297 - val_loss: 475.7595 - val_mae: 476.4513\n",
      "Epoch 978/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 2.0105 - mae: 2.4730 - val_loss: 447.4233 - val_mae: 448.1141\n",
      "Epoch 979/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 2.0268 - mae: 2.4852 - val_loss: 456.8585 - val_mae: 457.5494\n",
      "Epoch 980/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 1.8284 - mae: 2.2845 - val_loss: 446.9029 - val_mae: 447.5944\n",
      "Epoch 981/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 1.9629 - mae: 2.4236 - val_loss: 465.4408 - val_mae: 466.1325\n",
      "Epoch 982/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 1.6824 - mae: 2.1205 - val_loss: 460.4288 - val_mae: 461.1198\n",
      "Epoch 983/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 1.7079 - mae: 2.1624 - val_loss: 460.7225 - val_mae: 461.4126\n",
      "Epoch 984/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 1.8613 - mae: 2.3181 - val_loss: 460.6934 - val_mae: 461.3837\n",
      "Epoch 985/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 1.6278 - mae: 2.0773 - val_loss: 450.8751 - val_mae: 451.5659\n",
      "Epoch 986/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 1.9670 - mae: 2.4308 - val_loss: 447.0683 - val_mae: 447.7579\n",
      "Epoch 987/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 2.2753 - mae: 2.7595 - val_loss: 452.1192 - val_mae: 452.8087\n",
      "Epoch 988/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 1.9217 - mae: 2.4014 - val_loss: 449.9065 - val_mae: 450.5980\n",
      "Epoch 989/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 2.0362 - mae: 2.5192 - val_loss: 458.8903 - val_mae: 459.5806\n",
      "Epoch 990/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.0325 - mae: 2.4969 - val_loss: 470.1217 - val_mae: 470.8100\n",
      "Epoch 991/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 1.9334 - mae: 2.3930 - val_loss: 451.6689 - val_mae: 452.3594\n",
      "Epoch 992/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 1.9114 - mae: 2.3552 - val_loss: 455.7869 - val_mae: 456.4787\n",
      "Epoch 993/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 2.1794 - mae: 2.6531 - val_loss: 452.2124 - val_mae: 452.9029\n",
      "Epoch 994/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 1.7513 - mae: 2.2139 - val_loss: 467.7894 - val_mae: 468.4812\n",
      "Epoch 995/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 2.1842 - mae: 2.6592 - val_loss: 458.9773 - val_mae: 459.6693\n",
      "Epoch 996/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 2.3018 - mae: 2.7694 - val_loss: 452.0087 - val_mae: 452.7001\n",
      "Epoch 997/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 1.8069 - mae: 2.2578 - val_loss: 460.7530 - val_mae: 461.4449\n",
      "Epoch 998/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.8421 - mae: 2.3146 - val_loss: 455.2320 - val_mae: 455.9244\n",
      "Epoch 999/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 1.8226 - mae: 2.2781 - val_loss: 469.3135 - val_mae: 470.0057\n",
      "Epoch 1000/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 1.6753 - mae: 2.1096 - val_loss: 473.4690 - val_mae: 474.1614\n",
      "Epoch 1001/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 43ms/step - loss: 1.8191 - mae: 2.2782 - val_loss: 470.4169 - val_mae: 471.1087\n",
      "Epoch 1002/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.8384 - mae: 2.2961 - val_loss: 478.2242 - val_mae: 478.9166\n",
      "Epoch 1003/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 1.9432 - mae: 2.4106 - val_loss: 453.6729 - val_mae: 454.3633\n",
      "Epoch 1004/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 1.5155 - mae: 1.9621 - val_loss: 451.1996 - val_mae: 451.8907\n",
      "Epoch 1005/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 2.4191 - mae: 2.9197 - val_loss: 441.4799 - val_mae: 442.1708\n",
      "Epoch 1006/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.8430 - mae: 2.3227 - val_loss: 463.1436 - val_mae: 463.8344\n",
      "Epoch 1007/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 1.6808 - mae: 2.1426 - val_loss: 450.8284 - val_mae: 451.5208\n",
      "Epoch 1008/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 1.7386 - mae: 2.1885 - val_loss: 451.6219 - val_mae: 452.3130\n",
      "Epoch 1009/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 1.5574 - mae: 2.0028 - val_loss: 463.9618 - val_mae: 464.6523\n",
      "Epoch 1010/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 1.6336 - mae: 2.1049 - val_loss: 449.2739 - val_mae: 449.9642\n",
      "Epoch 1011/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 1.6774 - mae: 2.1222 - val_loss: 447.8817 - val_mae: 448.5737\n",
      "Epoch 1012/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 1.6296 - mae: 2.0610 - val_loss: 474.2023 - val_mae: 474.8926\n",
      "Epoch 1013/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 1.8765 - mae: 2.3566 - val_loss: 479.1543 - val_mae: 479.8436\n",
      "Epoch 1014/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 2.0430 - mae: 2.5165 - val_loss: 464.1829 - val_mae: 464.8733\n",
      "Epoch 1015/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 2.1006 - mae: 2.5734 - val_loss: 446.6369 - val_mae: 447.3287\n",
      "Epoch 1016/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 2.0086 - mae: 2.4873 - val_loss: 463.5580 - val_mae: 464.2503\n",
      "Epoch 1017/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.0848 - mae: 2.5541 - val_loss: 461.6456 - val_mae: 462.3376\n",
      "Epoch 1018/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 1.9686 - mae: 2.4370 - val_loss: 439.9438 - val_mae: 440.6356\n",
      "Epoch 1018: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3bb857bee0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train,Y_train, epochs=5000, batch_size=32, validation_data=(X_val,Y_val), callbacks=[earlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adf8814a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 1s 5ms/step\n",
      "18/18 [==============================] - 0s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_train_pred=regressor.predict(X_train)\n",
    "y_pred=regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.ravel()\n",
    "Y_train_pred = Y_train_pred.ravel().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train.ravel()\n",
    "Y_test = Y_test.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b0f090b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996465752101414"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for check\n",
    "r2_score(Y_train, Y_train_pred) #training score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e757ef47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2:-1.2314500902419723\n"
     ]
    }
   ],
   "source": [
    "r2=r2_score(Y_test[:-30],y_pred[:-30]) #score/ r^2\n",
    "print(f'r2:{r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00ef1c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2_oos\n",
    "def r2_oos(ret, pred):\n",
    "    sum_of_sq_res = np.nansum(np.power((ret-pred), 2))\n",
    "    sum_of_sq_total = np.nansum(np.power(ret, 2))\n",
    "    \n",
    "    return 1-sum_of_sq_res/sum_of_sq_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8969a6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_oos:0.6898357704628972\n"
     ]
    }
   ],
   "source": [
    "r2_oos = r2_oos(Y_test[:-30], y_pred[:-30])\n",
    "print(f'r2_oos:{r2_oos}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70b87143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae:1214.8053218170107\n",
      "rmse:1538.1666126807925\n",
      "mape:41.33285243815384\n"
     ]
    }
   ],
   "source": [
    "mae=mean_absolute_error(Y_test[:-30],y_pred[:-30]) #mae\n",
    "print(f'mae:{mae}')\n",
    "\n",
    "rmse=np.sqrt(mean_squared_error(Y_test[:-30],y_pred[:-30])) #rmse\n",
    "print(f'rmse:{rmse}')\n",
    "\n",
    "mape=mean_absolute_percentage_error(Y_test[:-30],y_pred[:-30]) #mape\n",
    "print(f'mape:{mape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb36caf",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5641115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-06-01</th>\n",
       "      <td>2149.0</td>\n",
       "      <td>1073.903320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-02</th>\n",
       "      <td>2080.0</td>\n",
       "      <td>913.336731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-03</th>\n",
       "      <td>2192.0</td>\n",
       "      <td>994.562317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-04</th>\n",
       "      <td>2305.0</td>\n",
       "      <td>1126.241455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-05</th>\n",
       "      <td>2250.0</td>\n",
       "      <td>818.895142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>856.523438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>818.233826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>925.182068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1162.354614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1010.347778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>547 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Y_test       y_pred\n",
       "Date                           \n",
       "2021-06-01  2149.0  1073.903320\n",
       "2021-06-02  2080.0   913.336731\n",
       "2021-06-03  2192.0   994.562317\n",
       "2021-06-04  2305.0  1126.241455\n",
       "2021-06-05  2250.0   818.895142\n",
       "...            ...          ...\n",
       "2022-11-25     NaN   856.523438\n",
       "2022-11-26     NaN   818.233826\n",
       "2022-11-27     NaN   925.182068\n",
       "2022-11-28     NaN  1162.354614\n",
       "2022-11-29     NaN  1010.347778\n",
       "\n",
       "[547 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_df = pd.DataFrame(zip(Y_test,y_pred),columns=['Y_test','y_pred'])\n",
    "pre_df.index = tmp_index\n",
    "pre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f4bd2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df['pred_returns'] = pre_df['y_pred'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b94aa95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_test</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>pred_returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-06-01</th>\n",
       "      <td>2149.0</td>\n",
       "      <td>1073.903320</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-02</th>\n",
       "      <td>2080.0</td>\n",
       "      <td>913.336731</td>\n",
       "      <td>-0.149517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-03</th>\n",
       "      <td>2192.0</td>\n",
       "      <td>994.562317</td>\n",
       "      <td>0.088933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-04</th>\n",
       "      <td>2305.0</td>\n",
       "      <td>1126.241455</td>\n",
       "      <td>0.132399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-05</th>\n",
       "      <td>2250.0</td>\n",
       "      <td>818.895142</td>\n",
       "      <td>-0.272896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>856.523438</td>\n",
       "      <td>-0.115288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>818.233826</td>\n",
       "      <td>-0.044704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>925.182068</td>\n",
       "      <td>0.130706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1162.354614</td>\n",
       "      <td>0.256352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1010.347778</td>\n",
       "      <td>-0.130775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>547 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Y_test       y_pred  pred_returns\n",
       "Date                                         \n",
       "2021-06-01  2149.0  1073.903320           NaN\n",
       "2021-06-02  2080.0   913.336731     -0.149517\n",
       "2021-06-03  2192.0   994.562317      0.088933\n",
       "2021-06-04  2305.0  1126.241455      0.132399\n",
       "2021-06-05  2250.0   818.895142     -0.272896\n",
       "...            ...          ...           ...\n",
       "2022-11-25     NaN   856.523438     -0.115288\n",
       "2022-11-26     NaN   818.233826     -0.044704\n",
       "2022-11-27     NaN   925.182068      0.130706\n",
       "2022-11-28     NaN  1162.354614      0.256352\n",
       "2022-11-29     NaN  1010.347778     -0.130775\n",
       "\n",
       "[547 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d9674c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(zip(Y_test,y_pred),columns=['Y_test','y_pred']).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "732393ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df.to_csv(\"../result/LSTM/eth_NN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!kdeconnect-cli -n TAS-AN00 --ping-msg 'Script complete!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Stock Market Predictor.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "0a952188e4bab49300a5758bda39ddc90e91f41f35dfe6ea820e496e515be371"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
