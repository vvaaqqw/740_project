{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TKAxbUFku8lD"
   },
   "source": [
    "# **Dependancies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oFJOnSzBk_uB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 17:25:11.295868: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import *\n",
    "from keras.callbacks import *\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from keras.layers import *\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "22PseW2xqQET"
   },
   "source": [
    "# **Loading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = pd.read_csv(\"../Data/train_ltc_selected_features.csv\")\n",
    "ltc = pd.read_csv(\"../Data/litecoin_Data.csv\")\n",
    "ltc['Date'] = pd.to_datetime(ltc['Date'])\n",
    "ltc = ltc.set_index(\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3000018/4014187506.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltcData['returns'] = ltcData['priceUSD'].pct_change().copy()\n"
     ]
    }
   ],
   "source": [
    "ltcData = ltc[selected.columns]\n",
    "ltcData['returns'] = ltcData['priceUSD'].pct_change().copy()\n",
    "Data = ltcData.drop(columns=['priceUSD'])\n",
    "Data = Data[1:]\n",
    "# divide X and Y\n",
    "X = Data.iloc[:,0:]\n",
    "#Y = Data['returns']   # 用returns的话就用这一行，然后把下一行comment掉\n",
    "Y = ltcData['priceUSD'].shift(-30)[1:] # 反之亦然\n",
    "# Split into three data sets\n",
    "X_train = X['2016-01-01':'2019-12-31']\n",
    "X_val = X['2020-01-01':'2021-05-31']\n",
    "X_test = X['2021-06-01':'2023-01-01']\n",
    "\n",
    "Y_train = Y['2016-01-01':'2019-12-31']\n",
    "Y_val = Y['2020-01-01':'2021-05-31']\n",
    "Y_test = Y['2021-06-01':'2023-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing mixmax, total=   0.0s\n",
      "[Pipeline] ............ (step 2 of 2) Processing robust, total=   0.0s\n"
     ]
    }
   ],
   "source": [
    "estimators=[]\n",
    "estimators.append(['mixmax',MinMaxScaler()])\n",
    "estimators.append(['robust',RobustScaler()])\n",
    "scale=Pipeline(estimators,verbose=True)\n",
    "scale.fit(X_train)\n",
    "X_train=scale.transform(X_train)\n",
    "X_test=scale.transform(X_test)\n",
    "X_val = scale.transform(X_val)\n",
    "tmp_index = Y_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.reshape(X_train,(X_train.shape[0],1,X_train.shape[1]))\n",
    "X_val=np.reshape(X_val,(X_val.shape[0],1,X_val.shape[1]))\n",
    "X_test=np.reshape(X_test,(X_test.shape[0],1,X_test.shape[1]))\n",
    "Y_train=Y_train.values\n",
    "Y_train=np.reshape(Y_train, (Y_train.shape[0],1,1))\n",
    "Y_val=Y_val.values\n",
    "Y_val=np.reshape(Y_val, (Y_val.shape[0],1,1))\n",
    "Y_test=Y_test.values\n",
    "Y_test=np.reshape(Y_test, (Y_test.shape[0],1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "NBZ9JgDTrHwV",
    "outputId": "40d0a5ca-682d-42d1-e08b-fd28df246868"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spectre/anaconda3/envs/tensorplustorch/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "adam=optimizers.Adam(lr=lr_schedule(0),amsgrad=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://medium.com/analytics-vidhya/hypertuning-a-lstm-with-keras-tuner-to-forecast-solar-irradiance-7da7577e96eb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 17:25:12.429172: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-04 17:25:12.430057: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "regressor = Sequential()\n",
    "regressor.add(Bidirectional(LSTM(350, return_sequences=True, activation='relu'), input_shape=(1, X_train.shape[2])))\n",
    "regressor.add(Bidirectional(LSTM(350, return_sequences=True, activation='relu')))\n",
    "regressor.add(Dense(1))\n",
    "regressor.compile(loss=\"logcosh\", optimizer=adam, metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0WWSdc7AxKV6"
   },
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=1000, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "46/46 [==============================] - 4s 46ms/step - loss: 42.4408 - mae: 43.1117 - val_loss: 55.2664 - val_mae: 55.9568\n",
      "Epoch 2/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 19.5023 - mae: 20.1233 - val_loss: 41.9508 - val_mae: 42.6413\n",
      "Epoch 3/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 14.7545 - mae: 15.3752 - val_loss: 32.5263 - val_mae: 33.2059\n",
      "Epoch 4/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 11.2857 - mae: 11.8885 - val_loss: 37.6521 - val_mae: 38.3361\n",
      "Epoch 5/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 9.0745 - mae: 9.6604 - val_loss: 42.0695 - val_mae: 42.7515\n",
      "Epoch 6/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 9.1695 - mae: 9.7471 - val_loss: 38.3298 - val_mae: 39.0100\n",
      "Epoch 7/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 8.3446 - mae: 8.9250 - val_loss: 39.4955 - val_mae: 40.1784\n",
      "Epoch 8/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 7.5598 - mae: 8.1364 - val_loss: 40.7781 - val_mae: 41.4551\n",
      "Epoch 9/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 7.2737 - mae: 7.8435 - val_loss: 41.6510 - val_mae: 42.3311\n",
      "Epoch 10/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 7.4350 - mae: 8.0070 - val_loss: 44.1053 - val_mae: 44.7831\n",
      "Epoch 11/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 6.9898 - mae: 7.5525 - val_loss: 43.6919 - val_mae: 44.3791\n",
      "Epoch 12/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 6.8828 - mae: 7.4378 - val_loss: 43.1736 - val_mae: 43.8560\n",
      "Epoch 13/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 6.3836 - mae: 6.9403 - val_loss: 44.0674 - val_mae: 44.7507\n",
      "Epoch 14/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 6.9337 - mae: 7.4944 - val_loss: 42.8760 - val_mae: 43.5606\n",
      "Epoch 15/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 6.1794 - mae: 6.7370 - val_loss: 43.2850 - val_mae: 43.9656\n",
      "Epoch 16/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 6.1780 - mae: 6.7278 - val_loss: 43.8345 - val_mae: 44.5151\n",
      "Epoch 17/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 5.7507 - mae: 6.3006 - val_loss: 46.3861 - val_mae: 47.0671\n",
      "Epoch 18/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 5.4086 - mae: 5.9556 - val_loss: 44.8854 - val_mae: 45.5660\n",
      "Epoch 19/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5.3515 - mae: 5.9051 - val_loss: 45.5931 - val_mae: 46.2767\n",
      "Epoch 20/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 5.3226 - mae: 5.8723 - val_loss: 45.5502 - val_mae: 46.2352\n",
      "Epoch 21/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 5.0728 - mae: 5.6240 - val_loss: 46.6177 - val_mae: 47.3011\n",
      "Epoch 22/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 4.8304 - mae: 5.3817 - val_loss: 45.3364 - val_mae: 46.0160\n",
      "Epoch 23/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 4.5550 - mae: 5.1023 - val_loss: 45.0426 - val_mae: 45.7257\n",
      "Epoch 24/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 4.8495 - mae: 5.3977 - val_loss: 45.6766 - val_mae: 46.3593\n",
      "Epoch 25/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 4.2521 - mae: 4.7972 - val_loss: 44.1728 - val_mae: 44.8539\n",
      "Epoch 26/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 4.5360 - mae: 5.0780 - val_loss: 45.9243 - val_mae: 46.6043\n",
      "Epoch 27/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 4.4364 - mae: 4.9775 - val_loss: 44.4558 - val_mae: 45.1373\n",
      "Epoch 28/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 4.0724 - mae: 4.6144 - val_loss: 45.3022 - val_mae: 45.9860\n",
      "Epoch 29/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 4.1995 - mae: 4.7391 - val_loss: 44.7978 - val_mae: 45.4822\n",
      "Epoch 30/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.8894 - mae: 4.4299 - val_loss: 44.7879 - val_mae: 45.4721\n",
      "Epoch 31/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 3.8729 - mae: 4.4182 - val_loss: 43.2449 - val_mae: 43.9234\n",
      "Epoch 32/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 3.9878 - mae: 4.5278 - val_loss: 41.4262 - val_mae: 42.1127\n",
      "Epoch 33/5000\n",
      "46/46 [==============================] - 2s 33ms/step - loss: 4.1346 - mae: 4.6804 - val_loss: 45.0662 - val_mae: 45.7459\n",
      "Epoch 34/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.4264 - mae: 3.9563 - val_loss: 44.1184 - val_mae: 44.7999\n",
      "Epoch 35/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 3.6279 - mae: 4.1687 - val_loss: 44.3228 - val_mae: 45.0028\n",
      "Epoch 36/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 3.5354 - mae: 4.0620 - val_loss: 44.8149 - val_mae: 45.4967\n",
      "Epoch 37/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.4253 - mae: 3.9570 - val_loss: 44.8792 - val_mae: 45.5662\n",
      "Epoch 38/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 3.3455 - mae: 3.8693 - val_loss: 44.6861 - val_mae: 45.3728\n",
      "Epoch 39/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 3.5321 - mae: 4.0574 - val_loss: 44.7253 - val_mae: 45.4106\n",
      "Epoch 40/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 3.6069 - mae: 4.1363 - val_loss: 45.0590 - val_mae: 45.7441\n",
      "Epoch 41/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 3.2096 - mae: 3.7284 - val_loss: 45.4707 - val_mae: 46.1577\n",
      "Epoch 42/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 3.3020 - mae: 3.8245 - val_loss: 46.9084 - val_mae: 47.5919\n",
      "Epoch 43/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 3.2547 - mae: 3.7744 - val_loss: 46.8121 - val_mae: 47.4940\n",
      "Epoch 44/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 3.5339 - mae: 4.0596 - val_loss: 45.8550 - val_mae: 46.5390\n",
      "Epoch 45/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 3.2118 - mae: 3.7268 - val_loss: 45.8677 - val_mae: 46.5535\n",
      "Epoch 46/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 3.5076 - mae: 4.0172 - val_loss: 47.2443 - val_mae: 47.9268\n",
      "Epoch 47/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 3.3293 - mae: 3.8388 - val_loss: 47.6271 - val_mae: 48.3076\n",
      "Epoch 48/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 3.1875 - mae: 3.6962 - val_loss: 47.1802 - val_mae: 47.8633\n",
      "Epoch 49/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 3.2693 - mae: 3.7730 - val_loss: 45.8626 - val_mae: 46.5476\n",
      "Epoch 50/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 2.9032 - mae: 3.4048 - val_loss: 45.5093 - val_mae: 46.1946\n",
      "Epoch 51/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 3.0394 - mae: 3.5496 - val_loss: 48.7409 - val_mae: 49.4162\n",
      "Epoch 52/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.9655 - mae: 3.4748 - val_loss: 45.5300 - val_mae: 46.2161\n",
      "Epoch 53/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 2.6236 - mae: 3.1215 - val_loss: 47.5685 - val_mae: 48.2558\n",
      "Epoch 54/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.4498 - mae: 2.9442 - val_loss: 45.7973 - val_mae: 46.4814\n",
      "Epoch 55/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.4368 - mae: 2.9283 - val_loss: 46.0319 - val_mae: 46.7160\n",
      "Epoch 56/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7340 - mae: 3.2400 - val_loss: 44.4947 - val_mae: 45.1788\n",
      "Epoch 57/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.7859 - mae: 3.2873 - val_loss: 46.2103 - val_mae: 46.8944\n",
      "Epoch 58/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.4734 - mae: 2.9626 - val_loss: 44.4397 - val_mae: 45.1238\n",
      "Epoch 59/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 2.4581 - mae: 2.9484 - val_loss: 45.6506 - val_mae: 46.3369\n",
      "Epoch 60/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 2.5844 - mae: 3.0813 - val_loss: 45.9219 - val_mae: 46.6099\n",
      "Epoch 61/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 39ms/step - loss: 2.5276 - mae: 3.0115 - val_loss: 45.7712 - val_mae: 46.4583\n",
      "Epoch 62/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 2.5729 - mae: 3.0637 - val_loss: 44.9373 - val_mae: 45.6242\n",
      "Epoch 63/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.4459 - mae: 2.9317 - val_loss: 45.4763 - val_mae: 46.1597\n",
      "Epoch 64/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 2.4744 - mae: 2.9519 - val_loss: 46.5958 - val_mae: 47.2826\n",
      "Epoch 65/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 2.4787 - mae: 2.9723 - val_loss: 45.7852 - val_mae: 46.4741\n",
      "Epoch 66/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 2.6297 - mae: 3.1178 - val_loss: 45.0732 - val_mae: 45.7583\n",
      "Epoch 67/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 2.5248 - mae: 3.0163 - val_loss: 46.0034 - val_mae: 46.6906\n",
      "Epoch 68/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 2.3335 - mae: 2.8164 - val_loss: 43.8799 - val_mae: 44.5630\n",
      "Epoch 69/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 2.5979 - mae: 3.0880 - val_loss: 46.9272 - val_mae: 47.6109\n",
      "Epoch 70/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 2.4516 - mae: 2.9436 - val_loss: 45.9249 - val_mae: 46.6103\n",
      "Epoch 71/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 2.3986 - mae: 2.8880 - val_loss: 44.2097 - val_mae: 44.8935\n",
      "Epoch 72/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.1846 - mae: 2.6605 - val_loss: 44.9777 - val_mae: 45.6637\n",
      "Epoch 73/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.3203 - mae: 2.7975 - val_loss: 45.0015 - val_mae: 45.6861\n",
      "Epoch 74/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 2.2250 - mae: 2.7069 - val_loss: 44.8257 - val_mae: 45.5140\n",
      "Epoch 75/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 2.2250 - mae: 2.6907 - val_loss: 44.3249 - val_mae: 45.0110\n",
      "Epoch 76/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 2.3119 - mae: 2.7887 - val_loss: 46.3924 - val_mae: 47.0752\n",
      "Epoch 77/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 2.6627 - mae: 3.1421 - val_loss: 45.6597 - val_mae: 46.3445\n",
      "Epoch 78/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 2.7704 - mae: 3.2425 - val_loss: 46.3509 - val_mae: 47.0346\n",
      "Epoch 79/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 2.3747 - mae: 2.8694 - val_loss: 44.3756 - val_mae: 45.0625\n",
      "Epoch 80/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 2.6182 - mae: 3.0965 - val_loss: 45.0614 - val_mae: 45.7457\n",
      "Epoch 81/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 2.1002 - mae: 2.5694 - val_loss: 44.5524 - val_mae: 45.2344\n",
      "Epoch 82/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 2.1906 - mae: 2.6596 - val_loss: 45.0420 - val_mae: 45.7225\n",
      "Epoch 83/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 2.4172 - mae: 2.9022 - val_loss: 46.1475 - val_mae: 46.8302\n",
      "Epoch 84/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.0068 - mae: 2.4878 - val_loss: 45.5373 - val_mae: 46.2207\n",
      "Epoch 85/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 1.9783 - mae: 2.4324 - val_loss: 44.8724 - val_mae: 45.5554\n",
      "Epoch 86/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 2.1790 - mae: 2.6562 - val_loss: 44.4672 - val_mae: 45.1499\n",
      "Epoch 87/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 2.1553 - mae: 2.6273 - val_loss: 44.4388 - val_mae: 45.1225\n",
      "Epoch 88/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 2.2245 - mae: 2.6956 - val_loss: 45.7910 - val_mae: 46.4751\n",
      "Epoch 89/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 1.8067 - mae: 2.2667 - val_loss: 44.7258 - val_mae: 45.4077\n",
      "Epoch 90/5000\n",
      "46/46 [==============================] - 2s 33ms/step - loss: 1.9889 - mae: 2.4609 - val_loss: 44.0277 - val_mae: 44.7094\n",
      "Epoch 91/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 2.0385 - mae: 2.4976 - val_loss: 46.4251 - val_mae: 47.1068\n",
      "Epoch 92/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 1.8955 - mae: 2.3619 - val_loss: 45.8178 - val_mae: 46.4996\n",
      "Epoch 93/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 2.1613 - mae: 2.6243 - val_loss: 45.2097 - val_mae: 45.8930\n",
      "Epoch 94/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 2.0562 - mae: 2.5370 - val_loss: 46.1949 - val_mae: 46.8765\n",
      "Epoch 95/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 2.2824 - mae: 2.7625 - val_loss: 44.8524 - val_mae: 45.5341\n",
      "Epoch 96/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 2.0713 - mae: 2.5345 - val_loss: 46.0080 - val_mae: 46.6895\n",
      "Epoch 97/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 1.9312 - mae: 2.3854 - val_loss: 46.1181 - val_mae: 46.8029\n",
      "Epoch 98/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 1.9561 - mae: 2.4153 - val_loss: 45.6629 - val_mae: 46.3481\n",
      "Epoch 99/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 1.9854 - mae: 2.4354 - val_loss: 45.4124 - val_mae: 46.0956\n",
      "Epoch 100/5000\n",
      "46/46 [==============================] - 2s 33ms/step - loss: 2.2122 - mae: 2.6755 - val_loss: 46.3960 - val_mae: 47.0788\n",
      "Epoch 101/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 2.2661 - mae: 2.7383 - val_loss: 45.2914 - val_mae: 45.9743\n",
      "Epoch 102/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 2.0337 - mae: 2.4911 - val_loss: 46.5138 - val_mae: 47.1957\n",
      "Epoch 103/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.8179 - mae: 2.2639 - val_loss: 44.8274 - val_mae: 45.5124\n",
      "Epoch 104/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 1.7353 - mae: 2.1833 - val_loss: 46.0607 - val_mae: 46.7469\n",
      "Epoch 105/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 1.8120 - mae: 2.2581 - val_loss: 46.2680 - val_mae: 46.9513\n",
      "Epoch 106/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.9485 - mae: 2.4148 - val_loss: 44.9426 - val_mae: 45.6277\n",
      "Epoch 107/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 1.9944 - mae: 2.4615 - val_loss: 45.0323 - val_mae: 45.7165\n",
      "Epoch 108/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 1.9331 - mae: 2.3912 - val_loss: 45.5125 - val_mae: 46.1990\n",
      "Epoch 109/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.7394 - mae: 2.1824 - val_loss: 45.9105 - val_mae: 46.5929\n",
      "Epoch 110/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 1.9324 - mae: 2.3880 - val_loss: 45.0693 - val_mae: 45.7555\n",
      "Epoch 111/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 1.8731 - mae: 2.3306 - val_loss: 45.8114 - val_mae: 46.4958\n",
      "Epoch 112/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 2.0442 - mae: 2.5090 - val_loss: 46.1915 - val_mae: 46.8808\n",
      "Epoch 113/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 1.8726 - mae: 2.3427 - val_loss: 46.0284 - val_mae: 46.7130\n",
      "Epoch 114/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 1.8987 - mae: 2.3640 - val_loss: 46.0602 - val_mae: 46.7444\n",
      "Epoch 115/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 1.8043 - mae: 2.2756 - val_loss: 46.0625 - val_mae: 46.7506\n",
      "Epoch 116/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 1.6762 - mae: 2.1331 - val_loss: 45.2266 - val_mae: 45.9133\n",
      "Epoch 117/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 1.6270 - mae: 2.0735 - val_loss: 44.3710 - val_mae: 45.0540\n",
      "Epoch 118/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 1.5533 - mae: 1.9884 - val_loss: 45.6230 - val_mae: 46.3076\n",
      "Epoch 119/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 1.6879 - mae: 2.1309 - val_loss: 45.7541 - val_mae: 46.4398\n",
      "Epoch 120/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 1.6495 - mae: 2.0963 - val_loss: 45.8209 - val_mae: 46.4993\n",
      "Epoch 121/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 37ms/step - loss: 1.7725 - mae: 2.2345 - val_loss: 45.7592 - val_mae: 46.4464\n",
      "Epoch 122/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 1.8533 - mae: 2.3060 - val_loss: 45.9872 - val_mae: 46.6728\n",
      "Epoch 123/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.7820 - mae: 2.2184 - val_loss: 46.0596 - val_mae: 46.7439\n",
      "Epoch 124/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.8555 - mae: 2.2996 - val_loss: 45.6965 - val_mae: 46.3814\n",
      "Epoch 125/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 1.4814 - mae: 1.9174 - val_loss: 45.5396 - val_mae: 46.2213\n",
      "Epoch 126/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.6165 - mae: 2.0612 - val_loss: 45.7742 - val_mae: 46.4580\n",
      "Epoch 127/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 1.8182 - mae: 2.2800 - val_loss: 46.7350 - val_mae: 47.4207\n",
      "Epoch 128/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 1.5112 - mae: 1.9384 - val_loss: 46.3724 - val_mae: 47.0569\n",
      "Epoch 129/5000\n",
      "46/46 [==============================] - 2s 33ms/step - loss: 1.6575 - mae: 2.1123 - val_loss: 45.3501 - val_mae: 46.0337\n",
      "Epoch 130/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 1.7101 - mae: 2.1738 - val_loss: 45.9770 - val_mae: 46.6627\n",
      "Epoch 131/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 1.5943 - mae: 2.0394 - val_loss: 44.9367 - val_mae: 45.6183\n",
      "Epoch 132/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 1.5950 - mae: 2.0369 - val_loss: 46.5998 - val_mae: 47.2832\n",
      "Epoch 133/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 1.7099 - mae: 2.1558 - val_loss: 46.0502 - val_mae: 46.7363\n",
      "Epoch 134/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 1.5817 - mae: 2.0190 - val_loss: 45.0098 - val_mae: 45.6945\n",
      "Epoch 135/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.5660 - mae: 1.9995 - val_loss: 45.4291 - val_mae: 46.1128\n",
      "Epoch 136/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 1.5048 - mae: 1.9299 - val_loss: 46.2680 - val_mae: 46.9548\n",
      "Epoch 137/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 1.5528 - mae: 1.9938 - val_loss: 45.3771 - val_mae: 46.0616\n",
      "Epoch 138/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 1.5590 - mae: 1.9968 - val_loss: 45.8652 - val_mae: 46.5486\n",
      "Epoch 139/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.6329 - mae: 2.0929 - val_loss: 45.6866 - val_mae: 46.3700\n",
      "Epoch 140/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 1.5796 - mae: 2.0133 - val_loss: 46.2298 - val_mae: 46.9125\n",
      "Epoch 141/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 1.7099 - mae: 2.1647 - val_loss: 45.6543 - val_mae: 46.3375\n",
      "Epoch 142/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 1.5962 - mae: 2.0357 - val_loss: 45.3237 - val_mae: 46.0084\n",
      "Epoch 143/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 1.6229 - mae: 2.0687 - val_loss: 45.4695 - val_mae: 46.1520\n",
      "Epoch 144/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 1.6694 - mae: 2.1012 - val_loss: 45.2286 - val_mae: 45.9107\n",
      "Epoch 145/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 1.6353 - mae: 2.0923 - val_loss: 45.4665 - val_mae: 46.1504\n",
      "Epoch 146/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 1.5306 - mae: 1.9716 - val_loss: 45.9773 - val_mae: 46.6636\n",
      "Epoch 147/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 1.4620 - mae: 1.9063 - val_loss: 45.8894 - val_mae: 46.5773\n",
      "Epoch 148/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.5577 - mae: 1.9946 - val_loss: 46.0585 - val_mae: 46.7431\n",
      "Epoch 149/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.5802 - mae: 1.9976 - val_loss: 44.8988 - val_mae: 45.5840\n",
      "Epoch 150/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 1.5309 - mae: 1.9712 - val_loss: 45.4230 - val_mae: 46.1075\n",
      "Epoch 151/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 1.4310 - mae: 1.8510 - val_loss: 45.7485 - val_mae: 46.4375\n",
      "Epoch 152/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 1.4429 - mae: 1.8608 - val_loss: 45.7874 - val_mae: 46.4746\n",
      "Epoch 153/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 1.4644 - mae: 1.8893 - val_loss: 45.9149 - val_mae: 46.5972\n",
      "Epoch 154/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 1.5923 - mae: 2.0310 - val_loss: 46.5110 - val_mae: 47.1926\n",
      "Epoch 155/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 1.9354 - mae: 2.3935 - val_loss: 45.7076 - val_mae: 46.3923\n",
      "Epoch 156/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 1.4795 - mae: 1.9132 - val_loss: 45.7275 - val_mae: 46.4127\n",
      "Epoch 157/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 1.5879 - mae: 2.0225 - val_loss: 45.3026 - val_mae: 45.9882\n",
      "Epoch 158/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 1.6346 - mae: 2.1073 - val_loss: 46.8431 - val_mae: 47.5270\n",
      "Epoch 159/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.9089 - mae: 2.3740 - val_loss: 44.7174 - val_mae: 45.4036\n",
      "Epoch 160/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 1.5688 - mae: 2.0145 - val_loss: 46.2361 - val_mae: 46.9232\n",
      "Epoch 161/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 1.6043 - mae: 2.0248 - val_loss: 44.2892 - val_mae: 44.9743\n",
      "Epoch 162/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.4156 - mae: 1.8506 - val_loss: 44.8155 - val_mae: 45.4981\n",
      "Epoch 163/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 1.6620 - mae: 2.1140 - val_loss: 46.6125 - val_mae: 47.3013\n",
      "Epoch 164/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 1.5458 - mae: 1.9872 - val_loss: 45.2154 - val_mae: 45.9011\n",
      "Epoch 165/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 1.4066 - mae: 1.8437 - val_loss: 45.4884 - val_mae: 46.1722\n",
      "Epoch 166/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 1.3022 - mae: 1.7243 - val_loss: 45.7634 - val_mae: 46.4502\n",
      "Epoch 167/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.5062 - mae: 1.9331 - val_loss: 45.5596 - val_mae: 46.2423\n",
      "Epoch 168/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.3446 - mae: 1.7666 - val_loss: 46.2216 - val_mae: 46.9091\n",
      "Epoch 169/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 1.4342 - mae: 1.8691 - val_loss: 45.6016 - val_mae: 46.2861\n",
      "Epoch 170/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 1.5518 - mae: 1.9931 - val_loss: 45.0700 - val_mae: 45.7541\n",
      "Epoch 171/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 1.5649 - mae: 2.0068 - val_loss: 45.9166 - val_mae: 46.5997\n",
      "Epoch 172/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 1.5702 - mae: 2.0113 - val_loss: 45.2899 - val_mae: 45.9798\n",
      "Epoch 173/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 1.3700 - mae: 1.7981 - val_loss: 45.1268 - val_mae: 45.8109\n",
      "Epoch 174/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.4288 - mae: 1.8568 - val_loss: 44.4546 - val_mae: 45.1359\n",
      "Epoch 175/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.3591 - mae: 1.7812 - val_loss: 45.8400 - val_mae: 46.5258\n",
      "Epoch 176/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 1.3746 - mae: 1.7921 - val_loss: 45.7125 - val_mae: 46.3968\n",
      "Epoch 177/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 1.3299 - mae: 1.7335 - val_loss: 45.7154 - val_mae: 46.3985\n",
      "Epoch 178/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.3523 - mae: 1.7674 - val_loss: 43.9249 - val_mae: 44.6119\n",
      "Epoch 179/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 1.5925 - mae: 2.0178 - val_loss: 45.0767 - val_mae: 45.7601\n",
      "Epoch 180/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 1.5954 - mae: 2.0503 - val_loss: 43.9870 - val_mae: 44.6750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 1.5318 - mae: 2.0016 - val_loss: 45.8204 - val_mae: 46.5057\n",
      "Epoch 182/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 1.5619 - mae: 1.9895 - val_loss: 44.9002 - val_mae: 45.5852\n",
      "Epoch 183/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 1.3735 - mae: 1.7822 - val_loss: 45.4718 - val_mae: 46.1583\n",
      "Epoch 184/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 1.2709 - mae: 1.6832 - val_loss: 45.6465 - val_mae: 46.3304\n",
      "Epoch 185/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 1.1968 - mae: 1.6150 - val_loss: 46.2586 - val_mae: 46.9442\n",
      "Epoch 186/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 1.2241 - mae: 1.6366 - val_loss: 44.6973 - val_mae: 45.3836\n",
      "Epoch 187/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 1.1707 - mae: 1.5823 - val_loss: 44.5338 - val_mae: 45.2185\n",
      "Epoch 188/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 1.2379 - mae: 1.6522 - val_loss: 45.6169 - val_mae: 46.3020\n",
      "Epoch 189/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 1.2235 - mae: 1.6500 - val_loss: 44.8560 - val_mae: 45.5444\n",
      "Epoch 190/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 1.3290 - mae: 1.7571 - val_loss: 44.8975 - val_mae: 45.5833\n",
      "Epoch 191/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 1.2839 - mae: 1.7019 - val_loss: 43.8328 - val_mae: 44.5185\n",
      "Epoch 192/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 1.5060 - mae: 1.9538 - val_loss: 44.6584 - val_mae: 45.3401\n",
      "Epoch 193/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 1.4726 - mae: 1.8906 - val_loss: 44.7729 - val_mae: 45.4548\n",
      "Epoch 194/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 1.2622 - mae: 1.6907 - val_loss: 45.1132 - val_mae: 45.7983\n",
      "Epoch 195/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 1.4065 - mae: 1.8315 - val_loss: 45.1453 - val_mae: 45.8319\n",
      "Epoch 196/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 1.3245 - mae: 1.7623 - val_loss: 44.8657 - val_mae: 45.5524\n",
      "Epoch 197/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 1.2337 - mae: 1.6473 - val_loss: 45.4362 - val_mae: 46.1223\n",
      "Epoch 198/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 1.1357 - mae: 1.5463 - val_loss: 45.5251 - val_mae: 46.2095\n",
      "Epoch 199/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 1.2860 - mae: 1.6949 - val_loss: 44.9817 - val_mae: 45.6700\n",
      "Epoch 200/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 1.6209 - mae: 2.0731 - val_loss: 44.4279 - val_mae: 45.1152\n",
      "Epoch 201/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 1.3652 - mae: 1.7909 - val_loss: 44.2949 - val_mae: 44.9853\n",
      "Epoch 202/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 1.2715 - mae: 1.6968 - val_loss: 45.4062 - val_mae: 46.0911\n",
      "Epoch 203/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.1594 - mae: 1.5596 - val_loss: 44.7999 - val_mae: 45.4844\n",
      "Epoch 204/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 1.2488 - mae: 1.6540 - val_loss: 44.9366 - val_mae: 45.6248\n",
      "Epoch 205/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.1610 - mae: 1.5653 - val_loss: 45.3173 - val_mae: 46.0030\n",
      "Epoch 206/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 1.2898 - mae: 1.7074 - val_loss: 45.1804 - val_mae: 45.8645\n",
      "Epoch 207/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 1.1930 - mae: 1.6042 - val_loss: 45.1035 - val_mae: 45.7878\n",
      "Epoch 208/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 1.3842 - mae: 1.8204 - val_loss: 45.1527 - val_mae: 45.8371\n",
      "Epoch 209/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 1.3232 - mae: 1.7426 - val_loss: 45.3836 - val_mae: 46.0646\n",
      "Epoch 210/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 1.7010 - mae: 2.1631 - val_loss: 44.2488 - val_mae: 44.9376\n",
      "Epoch 211/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 1.4377 - mae: 1.8651 - val_loss: 45.4582 - val_mae: 46.1444\n",
      "Epoch 212/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 1.1639 - mae: 1.5699 - val_loss: 45.2101 - val_mae: 45.8952\n",
      "Epoch 213/5000\n",
      "46/46 [==============================] - 2s 33ms/step - loss: 1.2592 - mae: 1.6846 - val_loss: 45.2024 - val_mae: 45.8908\n",
      "Epoch 214/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 1.2905 - mae: 1.7123 - val_loss: 44.7886 - val_mae: 45.4778\n",
      "Epoch 215/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 1.2695 - mae: 1.6805 - val_loss: 45.6460 - val_mae: 46.3337\n",
      "Epoch 216/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 1.1226 - mae: 1.5221 - val_loss: 44.8289 - val_mae: 45.5161\n",
      "Epoch 217/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 1.0548 - mae: 1.4574 - val_loss: 45.1064 - val_mae: 45.7901\n",
      "Epoch 218/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 1.3280 - mae: 1.7391 - val_loss: 44.5154 - val_mae: 45.2023\n",
      "Epoch 219/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.2798 - mae: 1.6892 - val_loss: 44.3939 - val_mae: 45.0822\n",
      "Epoch 220/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 1.3047 - mae: 1.7316 - val_loss: 45.2473 - val_mae: 45.9332\n",
      "Epoch 221/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 1.2160 - mae: 1.6375 - val_loss: 44.9906 - val_mae: 45.6784\n",
      "Epoch 222/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 1.1459 - mae: 1.5552 - val_loss: 44.6615 - val_mae: 45.3471\n",
      "Epoch 223/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 1.0700 - mae: 1.4795 - val_loss: 44.9043 - val_mae: 45.5903\n",
      "Epoch 224/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.1187 - mae: 1.5191 - val_loss: 44.8691 - val_mae: 45.5561\n",
      "Epoch 225/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 1.1971 - mae: 1.6181 - val_loss: 44.1527 - val_mae: 44.8422\n",
      "Epoch 226/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 1.2267 - mae: 1.6485 - val_loss: 44.3292 - val_mae: 45.0160\n",
      "Epoch 227/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 1.0425 - mae: 1.4559 - val_loss: 45.4984 - val_mae: 46.1829\n",
      "Epoch 228/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 1.1988 - mae: 1.6026 - val_loss: 45.3330 - val_mae: 46.0188\n",
      "Epoch 229/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 1.2973 - mae: 1.7264 - val_loss: 44.4772 - val_mae: 45.1629\n",
      "Epoch 230/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 1.2839 - mae: 1.6977 - val_loss: 45.3364 - val_mae: 46.0224\n",
      "Epoch 231/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 1.1288 - mae: 1.5621 - val_loss: 44.8018 - val_mae: 45.4885\n",
      "Epoch 232/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 1.2215 - mae: 1.6352 - val_loss: 45.2245 - val_mae: 45.9086\n",
      "Epoch 233/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 1.1687 - mae: 1.5879 - val_loss: 44.0910 - val_mae: 44.7789\n",
      "Epoch 234/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 1.2266 - mae: 1.6429 - val_loss: 44.1380 - val_mae: 44.8268\n",
      "Epoch 235/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 1.1454 - mae: 1.5534 - val_loss: 44.8779 - val_mae: 45.5670\n",
      "Epoch 236/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 1.1358 - mae: 1.5463 - val_loss: 44.4184 - val_mae: 45.1049\n",
      "Epoch 237/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 1.1184 - mae: 1.5262 - val_loss: 43.8797 - val_mae: 44.5678\n",
      "Epoch 238/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 1.1292 - mae: 1.5280 - val_loss: 44.3478 - val_mae: 45.0336\n",
      "Epoch 239/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 1.1308 - mae: 1.5301 - val_loss: 45.4510 - val_mae: 46.1378\n",
      "Epoch 240/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 1.1416 - mae: 1.5383 - val_loss: 45.2611 - val_mae: 45.9484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 1.1736 - mae: 1.5976 - val_loss: 44.7256 - val_mae: 45.4115\n",
      "Epoch 242/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 1.1143 - mae: 1.5371 - val_loss: 44.3761 - val_mae: 45.0592\n",
      "Epoch 243/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.9984 - mae: 1.3863 - val_loss: 44.5988 - val_mae: 45.2870\n",
      "Epoch 244/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 1.0452 - mae: 1.4486 - val_loss: 44.4759 - val_mae: 45.1644\n",
      "Epoch 245/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 1.1910 - mae: 1.6095 - val_loss: 44.2782 - val_mae: 44.9632\n",
      "Epoch 246/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 1.0710 - mae: 1.4719 - val_loss: 44.9479 - val_mae: 45.6336\n",
      "Epoch 247/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 1.0458 - mae: 1.4406 - val_loss: 44.3052 - val_mae: 44.9904\n",
      "Epoch 248/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 1.0004 - mae: 1.3917 - val_loss: 44.7848 - val_mae: 45.4731\n",
      "Epoch 249/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 1.0584 - mae: 1.4553 - val_loss: 44.6658 - val_mae: 45.3519\n",
      "Epoch 250/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 1.1300 - mae: 1.5379 - val_loss: 44.7429 - val_mae: 45.4311\n",
      "Epoch 251/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.0842 - mae: 1.4923 - val_loss: 45.5109 - val_mae: 46.1969\n",
      "Epoch 252/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.9989 - mae: 1.3996 - val_loss: 44.3319 - val_mae: 45.0188\n",
      "Epoch 253/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 1.0671 - mae: 1.4624 - val_loss: 44.2829 - val_mae: 44.9705\n",
      "Epoch 254/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 1.1848 - mae: 1.5861 - val_loss: 44.4359 - val_mae: 45.1215\n",
      "Epoch 255/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 1.1887 - mae: 1.6035 - val_loss: 44.3666 - val_mae: 45.0567\n",
      "Epoch 256/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 1.0232 - mae: 1.4215 - val_loss: 44.3324 - val_mae: 45.0209\n",
      "Epoch 257/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.9635 - mae: 1.3532 - val_loss: 44.3868 - val_mae: 45.0750\n",
      "Epoch 258/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 1.0646 - mae: 1.4634 - val_loss: 44.1223 - val_mae: 44.8067\n",
      "Epoch 259/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 1.1328 - mae: 1.5399 - val_loss: 45.0468 - val_mae: 45.7326\n",
      "Epoch 260/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 1.0885 - mae: 1.4941 - val_loss: 44.1665 - val_mae: 44.8534\n",
      "Epoch 261/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 1.2472 - mae: 1.6801 - val_loss: 45.4033 - val_mae: 46.0911\n",
      "Epoch 262/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.1562 - mae: 1.5658 - val_loss: 44.2738 - val_mae: 44.9581\n",
      "Epoch 263/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.1112 - mae: 1.5088 - val_loss: 44.4682 - val_mae: 45.1558\n",
      "Epoch 264/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 1.0919 - mae: 1.4895 - val_loss: 44.3810 - val_mae: 45.0696\n",
      "Epoch 265/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 1.0867 - mae: 1.4747 - val_loss: 45.1718 - val_mae: 45.8586\n",
      "Epoch 266/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 1.0147 - mae: 1.4065 - val_loss: 44.4361 - val_mae: 45.1250\n",
      "Epoch 267/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 1.1236 - mae: 1.5057 - val_loss: 43.7263 - val_mae: 44.4123\n",
      "Epoch 268/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.9008 - mae: 1.2785 - val_loss: 44.3503 - val_mae: 45.0381\n",
      "Epoch 269/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 1.2833 - mae: 1.6983 - val_loss: 44.3499 - val_mae: 45.0365\n",
      "Epoch 270/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 1.1058 - mae: 1.5160 - val_loss: 44.5981 - val_mae: 45.2871\n",
      "Epoch 271/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 1.1466 - mae: 1.5573 - val_loss: 44.1414 - val_mae: 44.8295\n",
      "Epoch 272/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.9202 - mae: 1.3126 - val_loss: 44.4549 - val_mae: 45.1389\n",
      "Epoch 273/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 1.1975 - mae: 1.5956 - val_loss: 44.8084 - val_mae: 45.4905\n",
      "Epoch 274/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 1.1272 - mae: 1.5245 - val_loss: 44.5799 - val_mae: 45.2672\n",
      "Epoch 275/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.9703 - mae: 1.3599 - val_loss: 43.9306 - val_mae: 44.6182\n",
      "Epoch 276/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 1.1277 - mae: 1.5216 - val_loss: 44.4613 - val_mae: 45.1506\n",
      "Epoch 277/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.9859 - mae: 1.3907 - val_loss: 44.4894 - val_mae: 45.1778\n",
      "Epoch 278/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.9023 - mae: 1.2816 - val_loss: 44.5307 - val_mae: 45.2180\n",
      "Epoch 279/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.9988 - mae: 1.3907 - val_loss: 44.0477 - val_mae: 44.7339\n",
      "Epoch 280/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 1.0676 - mae: 1.4664 - val_loss: 44.1632 - val_mae: 44.8516\n",
      "Epoch 281/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.9707 - mae: 1.3553 - val_loss: 44.4013 - val_mae: 45.0891\n",
      "Epoch 282/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 1.1219 - mae: 1.5164 - val_loss: 44.9449 - val_mae: 45.6302\n",
      "Epoch 283/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 1.1134 - mae: 1.5263 - val_loss: 44.2530 - val_mae: 44.9391\n",
      "Epoch 284/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.9891 - mae: 1.3735 - val_loss: 44.7043 - val_mae: 45.3919\n",
      "Epoch 285/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 1.1725 - mae: 1.5740 - val_loss: 44.5526 - val_mae: 45.2395\n",
      "Epoch 286/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 1.1110 - mae: 1.5025 - val_loss: 43.9872 - val_mae: 44.6742\n",
      "Epoch 287/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 1.1760 - mae: 1.6055 - val_loss: 44.6432 - val_mae: 45.3283\n",
      "Epoch 288/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 0.9914 - mae: 1.3846 - val_loss: 43.9259 - val_mae: 44.6095\n",
      "Epoch 289/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.9642 - mae: 1.3576 - val_loss: 44.5510 - val_mae: 45.2374\n",
      "Epoch 290/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.8922 - mae: 1.2763 - val_loss: 44.9967 - val_mae: 45.6860\n",
      "Epoch 291/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 1.0444 - mae: 1.4384 - val_loss: 43.7067 - val_mae: 44.3937\n",
      "Epoch 292/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.9856 - mae: 1.3756 - val_loss: 44.6170 - val_mae: 45.2974\n",
      "Epoch 293/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 1.0913 - mae: 1.4852 - val_loss: 44.2589 - val_mae: 44.9467\n",
      "Epoch 294/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 0.9241 - mae: 1.2950 - val_loss: 44.6780 - val_mae: 45.3643\n",
      "Epoch 295/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.9509 - mae: 1.3440 - val_loss: 44.3774 - val_mae: 45.0646\n",
      "Epoch 296/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.9550 - mae: 1.3483 - val_loss: 44.9140 - val_mae: 45.6004\n",
      "Epoch 297/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 1.0068 - mae: 1.3975 - val_loss: 43.4736 - val_mae: 44.1597\n",
      "Epoch 298/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.1627 - mae: 1.5699 - val_loss: 44.2114 - val_mae: 44.8985\n",
      "Epoch 299/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 1.0456 - mae: 1.4412 - val_loss: 43.7510 - val_mae: 44.4384\n",
      "Epoch 300/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 1.0081 - mae: 1.3965 - val_loss: 43.9445 - val_mae: 44.6296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.9134 - mae: 1.2975 - val_loss: 44.6654 - val_mae: 45.3515\n",
      "Epoch 302/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 1.0753 - mae: 1.4956 - val_loss: 44.5229 - val_mae: 45.2097\n",
      "Epoch 303/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.0180 - mae: 1.4126 - val_loss: 43.6523 - val_mae: 44.3389\n",
      "Epoch 304/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.9975 - mae: 1.3901 - val_loss: 43.9974 - val_mae: 44.6787\n",
      "Epoch 305/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.9657 - mae: 1.3577 - val_loss: 44.1053 - val_mae: 44.7919\n",
      "Epoch 306/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 0.8885 - mae: 1.2604 - val_loss: 44.2933 - val_mae: 44.9780\n",
      "Epoch 307/5000\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 0.9281 - mae: 1.3260 - val_loss: 43.2825 - val_mae: 43.9686\n",
      "Epoch 308/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 0.9523 - mae: 1.3395 - val_loss: 43.7418 - val_mae: 44.4300\n",
      "Epoch 309/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.0053 - mae: 1.4063 - val_loss: 43.2340 - val_mae: 43.9190\n",
      "Epoch 310/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.9143 - mae: 1.2936 - val_loss: 44.0005 - val_mae: 44.6885\n",
      "Epoch 311/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 0.9149 - mae: 1.3177 - val_loss: 44.3185 - val_mae: 45.0063\n",
      "Epoch 312/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 0.8996 - mae: 1.2799 - val_loss: 44.2046 - val_mae: 44.8905\n",
      "Epoch 313/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.8108 - mae: 1.1789 - val_loss: 43.7461 - val_mae: 44.4325\n",
      "Epoch 314/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.8553 - mae: 1.2385 - val_loss: 44.3786 - val_mae: 45.0650\n",
      "Epoch 315/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 1.1974 - mae: 1.5806 - val_loss: 44.4325 - val_mae: 45.1209\n",
      "Epoch 316/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.9592 - mae: 1.3441 - val_loss: 44.7948 - val_mae: 45.4820\n",
      "Epoch 317/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 1.1746 - mae: 1.5873 - val_loss: 44.6999 - val_mae: 45.3848\n",
      "Epoch 318/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 0.9151 - mae: 1.3038 - val_loss: 44.0442 - val_mae: 44.7315\n",
      "Epoch 319/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.9394 - mae: 1.3125 - val_loss: 43.9167 - val_mae: 44.6022\n",
      "Epoch 320/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.9344 - mae: 1.3259 - val_loss: 43.6803 - val_mae: 44.3680\n",
      "Epoch 321/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 1.1426 - mae: 1.5638 - val_loss: 44.6757 - val_mae: 45.3627\n",
      "Epoch 322/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 1.1797 - mae: 1.6102 - val_loss: 44.3542 - val_mae: 45.0384\n",
      "Epoch 323/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 1.0808 - mae: 1.4844 - val_loss: 43.7627 - val_mae: 44.4515\n",
      "Epoch 324/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.9624 - mae: 1.3641 - val_loss: 44.3925 - val_mae: 45.0797\n",
      "Epoch 325/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.8380 - mae: 1.2053 - val_loss: 44.4892 - val_mae: 45.1705\n",
      "Epoch 326/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 1.0189 - mae: 1.4214 - val_loss: 44.4783 - val_mae: 45.1652\n",
      "Epoch 327/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 0.8440 - mae: 1.2182 - val_loss: 44.2920 - val_mae: 44.9797\n",
      "Epoch 328/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.8467 - mae: 1.2186 - val_loss: 43.8512 - val_mae: 44.5342\n",
      "Epoch 329/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.8555 - mae: 1.2386 - val_loss: 44.6413 - val_mae: 45.3240\n",
      "Epoch 330/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 1.0176 - mae: 1.4141 - val_loss: 43.9823 - val_mae: 44.6691\n",
      "Epoch 331/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.9273 - mae: 1.3100 - val_loss: 44.2452 - val_mae: 44.9301\n",
      "Epoch 332/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.9385 - mae: 1.3142 - val_loss: 44.0694 - val_mae: 44.7527\n",
      "Epoch 333/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.9532 - mae: 1.3407 - val_loss: 44.1572 - val_mae: 44.8451\n",
      "Epoch 334/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.8536 - mae: 1.2226 - val_loss: 43.9678 - val_mae: 44.6549\n",
      "Epoch 335/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.9462 - mae: 1.3490 - val_loss: 44.6194 - val_mae: 45.3062\n",
      "Epoch 336/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.9292 - mae: 1.3060 - val_loss: 43.8301 - val_mae: 44.5128\n",
      "Epoch 337/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.8502 - mae: 1.2331 - val_loss: 43.5123 - val_mae: 44.1957\n",
      "Epoch 338/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 1.0487 - mae: 1.4463 - val_loss: 44.1209 - val_mae: 44.8058\n",
      "Epoch 339/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.8569 - mae: 1.2474 - val_loss: 44.3634 - val_mae: 45.0510\n",
      "Epoch 340/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.9991 - mae: 1.3829 - val_loss: 43.8539 - val_mae: 44.5367\n",
      "Epoch 341/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.9804 - mae: 1.3655 - val_loss: 43.8178 - val_mae: 44.5035\n",
      "Epoch 342/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.9166 - mae: 1.3011 - val_loss: 44.4130 - val_mae: 45.0999\n",
      "Epoch 343/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.8692 - mae: 1.2580 - val_loss: 43.9282 - val_mae: 44.6155\n",
      "Epoch 344/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 0.9766 - mae: 1.3785 - val_loss: 44.2055 - val_mae: 44.8935\n",
      "Epoch 345/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 1.2548 - mae: 1.6742 - val_loss: 44.3959 - val_mae: 45.0829\n",
      "Epoch 346/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 1.0337 - mae: 1.4163 - val_loss: 43.5198 - val_mae: 44.2056\n",
      "Epoch 347/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.9186 - mae: 1.2893 - val_loss: 43.7921 - val_mae: 44.4787\n",
      "Epoch 348/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.8400 - mae: 1.2142 - val_loss: 44.1606 - val_mae: 44.8477\n",
      "Epoch 349/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.7657 - mae: 1.1430 - val_loss: 44.4385 - val_mae: 45.1257\n",
      "Epoch 350/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.7884 - mae: 1.1698 - val_loss: 44.2465 - val_mae: 44.9322\n",
      "Epoch 351/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.8802 - mae: 1.2722 - val_loss: 43.8344 - val_mae: 44.5208\n",
      "Epoch 352/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.9399 - mae: 1.3301 - val_loss: 43.2767 - val_mae: 43.9627\n",
      "Epoch 353/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.9141 - mae: 1.2993 - val_loss: 44.1740 - val_mae: 44.8579\n",
      "Epoch 354/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.8591 - mae: 1.2336 - val_loss: 44.6471 - val_mae: 45.3330\n",
      "Epoch 355/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.9118 - mae: 1.2850 - val_loss: 43.9977 - val_mae: 44.6812\n",
      "Epoch 356/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.8861 - mae: 1.2661 - val_loss: 44.5593 - val_mae: 45.2445\n",
      "Epoch 357/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.8793 - mae: 1.2575 - val_loss: 43.6852 - val_mae: 44.3716\n",
      "Epoch 358/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.7500 - mae: 1.1135 - val_loss: 43.9705 - val_mae: 44.6524\n",
      "Epoch 359/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.9478 - mae: 1.3295 - val_loss: 42.8463 - val_mae: 43.5329\n",
      "Epoch 360/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 1.0120 - mae: 1.3988 - val_loss: 43.7213 - val_mae: 44.4046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.9188 - mae: 1.3071 - val_loss: 43.4157 - val_mae: 44.1022\n",
      "Epoch 362/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.9241 - mae: 1.3036 - val_loss: 43.6091 - val_mae: 44.2954\n",
      "Epoch 363/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.7835 - mae: 1.1311 - val_loss: 43.8326 - val_mae: 44.5166\n",
      "Epoch 364/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.9388 - mae: 1.3159 - val_loss: 44.1040 - val_mae: 44.7890\n",
      "Epoch 365/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.8061 - mae: 1.1821 - val_loss: 43.8753 - val_mae: 44.5591\n",
      "Epoch 366/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.8657 - mae: 1.2449 - val_loss: 43.5256 - val_mae: 44.2111\n",
      "Epoch 367/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.7981 - mae: 1.1675 - val_loss: 43.4383 - val_mae: 44.1249\n",
      "Epoch 368/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.7887 - mae: 1.1514 - val_loss: 43.8908 - val_mae: 44.5767\n",
      "Epoch 369/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 0.9597 - mae: 1.3530 - val_loss: 43.6433 - val_mae: 44.3278\n",
      "Epoch 370/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.8758 - mae: 1.2870 - val_loss: 43.8234 - val_mae: 44.5063\n",
      "Epoch 371/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.8110 - mae: 1.1799 - val_loss: 43.4586 - val_mae: 44.1456\n",
      "Epoch 372/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 0.9922 - mae: 1.3898 - val_loss: 42.4797 - val_mae: 43.1675\n",
      "Epoch 373/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 1.0342 - mae: 1.4364 - val_loss: 43.2881 - val_mae: 43.9744\n",
      "Epoch 374/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.8489 - mae: 1.2146 - val_loss: 43.8791 - val_mae: 44.5644\n",
      "Epoch 375/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.8545 - mae: 1.2216 - val_loss: 43.9793 - val_mae: 44.6667\n",
      "Epoch 376/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.8896 - mae: 1.2754 - val_loss: 43.3024 - val_mae: 43.9848\n",
      "Epoch 377/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.8174 - mae: 1.1888 - val_loss: 43.4594 - val_mae: 44.1479\n",
      "Epoch 378/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.8554 - mae: 1.2433 - val_loss: 43.7631 - val_mae: 44.4498\n",
      "Epoch 379/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.7052 - mae: 1.0741 - val_loss: 44.2367 - val_mae: 44.9237\n",
      "Epoch 380/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.8791 - mae: 1.2500 - val_loss: 44.2620 - val_mae: 44.9451\n",
      "Epoch 381/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.7374 - mae: 1.0890 - val_loss: 43.3891 - val_mae: 44.0735\n",
      "Epoch 382/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.8558 - mae: 1.2292 - val_loss: 43.4067 - val_mae: 44.0904\n",
      "Epoch 383/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.7853 - mae: 1.1557 - val_loss: 43.4072 - val_mae: 44.0938\n",
      "Epoch 384/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 1.0813 - mae: 1.4908 - val_loss: 43.6434 - val_mae: 44.3291\n",
      "Epoch 385/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.9054 - mae: 1.2952 - val_loss: 43.0626 - val_mae: 43.7509\n",
      "Epoch 386/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 0.8794 - mae: 1.2536 - val_loss: 43.7087 - val_mae: 44.3955\n",
      "Epoch 387/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.7313 - mae: 1.0964 - val_loss: 43.5186 - val_mae: 44.2057\n",
      "Epoch 388/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.7904 - mae: 1.1646 - val_loss: 44.2027 - val_mae: 44.8875\n",
      "Epoch 389/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.7860 - mae: 1.1487 - val_loss: 44.7571 - val_mae: 45.4442\n",
      "Epoch 390/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.9022 - mae: 1.2936 - val_loss: 43.1727 - val_mae: 43.8589\n",
      "Epoch 391/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.7542 - mae: 1.1200 - val_loss: 43.8583 - val_mae: 44.5470\n",
      "Epoch 392/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.7947 - mae: 1.1832 - val_loss: 43.7256 - val_mae: 44.4122\n",
      "Epoch 393/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.7874 - mae: 1.1647 - val_loss: 43.4043 - val_mae: 44.0909\n",
      "Epoch 394/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.8822 - mae: 1.2687 - val_loss: 44.1594 - val_mae: 44.8480\n",
      "Epoch 395/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.8745 - mae: 1.2577 - val_loss: 43.3731 - val_mae: 44.0610\n",
      "Epoch 396/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.9374 - mae: 1.3457 - val_loss: 43.3902 - val_mae: 44.0718\n",
      "Epoch 397/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 0.7793 - mae: 1.1385 - val_loss: 44.4775 - val_mae: 45.1637\n",
      "Epoch 398/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.8397 - mae: 1.2030 - val_loss: 43.8722 - val_mae: 44.5551\n",
      "Epoch 399/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.7949 - mae: 1.1611 - val_loss: 43.7443 - val_mae: 44.4298\n",
      "Epoch 400/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.7924 - mae: 1.1664 - val_loss: 43.3751 - val_mae: 44.0594\n",
      "Epoch 401/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.7373 - mae: 1.1010 - val_loss: 43.7335 - val_mae: 44.4187\n",
      "Epoch 402/5000\n",
      "46/46 [==============================] - 2s 53ms/step - loss: 0.6949 - mae: 1.0487 - val_loss: 43.3557 - val_mae: 44.0430\n",
      "Epoch 403/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.7549 - mae: 1.1229 - val_loss: 43.9802 - val_mae: 44.6646\n",
      "Epoch 404/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.8647 - mae: 1.2420 - val_loss: 44.2224 - val_mae: 44.9052\n",
      "Epoch 405/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.8856 - mae: 1.2587 - val_loss: 43.8381 - val_mae: 44.5209\n",
      "Epoch 406/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.7274 - mae: 1.0885 - val_loss: 43.9750 - val_mae: 44.6615\n",
      "Epoch 407/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.7256 - mae: 1.0856 - val_loss: 43.0375 - val_mae: 43.7231\n",
      "Epoch 408/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.8789 - mae: 1.2605 - val_loss: 43.6887 - val_mae: 44.3712\n",
      "Epoch 409/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.7416 - mae: 1.1060 - val_loss: 43.8310 - val_mae: 44.5155\n",
      "Epoch 410/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.7941 - mae: 1.1651 - val_loss: 43.6494 - val_mae: 44.3323\n",
      "Epoch 411/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.8016 - mae: 1.1557 - val_loss: 43.2022 - val_mae: 43.8856\n",
      "Epoch 412/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.8027 - mae: 1.1806 - val_loss: 43.7705 - val_mae: 44.4545\n",
      "Epoch 413/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.9265 - mae: 1.3133 - val_loss: 44.0933 - val_mae: 44.7779\n",
      "Epoch 414/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.8971 - mae: 1.2909 - val_loss: 43.7689 - val_mae: 44.4565\n",
      "Epoch 415/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.9057 - mae: 1.2926 - val_loss: 44.0637 - val_mae: 44.7478\n",
      "Epoch 416/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 1.0073 - mae: 1.4039 - val_loss: 43.5960 - val_mae: 44.2806\n",
      "Epoch 417/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.8102 - mae: 1.1910 - val_loss: 43.4426 - val_mae: 44.1271\n",
      "Epoch 418/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.7770 - mae: 1.1380 - val_loss: 43.5374 - val_mae: 44.2214\n",
      "Epoch 419/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.8574 - mae: 1.2283 - val_loss: 44.4467 - val_mae: 45.1338\n",
      "Epoch 420/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.7854 - mae: 1.1488 - val_loss: 43.8675 - val_mae: 44.5534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.8400 - mae: 1.2239 - val_loss: 43.8867 - val_mae: 44.5721\n",
      "Epoch 422/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.8121 - mae: 1.1816 - val_loss: 43.6512 - val_mae: 44.3349\n",
      "Epoch 423/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.7617 - mae: 1.1353 - val_loss: 43.7787 - val_mae: 44.4652\n",
      "Epoch 424/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.7564 - mae: 1.1155 - val_loss: 44.0062 - val_mae: 44.6935\n",
      "Epoch 425/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.8757 - mae: 1.2468 - val_loss: 44.3917 - val_mae: 45.0738\n",
      "Epoch 426/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.7987 - mae: 1.1753 - val_loss: 43.3419 - val_mae: 44.0237\n",
      "Epoch 427/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.7031 - mae: 1.0584 - val_loss: 44.1204 - val_mae: 44.8086\n",
      "Epoch 428/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.6697 - mae: 1.0045 - val_loss: 43.9130 - val_mae: 44.6011\n",
      "Epoch 429/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.9651 - mae: 1.3433 - val_loss: 43.3060 - val_mae: 43.9911\n",
      "Epoch 430/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.7754 - mae: 1.1543 - val_loss: 43.4196 - val_mae: 44.1039\n",
      "Epoch 431/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.8785 - mae: 1.2591 - val_loss: 43.9282 - val_mae: 44.6132\n",
      "Epoch 432/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.8086 - mae: 1.1784 - val_loss: 43.6145 - val_mae: 44.2973\n",
      "Epoch 433/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.7354 - mae: 1.0963 - val_loss: 43.8574 - val_mae: 44.5402\n",
      "Epoch 434/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.7427 - mae: 1.1030 - val_loss: 43.9688 - val_mae: 44.6524\n",
      "Epoch 435/5000\n",
      "46/46 [==============================] - 2s 33ms/step - loss: 0.7629 - mae: 1.1199 - val_loss: 44.2649 - val_mae: 44.9494\n",
      "Epoch 436/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.7682 - mae: 1.1410 - val_loss: 44.1141 - val_mae: 44.7959\n",
      "Epoch 437/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.7538 - mae: 1.1232 - val_loss: 43.9999 - val_mae: 44.6877\n",
      "Epoch 438/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.7776 - mae: 1.1426 - val_loss: 44.1107 - val_mae: 44.7970\n",
      "Epoch 439/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.7448 - mae: 1.1209 - val_loss: 43.4092 - val_mae: 44.0944\n",
      "Epoch 440/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.8798 - mae: 1.2658 - val_loss: 43.6880 - val_mae: 44.3732\n",
      "Epoch 441/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 0.6951 - mae: 1.0457 - val_loss: 43.9490 - val_mae: 44.6315\n",
      "Epoch 442/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.6994 - mae: 1.0529 - val_loss: 43.5898 - val_mae: 44.2750\n",
      "Epoch 443/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.7067 - mae: 1.0746 - val_loss: 43.3100 - val_mae: 43.9941\n",
      "Epoch 444/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.6703 - mae: 1.0180 - val_loss: 43.3033 - val_mae: 43.9877\n",
      "Epoch 445/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.6402 - mae: 0.9746 - val_loss: 43.3622 - val_mae: 44.0453\n",
      "Epoch 446/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.6020 - mae: 0.9391 - val_loss: 43.4473 - val_mae: 44.1287\n",
      "Epoch 447/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.6673 - mae: 1.0067 - val_loss: 43.7985 - val_mae: 44.4818\n",
      "Epoch 448/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.7218 - mae: 1.0805 - val_loss: 43.6111 - val_mae: 44.2964\n",
      "Epoch 449/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.6231 - mae: 0.9713 - val_loss: 43.7328 - val_mae: 44.4187\n",
      "Epoch 450/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.5944 - mae: 0.9295 - val_loss: 43.8201 - val_mae: 44.5036\n",
      "Epoch 451/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.7148 - mae: 1.0708 - val_loss: 42.4899 - val_mae: 43.1697\n",
      "Epoch 452/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.8702 - mae: 1.2781 - val_loss: 43.2857 - val_mae: 43.9677\n",
      "Epoch 453/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 0.7648 - mae: 1.1375 - val_loss: 43.6569 - val_mae: 44.3419\n",
      "Epoch 454/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.6902 - mae: 1.0461 - val_loss: 43.8392 - val_mae: 44.5228\n",
      "Epoch 455/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.6303 - mae: 0.9759 - val_loss: 43.9675 - val_mae: 44.6525\n",
      "Epoch 456/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.7946 - mae: 1.1754 - val_loss: 43.9750 - val_mae: 44.6590\n",
      "Epoch 457/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.7149 - mae: 1.0704 - val_loss: 44.2581 - val_mae: 44.9436\n",
      "Epoch 458/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.6585 - mae: 1.0055 - val_loss: 43.8348 - val_mae: 44.5203\n",
      "Epoch 459/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.6762 - mae: 1.0309 - val_loss: 43.8569 - val_mae: 44.5415\n",
      "Epoch 460/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.6213 - mae: 0.9559 - val_loss: 43.6533 - val_mae: 44.3383\n",
      "Epoch 461/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.7822 - mae: 1.1367 - val_loss: 43.2260 - val_mae: 43.9143\n",
      "Epoch 462/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.7530 - mae: 1.1427 - val_loss: 43.6569 - val_mae: 44.3399\n",
      "Epoch 463/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.6953 - mae: 1.0578 - val_loss: 43.6377 - val_mae: 44.3253\n",
      "Epoch 464/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.7091 - mae: 1.0754 - val_loss: 44.0910 - val_mae: 44.7772\n",
      "Epoch 465/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.6916 - mae: 1.0554 - val_loss: 43.1747 - val_mae: 43.8588\n",
      "Epoch 466/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.7125 - mae: 1.0800 - val_loss: 43.5682 - val_mae: 44.2522\n",
      "Epoch 467/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.7288 - mae: 1.0879 - val_loss: 44.1757 - val_mae: 44.8586\n",
      "Epoch 468/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 0.7837 - mae: 1.1475 - val_loss: 44.0418 - val_mae: 44.7285\n",
      "Epoch 469/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.6719 - mae: 1.0095 - val_loss: 43.5977 - val_mae: 44.2824\n",
      "Epoch 470/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.6411 - mae: 1.0022 - val_loss: 43.9170 - val_mae: 44.6024\n",
      "Epoch 471/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.8055 - mae: 1.1750 - val_loss: 43.0114 - val_mae: 43.6934\n",
      "Epoch 472/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.7965 - mae: 1.1769 - val_loss: 43.7830 - val_mae: 44.4675\n",
      "Epoch 473/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.7016 - mae: 1.0667 - val_loss: 43.2665 - val_mae: 43.9498\n",
      "Epoch 474/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.5581 - mae: 0.9047 - val_loss: 43.7115 - val_mae: 44.3933\n",
      "Epoch 475/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 0.7495 - mae: 1.1010 - val_loss: 44.2567 - val_mae: 44.9416\n",
      "Epoch 476/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.7972 - mae: 1.1661 - val_loss: 43.6013 - val_mae: 44.2869\n",
      "Epoch 477/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.7473 - mae: 1.0897 - val_loss: 43.4088 - val_mae: 44.0920\n",
      "Epoch 478/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.7915 - mae: 1.1353 - val_loss: 43.5404 - val_mae: 44.2264\n",
      "Epoch 479/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.7135 - mae: 1.0686 - val_loss: 43.5770 - val_mae: 44.2623\n",
      "Epoch 480/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.6946 - mae: 1.0645 - val_loss: 43.7642 - val_mae: 44.4487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.8950 - mae: 1.3006 - val_loss: 43.1348 - val_mae: 43.8166\n",
      "Epoch 482/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 1.1372 - mae: 1.5765 - val_loss: 43.0586 - val_mae: 43.7403\n",
      "Epoch 483/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.7896 - mae: 1.1624 - val_loss: 43.9352 - val_mae: 44.6182\n",
      "Epoch 484/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.8885 - mae: 1.2622 - val_loss: 43.0778 - val_mae: 43.7574\n",
      "Epoch 485/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.7450 - mae: 1.1066 - val_loss: 43.9819 - val_mae: 44.6650\n",
      "Epoch 486/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.7134 - mae: 1.0690 - val_loss: 43.3051 - val_mae: 43.9891\n",
      "Epoch 487/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 0.7908 - mae: 1.1489 - val_loss: 43.1851 - val_mae: 43.8695\n",
      "Epoch 488/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.7760 - mae: 1.1331 - val_loss: 43.7399 - val_mae: 44.4250\n",
      "Epoch 489/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 0.8129 - mae: 1.1718 - val_loss: 44.0106 - val_mae: 44.6951\n",
      "Epoch 490/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.7459 - mae: 1.1051 - val_loss: 43.2866 - val_mae: 43.9690\n",
      "Epoch 491/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.7035 - mae: 1.0755 - val_loss: 43.5722 - val_mae: 44.2576\n",
      "Epoch 492/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.6320 - mae: 0.9807 - val_loss: 43.9074 - val_mae: 44.5917\n",
      "Epoch 493/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.6561 - mae: 1.0007 - val_loss: 43.2925 - val_mae: 43.9770\n",
      "Epoch 494/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 0.6367 - mae: 0.9860 - val_loss: 44.1729 - val_mae: 44.8598\n",
      "Epoch 495/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 0.6348 - mae: 0.9812 - val_loss: 42.8525 - val_mae: 43.5356\n",
      "Epoch 496/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 0.7923 - mae: 1.1582 - val_loss: 43.3364 - val_mae: 44.0194\n",
      "Epoch 497/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.7920 - mae: 1.1585 - val_loss: 42.9224 - val_mae: 43.6072\n",
      "Epoch 498/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.6529 - mae: 1.0007 - val_loss: 43.3672 - val_mae: 44.0508\n",
      "Epoch 499/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.6737 - mae: 1.0258 - val_loss: 43.3975 - val_mae: 44.0766\n",
      "Epoch 500/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 0.8011 - mae: 1.1695 - val_loss: 43.7033 - val_mae: 44.3880\n",
      "Epoch 501/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.6665 - mae: 1.0153 - val_loss: 43.3409 - val_mae: 44.0229\n",
      "Epoch 502/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.6729 - mae: 1.0221 - val_loss: 43.5831 - val_mae: 44.2688\n",
      "Epoch 503/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.7498 - mae: 1.1067 - val_loss: 43.7892 - val_mae: 44.4729\n",
      "Epoch 504/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.6738 - mae: 1.0291 - val_loss: 44.1390 - val_mae: 44.8211\n",
      "Epoch 505/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.7711 - mae: 1.1306 - val_loss: 44.0174 - val_mae: 44.7008\n",
      "Epoch 506/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 1.0152 - mae: 1.4201 - val_loss: 43.8838 - val_mae: 44.5672\n",
      "Epoch 507/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.7451 - mae: 1.1104 - val_loss: 43.3199 - val_mae: 44.0039\n",
      "Epoch 508/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 0.6403 - mae: 0.9946 - val_loss: 43.5998 - val_mae: 44.2828\n",
      "Epoch 509/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 0.8444 - mae: 1.2394 - val_loss: 43.8354 - val_mae: 44.5199\n",
      "Epoch 510/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.6345 - mae: 0.9774 - val_loss: 43.0058 - val_mae: 43.6898\n",
      "Epoch 511/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 0.6518 - mae: 0.9997 - val_loss: 42.8229 - val_mae: 43.5083\n",
      "Epoch 512/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.6901 - mae: 1.0443 - val_loss: 43.4422 - val_mae: 44.1259\n",
      "Epoch 513/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.6486 - mae: 0.9889 - val_loss: 42.9279 - val_mae: 43.6123\n",
      "Epoch 514/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.7245 - mae: 1.0894 - val_loss: 44.5895 - val_mae: 45.2767\n",
      "Epoch 515/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.6841 - mae: 1.0520 - val_loss: 43.0510 - val_mae: 43.7347\n",
      "Epoch 516/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.5698 - mae: 0.9029 - val_loss: 43.4573 - val_mae: 44.1426\n",
      "Epoch 517/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.6849 - mae: 1.0313 - val_loss: 42.7856 - val_mae: 43.4701\n",
      "Epoch 518/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.7142 - mae: 1.0612 - val_loss: 43.0702 - val_mae: 43.7523\n",
      "Epoch 519/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.6100 - mae: 0.9473 - val_loss: 43.5571 - val_mae: 44.2432\n",
      "Epoch 520/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.6918 - mae: 1.0459 - val_loss: 43.0021 - val_mae: 43.6824\n",
      "Epoch 521/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.6129 - mae: 0.9443 - val_loss: 44.0895 - val_mae: 44.7754\n",
      "Epoch 522/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.6596 - mae: 1.0112 - val_loss: 43.2966 - val_mae: 43.9800\n",
      "Epoch 523/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.6540 - mae: 0.9948 - val_loss: 43.4730 - val_mae: 44.1577\n",
      "Epoch 524/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.7158 - mae: 1.0601 - val_loss: 43.1392 - val_mae: 43.8242\n",
      "Epoch 525/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 0.6402 - mae: 0.9886 - val_loss: 43.2800 - val_mae: 43.9623\n",
      "Epoch 526/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.6334 - mae: 0.9713 - val_loss: 43.4132 - val_mae: 44.0960\n",
      "Epoch 527/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.6458 - mae: 0.9933 - val_loss: 43.2291 - val_mae: 43.9124\n",
      "Epoch 528/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.5907 - mae: 0.9405 - val_loss: 43.6343 - val_mae: 44.3201\n",
      "Epoch 529/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.7567 - mae: 1.1348 - val_loss: 42.9804 - val_mae: 43.6646\n",
      "Epoch 530/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.6800 - mae: 1.0323 - val_loss: 43.3894 - val_mae: 44.0749\n",
      "Epoch 531/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.5881 - mae: 0.9300 - val_loss: 43.1431 - val_mae: 43.8278\n",
      "Epoch 532/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.5790 - mae: 0.9256 - val_loss: 43.7883 - val_mae: 44.4708\n",
      "Epoch 533/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.6419 - mae: 1.0037 - val_loss: 43.2185 - val_mae: 43.9020\n",
      "Epoch 534/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 0.6061 - mae: 0.9474 - val_loss: 43.5824 - val_mae: 44.2656\n",
      "Epoch 535/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.6928 - mae: 1.0443 - val_loss: 43.7432 - val_mae: 44.4286\n",
      "Epoch 536/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.6822 - mae: 1.0362 - val_loss: 43.3038 - val_mae: 43.9866\n",
      "Epoch 537/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.6362 - mae: 0.9580 - val_loss: 43.5712 - val_mae: 44.2544\n",
      "Epoch 538/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.5499 - mae: 0.8696 - val_loss: 43.5973 - val_mae: 44.2827\n",
      "Epoch 539/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.6747 - mae: 1.0081 - val_loss: 43.3342 - val_mae: 44.0192\n",
      "Epoch 540/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.5504 - mae: 0.8857 - val_loss: 42.9679 - val_mae: 43.6505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 541/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 0.7358 - mae: 1.0880 - val_loss: 43.5263 - val_mae: 44.2112\n",
      "Epoch 542/5000\n",
      "46/46 [==============================] - 3s 55ms/step - loss: 0.6294 - mae: 0.9662 - val_loss: 43.4516 - val_mae: 44.1366\n",
      "Epoch 543/5000\n",
      "46/46 [==============================] - 3s 60ms/step - loss: 0.5679 - mae: 0.8874 - val_loss: 43.1427 - val_mae: 43.8280\n",
      "Epoch 544/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 0.6682 - mae: 1.0153 - val_loss: 43.6120 - val_mae: 44.2980\n",
      "Epoch 545/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.5976 - mae: 0.9284 - val_loss: 43.3535 - val_mae: 44.0375\n",
      "Epoch 546/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.5427 - mae: 0.8731 - val_loss: 43.2038 - val_mae: 43.8864\n",
      "Epoch 547/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.5740 - mae: 0.9147 - val_loss: 43.5261 - val_mae: 44.2131\n",
      "Epoch 548/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.5924 - mae: 0.9175 - val_loss: 43.7517 - val_mae: 44.4373\n",
      "Epoch 549/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.5372 - mae: 0.8560 - val_loss: 43.4032 - val_mae: 44.0858\n",
      "Epoch 550/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.5000 - mae: 0.8092 - val_loss: 43.4805 - val_mae: 44.1640\n",
      "Epoch 551/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 0.6637 - mae: 1.0021 - val_loss: 43.8561 - val_mae: 44.5413\n",
      "Epoch 552/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.6570 - mae: 1.0026 - val_loss: 43.7825 - val_mae: 44.4655\n",
      "Epoch 553/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.5797 - mae: 0.9087 - val_loss: 43.8143 - val_mae: 44.4995\n",
      "Epoch 554/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.5666 - mae: 0.8917 - val_loss: 43.5464 - val_mae: 44.2340\n",
      "Epoch 555/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.6690 - mae: 1.0004 - val_loss: 43.5736 - val_mae: 44.2566\n",
      "Epoch 556/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.5727 - mae: 0.9081 - val_loss: 44.0430 - val_mae: 44.7273\n",
      "Epoch 557/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.6404 - mae: 0.9878 - val_loss: 43.5561 - val_mae: 44.2403\n",
      "Epoch 558/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.5231 - mae: 0.8516 - val_loss: 43.3884 - val_mae: 44.0741\n",
      "Epoch 559/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.6161 - mae: 0.9623 - val_loss: 43.7444 - val_mae: 44.4271\n",
      "Epoch 560/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.7183 - mae: 1.0869 - val_loss: 43.1479 - val_mae: 43.8344\n",
      "Epoch 561/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.6740 - mae: 1.0249 - val_loss: 43.6153 - val_mae: 44.2970\n",
      "Epoch 562/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.6099 - mae: 0.9487 - val_loss: 43.4332 - val_mae: 44.1169\n",
      "Epoch 563/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.5188 - mae: 0.8390 - val_loss: 44.3156 - val_mae: 45.0010\n",
      "Epoch 564/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.6326 - mae: 0.9754 - val_loss: 43.1791 - val_mae: 43.8646\n",
      "Epoch 565/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.5928 - mae: 0.9360 - val_loss: 43.8566 - val_mae: 44.5406\n",
      "Epoch 566/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.7123 - mae: 1.0740 - val_loss: 43.2419 - val_mae: 43.9263\n",
      "Epoch 567/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.6209 - mae: 0.9628 - val_loss: 43.5894 - val_mae: 44.2748\n",
      "Epoch 568/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.8469 - mae: 1.2133 - val_loss: 43.3725 - val_mae: 44.0579\n",
      "Epoch 569/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.6031 - mae: 0.9598 - val_loss: 43.3429 - val_mae: 44.0267\n",
      "Epoch 570/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.6811 - mae: 1.0424 - val_loss: 43.3572 - val_mae: 44.0403\n",
      "Epoch 571/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 0.6107 - mae: 0.9655 - val_loss: 43.2237 - val_mae: 43.9094\n",
      "Epoch 572/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.6102 - mae: 0.9533 - val_loss: 42.8661 - val_mae: 43.5483\n",
      "Epoch 573/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.7000 - mae: 1.0437 - val_loss: 43.2093 - val_mae: 43.8940\n",
      "Epoch 574/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.5565 - mae: 0.8977 - val_loss: 42.9720 - val_mae: 43.6558\n",
      "Epoch 575/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.5823 - mae: 0.9245 - val_loss: 43.5192 - val_mae: 44.2011\n",
      "Epoch 576/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.5451 - mae: 0.8703 - val_loss: 43.4351 - val_mae: 44.1184\n",
      "Epoch 577/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.5140 - mae: 0.8354 - val_loss: 43.2606 - val_mae: 43.9458\n",
      "Epoch 578/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.5198 - mae: 0.8499 - val_loss: 43.0491 - val_mae: 43.7290\n",
      "Epoch 579/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.5262 - mae: 0.8642 - val_loss: 43.3081 - val_mae: 43.9912\n",
      "Epoch 580/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.6667 - mae: 1.0231 - val_loss: 43.1170 - val_mae: 43.7999\n",
      "Epoch 581/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.6534 - mae: 0.9941 - val_loss: 44.0847 - val_mae: 44.7681\n",
      "Epoch 582/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.5851 - mae: 0.9121 - val_loss: 43.0139 - val_mae: 43.6965\n",
      "Epoch 583/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.5988 - mae: 0.9534 - val_loss: 43.2105 - val_mae: 43.8963\n",
      "Epoch 584/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.6173 - mae: 0.9577 - val_loss: 42.7812 - val_mae: 43.4693\n",
      "Epoch 585/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.6079 - mae: 0.9467 - val_loss: 43.4595 - val_mae: 44.1449\n",
      "Epoch 586/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 0.5989 - mae: 0.9519 - val_loss: 42.8732 - val_mae: 43.5564\n",
      "Epoch 587/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.5250 - mae: 0.8610 - val_loss: 43.1241 - val_mae: 43.8051\n",
      "Epoch 588/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.5445 - mae: 0.8716 - val_loss: 42.9676 - val_mae: 43.6497\n",
      "Epoch 589/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.5466 - mae: 0.8759 - val_loss: 43.2555 - val_mae: 43.9410\n",
      "Epoch 590/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.6624 - mae: 0.9975 - val_loss: 43.4651 - val_mae: 44.1468\n",
      "Epoch 591/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.5734 - mae: 0.9145 - val_loss: 43.0489 - val_mae: 43.7354\n",
      "Epoch 592/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.6325 - mae: 0.9690 - val_loss: 43.4365 - val_mae: 44.1187\n",
      "Epoch 593/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.5646 - mae: 0.8881 - val_loss: 42.8613 - val_mae: 43.5461\n",
      "Epoch 594/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.5659 - mae: 0.8900 - val_loss: 43.4797 - val_mae: 44.1624\n",
      "Epoch 595/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.6118 - mae: 0.9252 - val_loss: 43.2392 - val_mae: 43.9236\n",
      "Epoch 596/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.5381 - mae: 0.8694 - val_loss: 43.4328 - val_mae: 44.1207\n",
      "Epoch 597/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.6038 - mae: 0.9352 - val_loss: 43.4307 - val_mae: 44.1127\n",
      "Epoch 598/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.5596 - mae: 0.8885 - val_loss: 43.6844 - val_mae: 44.3646\n",
      "Epoch 599/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 0.6678 - mae: 1.0204 - val_loss: 43.1230 - val_mae: 43.8079\n",
      "Epoch 600/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.6397 - mae: 0.9699 - val_loss: 43.3216 - val_mae: 44.0056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 601/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 0.6117 - mae: 0.9483 - val_loss: 43.5761 - val_mae: 44.2629\n",
      "Epoch 602/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.5774 - mae: 0.8947 - val_loss: 43.2108 - val_mae: 43.8946\n",
      "Epoch 603/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.5519 - mae: 0.8851 - val_loss: 43.9025 - val_mae: 44.5878\n",
      "Epoch 604/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.5368 - mae: 0.8693 - val_loss: 43.2683 - val_mae: 43.9491\n",
      "Epoch 605/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.6529 - mae: 1.0065 - val_loss: 42.1582 - val_mae: 42.8447\n",
      "Epoch 606/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.6826 - mae: 1.0283 - val_loss: 43.5676 - val_mae: 44.2559\n",
      "Epoch 607/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 0.6175 - mae: 0.9583 - val_loss: 43.4840 - val_mae: 44.1712\n",
      "Epoch 608/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.8241 - mae: 1.2060 - val_loss: 43.0802 - val_mae: 43.7643\n",
      "Epoch 609/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.5458 - mae: 0.8828 - val_loss: 43.3422 - val_mae: 44.0259\n",
      "Epoch 610/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.5481 - mae: 0.8752 - val_loss: 43.2604 - val_mae: 43.9463\n",
      "Epoch 611/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.5073 - mae: 0.8246 - val_loss: 42.6898 - val_mae: 43.3748\n",
      "Epoch 612/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.6338 - mae: 0.9712 - val_loss: 43.3436 - val_mae: 44.0271\n",
      "Epoch 613/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.6339 - mae: 0.9719 - val_loss: 43.3713 - val_mae: 44.0602\n",
      "Epoch 614/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.7243 - mae: 1.0682 - val_loss: 43.0600 - val_mae: 43.7426\n",
      "Epoch 615/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.5759 - mae: 0.9148 - val_loss: 42.9522 - val_mae: 43.6376\n",
      "Epoch 616/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.5182 - mae: 0.8430 - val_loss: 43.1282 - val_mae: 43.8135\n",
      "Epoch 617/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.5893 - mae: 0.9128 - val_loss: 43.1131 - val_mae: 43.7980\n",
      "Epoch 618/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.5613 - mae: 0.8938 - val_loss: 43.1610 - val_mae: 43.8473\n",
      "Epoch 619/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.5000 - mae: 0.8334 - val_loss: 43.1707 - val_mae: 43.8572\n",
      "Epoch 620/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.4368 - mae: 0.7488 - val_loss: 43.5378 - val_mae: 44.2243\n",
      "Epoch 621/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 0.4670 - mae: 0.7766 - val_loss: 43.1803 - val_mae: 43.8642\n",
      "Epoch 622/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.4867 - mae: 0.8074 - val_loss: 43.2115 - val_mae: 43.8974\n",
      "Epoch 623/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.6611 - mae: 1.0146 - val_loss: 42.9037 - val_mae: 43.5897\n",
      "Epoch 624/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.4721 - mae: 0.7778 - val_loss: 43.0798 - val_mae: 43.7644\n",
      "Epoch 625/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.4930 - mae: 0.7984 - val_loss: 43.3174 - val_mae: 44.0049\n",
      "Epoch 626/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.5745 - mae: 0.8987 - val_loss: 42.9323 - val_mae: 43.6194\n",
      "Epoch 627/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.5355 - mae: 0.8514 - val_loss: 43.4462 - val_mae: 44.1329\n",
      "Epoch 628/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 0.4583 - mae: 0.7679 - val_loss: 43.3816 - val_mae: 44.0664\n",
      "Epoch 629/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.4367 - mae: 0.7352 - val_loss: 43.0051 - val_mae: 43.6895\n",
      "Epoch 630/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.4804 - mae: 0.8052 - val_loss: 43.1650 - val_mae: 43.8495\n",
      "Epoch 631/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.4656 - mae: 0.7719 - val_loss: 43.4043 - val_mae: 44.0918\n",
      "Epoch 632/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.5900 - mae: 0.9469 - val_loss: 42.8557 - val_mae: 43.5435\n",
      "Epoch 633/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.6819 - mae: 1.0407 - val_loss: 43.7293 - val_mae: 44.4176\n",
      "Epoch 634/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.7454 - mae: 1.1076 - val_loss: 42.8661 - val_mae: 43.5536\n",
      "Epoch 635/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.7791 - mae: 1.1678 - val_loss: 43.2209 - val_mae: 43.9037\n",
      "Epoch 636/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.5900 - mae: 0.9289 - val_loss: 43.8150 - val_mae: 44.4998\n",
      "Epoch 637/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.5550 - mae: 0.8840 - val_loss: 43.1497 - val_mae: 43.8376\n",
      "Epoch 638/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.6378 - mae: 0.9876 - val_loss: 43.3079 - val_mae: 43.9943\n",
      "Epoch 639/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.4818 - mae: 0.8197 - val_loss: 42.8166 - val_mae: 43.5005\n",
      "Epoch 640/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.5359 - mae: 0.8520 - val_loss: 43.3814 - val_mae: 44.0646\n",
      "Epoch 641/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.4923 - mae: 0.8202 - val_loss: 43.0150 - val_mae: 43.7015\n",
      "Epoch 642/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.5297 - mae: 0.8562 - val_loss: 43.1876 - val_mae: 43.8722\n",
      "Epoch 643/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.5632 - mae: 0.9055 - val_loss: 43.1902 - val_mae: 43.8785\n",
      "Epoch 644/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.5496 - mae: 0.8754 - val_loss: 42.7110 - val_mae: 43.3972\n",
      "Epoch 645/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.5234 - mae: 0.8416 - val_loss: 43.1033 - val_mae: 43.7914\n",
      "Epoch 646/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 0.6985 - mae: 1.0501 - val_loss: 42.9933 - val_mae: 43.6813\n",
      "Epoch 647/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.4951 - mae: 0.8265 - val_loss: 43.0982 - val_mae: 43.7863\n",
      "Epoch 648/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 0.5976 - mae: 0.9377 - val_loss: 43.2882 - val_mae: 43.9738\n",
      "Epoch 649/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.5397 - mae: 0.8896 - val_loss: 43.0561 - val_mae: 43.7399\n",
      "Epoch 650/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.5942 - mae: 0.9398 - val_loss: 43.2441 - val_mae: 43.9311\n",
      "Epoch 651/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.4936 - mae: 0.8135 - val_loss: 43.2966 - val_mae: 43.9815\n",
      "Epoch 652/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.4861 - mae: 0.7977 - val_loss: 43.3483 - val_mae: 44.0318\n",
      "Epoch 653/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.5983 - mae: 0.9433 - val_loss: 43.5460 - val_mae: 44.2311\n",
      "Epoch 654/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.6582 - mae: 1.0072 - val_loss: 43.7466 - val_mae: 44.4353\n",
      "Epoch 655/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.5868 - mae: 0.9164 - val_loss: 43.5509 - val_mae: 44.2372\n",
      "Epoch 656/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.6026 - mae: 0.9309 - val_loss: 43.4060 - val_mae: 44.0935\n",
      "Epoch 657/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 0.5268 - mae: 0.8355 - val_loss: 43.8672 - val_mae: 44.5547\n",
      "Epoch 658/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.5452 - mae: 0.8550 - val_loss: 43.6564 - val_mae: 44.3442\n",
      "Epoch 659/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.4785 - mae: 0.7944 - val_loss: 43.6744 - val_mae: 44.3610\n",
      "Epoch 660/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.5275 - mae: 0.8575 - val_loss: 43.4951 - val_mae: 44.1832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 661/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.5033 - mae: 0.8232 - val_loss: 43.5980 - val_mae: 44.2838\n",
      "Epoch 662/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.4851 - mae: 0.8104 - val_loss: 43.3208 - val_mae: 44.0084\n",
      "Epoch 663/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.4817 - mae: 0.7960 - val_loss: 43.3518 - val_mae: 44.0394\n",
      "Epoch 664/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.4976 - mae: 0.8304 - val_loss: 43.4365 - val_mae: 44.1249\n",
      "Epoch 665/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.4948 - mae: 0.8140 - val_loss: 43.4768 - val_mae: 44.1607\n",
      "Epoch 666/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.4819 - mae: 0.8218 - val_loss: 43.4774 - val_mae: 44.1641\n",
      "Epoch 667/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.5523 - mae: 0.8932 - val_loss: 43.1495 - val_mae: 43.8351\n",
      "Epoch 668/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.6651 - mae: 1.0160 - val_loss: 43.4721 - val_mae: 44.1602\n",
      "Epoch 669/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.5887 - mae: 0.9227 - val_loss: 43.1741 - val_mae: 43.8617\n",
      "Epoch 670/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.5066 - mae: 0.8330 - val_loss: 43.2999 - val_mae: 43.9874\n",
      "Epoch 671/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.4488 - mae: 0.7690 - val_loss: 43.7994 - val_mae: 44.4858\n",
      "Epoch 672/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.5999 - mae: 0.9548 - val_loss: 43.7594 - val_mae: 44.4474\n",
      "Epoch 673/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 0.5191 - mae: 0.8502 - val_loss: 43.6054 - val_mae: 44.2938\n",
      "Epoch 674/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.4797 - mae: 0.7902 - val_loss: 43.6421 - val_mae: 44.3306\n",
      "Epoch 675/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 0.6559 - mae: 0.9875 - val_loss: 43.2723 - val_mae: 43.9604\n",
      "Epoch 676/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.6240 - mae: 0.9650 - val_loss: 43.4331 - val_mae: 44.1206\n",
      "Epoch 677/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.4582 - mae: 0.7757 - val_loss: 44.0375 - val_mae: 44.7249\n",
      "Epoch 678/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.5875 - mae: 0.9195 - val_loss: 43.1106 - val_mae: 43.7981\n",
      "Epoch 679/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.4862 - mae: 0.8157 - val_loss: 43.2149 - val_mae: 43.9016\n",
      "Epoch 680/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.4860 - mae: 0.8001 - val_loss: 43.6013 - val_mae: 44.2891\n",
      "Epoch 681/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.4232 - mae: 0.7203 - val_loss: 43.3827 - val_mae: 44.0699\n",
      "Epoch 682/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.4396 - mae: 0.7519 - val_loss: 42.9262 - val_mae: 43.6100\n",
      "Epoch 683/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.4690 - mae: 0.7831 - val_loss: 43.0600 - val_mae: 43.7469\n",
      "Epoch 684/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.5440 - mae: 0.8739 - val_loss: 43.2183 - val_mae: 43.9045\n",
      "Epoch 685/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.4873 - mae: 0.8131 - val_loss: 43.5729 - val_mae: 44.2618\n",
      "Epoch 686/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 0.5020 - mae: 0.8249 - val_loss: 43.3494 - val_mae: 44.0377\n",
      "Epoch 687/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.4381 - mae: 0.7467 - val_loss: 43.1951 - val_mae: 43.8816\n",
      "Epoch 688/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 0.4909 - mae: 0.8147 - val_loss: 43.1726 - val_mae: 43.8610\n",
      "Epoch 689/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.4639 - mae: 0.7873 - val_loss: 43.2652 - val_mae: 43.9501\n",
      "Epoch 690/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.6054 - mae: 0.9427 - val_loss: 43.8064 - val_mae: 44.4936\n",
      "Epoch 691/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.6966 - mae: 1.0470 - val_loss: 43.8612 - val_mae: 44.5486\n",
      "Epoch 692/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.5588 - mae: 0.9005 - val_loss: 43.2669 - val_mae: 43.9528\n",
      "Epoch 693/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.5980 - mae: 0.9355 - val_loss: 43.1746 - val_mae: 43.8625\n",
      "Epoch 694/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.5189 - mae: 0.8254 - val_loss: 43.7175 - val_mae: 44.4043\n",
      "Epoch 695/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.5155 - mae: 0.8420 - val_loss: 43.0737 - val_mae: 43.7612\n",
      "Epoch 696/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.4366 - mae: 0.7447 - val_loss: 43.0735 - val_mae: 43.7616\n",
      "Epoch 697/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.4751 - mae: 0.7922 - val_loss: 43.3331 - val_mae: 44.0210\n",
      "Epoch 698/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.6041 - mae: 0.9292 - val_loss: 43.6743 - val_mae: 44.3617\n",
      "Epoch 699/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.5305 - mae: 0.8425 - val_loss: 43.7700 - val_mae: 44.4579\n",
      "Epoch 700/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.4622 - mae: 0.7811 - val_loss: 43.9319 - val_mae: 44.6195\n",
      "Epoch 701/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 0.4750 - mae: 0.7789 - val_loss: 43.3669 - val_mae: 44.0537\n",
      "Epoch 702/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.5096 - mae: 0.8342 - val_loss: 43.5380 - val_mae: 44.2252\n",
      "Epoch 703/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.5082 - mae: 0.8437 - val_loss: 43.3667 - val_mae: 44.0542\n",
      "Epoch 704/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.6592 - mae: 1.0160 - val_loss: 43.3438 - val_mae: 44.0311\n",
      "Epoch 705/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.5377 - mae: 0.8668 - val_loss: 43.2334 - val_mae: 43.9211\n",
      "Epoch 706/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.5144 - mae: 0.8327 - val_loss: 43.0386 - val_mae: 43.7261\n",
      "Epoch 707/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.4375 - mae: 0.7434 - val_loss: 43.3453 - val_mae: 44.0318\n",
      "Epoch 708/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.4604 - mae: 0.7573 - val_loss: 43.5450 - val_mae: 44.2326\n",
      "Epoch 709/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.5272 - mae: 0.8424 - val_loss: 43.5026 - val_mae: 44.1903\n",
      "Epoch 710/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.4873 - mae: 0.7951 - val_loss: 43.3587 - val_mae: 44.0472\n",
      "Epoch 711/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.5858 - mae: 0.9127 - val_loss: 43.3535 - val_mae: 44.0402\n",
      "Epoch 712/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.4692 - mae: 0.7815 - val_loss: 43.1714 - val_mae: 43.8584\n",
      "Epoch 713/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.4663 - mae: 0.7721 - val_loss: 43.2161 - val_mae: 43.9037\n",
      "Epoch 714/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.4017 - mae: 0.6953 - val_loss: 43.0975 - val_mae: 43.7842\n",
      "Epoch 715/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.5378 - mae: 0.8764 - val_loss: 42.7421 - val_mae: 43.4284\n",
      "Epoch 716/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 0.6356 - mae: 0.9839 - val_loss: 43.4812 - val_mae: 44.1668\n",
      "Epoch 717/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.5007 - mae: 0.8205 - val_loss: 43.3501 - val_mae: 44.0378\n",
      "Epoch 718/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.4562 - mae: 0.7801 - val_loss: 42.9746 - val_mae: 43.6620\n",
      "Epoch 719/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.4348 - mae: 0.7431 - val_loss: 43.6764 - val_mae: 44.3623\n",
      "Epoch 720/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.5345 - mae: 0.8590 - val_loss: 43.4647 - val_mae: 44.1515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 721/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 0.4437 - mae: 0.7553 - val_loss: 43.0618 - val_mae: 43.7484\n",
      "Epoch 722/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 0.4692 - mae: 0.7884 - val_loss: 43.2992 - val_mae: 43.9863\n",
      "Epoch 723/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.4430 - mae: 0.7581 - val_loss: 43.5822 - val_mae: 44.2678\n",
      "Epoch 724/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 0.5413 - mae: 0.8702 - val_loss: 43.5989 - val_mae: 44.2843\n",
      "Epoch 725/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.5936 - mae: 0.9314 - val_loss: 43.1124 - val_mae: 43.7992\n",
      "Epoch 726/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.4895 - mae: 0.8116 - val_loss: 43.1582 - val_mae: 43.8407\n",
      "Epoch 727/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.5849 - mae: 0.9400 - val_loss: 43.0634 - val_mae: 43.7484\n",
      "Epoch 728/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.4668 - mae: 0.7972 - val_loss: 43.4796 - val_mae: 44.1662\n",
      "Epoch 729/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 0.5419 - mae: 0.8686 - val_loss: 43.4678 - val_mae: 44.1561\n",
      "Epoch 730/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.5070 - mae: 0.8291 - val_loss: 43.6334 - val_mae: 44.3209\n",
      "Epoch 731/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.5088 - mae: 0.8289 - val_loss: 43.0881 - val_mae: 43.7749\n",
      "Epoch 732/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.5647 - mae: 0.8812 - val_loss: 43.6329 - val_mae: 44.3202\n",
      "Epoch 733/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.4848 - mae: 0.8054 - val_loss: 42.6320 - val_mae: 43.3189\n",
      "Epoch 734/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.5968 - mae: 0.9397 - val_loss: 43.5914 - val_mae: 44.2794\n",
      "Epoch 735/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.4543 - mae: 0.7663 - val_loss: 43.3336 - val_mae: 44.0213\n",
      "Epoch 736/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.4372 - mae: 0.7364 - val_loss: 43.7191 - val_mae: 44.4054\n",
      "Epoch 737/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.4770 - mae: 0.7817 - val_loss: 43.2860 - val_mae: 43.9735\n",
      "Epoch 738/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.4261 - mae: 0.7289 - val_loss: 43.3458 - val_mae: 44.0321\n",
      "Epoch 739/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.4370 - mae: 0.7331 - val_loss: 43.0289 - val_mae: 43.7160\n",
      "Epoch 740/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.4176 - mae: 0.7221 - val_loss: 43.3825 - val_mae: 44.0689\n",
      "Epoch 741/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.4744 - mae: 0.7795 - val_loss: 43.9440 - val_mae: 44.6317\n",
      "Epoch 742/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.4330 - mae: 0.7428 - val_loss: 43.3445 - val_mae: 44.0322\n",
      "Epoch 743/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 0.4367 - mae: 0.7495 - val_loss: 43.5593 - val_mae: 44.2464\n",
      "Epoch 744/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 0.4118 - mae: 0.7111 - val_loss: 43.4994 - val_mae: 44.1847\n",
      "Epoch 745/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.3929 - mae: 0.6871 - val_loss: 43.1875 - val_mae: 43.8731\n",
      "Epoch 746/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.4562 - mae: 0.7639 - val_loss: 43.2619 - val_mae: 43.9481\n",
      "Epoch 747/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.3835 - mae: 0.6784 - val_loss: 43.3288 - val_mae: 44.0149\n",
      "Epoch 748/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.4049 - mae: 0.7158 - val_loss: 43.3850 - val_mae: 44.0713\n",
      "Epoch 749/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 0.5116 - mae: 0.8245 - val_loss: 43.3093 - val_mae: 43.9963\n",
      "Epoch 750/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.4544 - mae: 0.7822 - val_loss: 43.3234 - val_mae: 44.0088\n",
      "Epoch 751/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.4536 - mae: 0.7757 - val_loss: 43.7008 - val_mae: 44.3881\n",
      "Epoch 752/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.4085 - mae: 0.6993 - val_loss: 43.3171 - val_mae: 44.0046\n",
      "Epoch 753/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 0.4766 - mae: 0.7939 - val_loss: 43.0234 - val_mae: 43.7103\n",
      "Epoch 754/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.5562 - mae: 0.8936 - val_loss: 43.9027 - val_mae: 44.5891\n",
      "Epoch 755/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.5400 - mae: 0.8728 - val_loss: 43.1775 - val_mae: 43.8649\n",
      "Epoch 756/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.4816 - mae: 0.7907 - val_loss: 43.1163 - val_mae: 43.8045\n",
      "Epoch 757/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 0.5227 - mae: 0.8487 - val_loss: 43.2806 - val_mae: 43.9664\n",
      "Epoch 758/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 0.4585 - mae: 0.7590 - val_loss: 43.0932 - val_mae: 43.7805\n",
      "Epoch 759/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 0.5970 - mae: 0.9313 - val_loss: 43.5614 - val_mae: 44.2486\n",
      "Epoch 760/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.4601 - mae: 0.7697 - val_loss: 43.3307 - val_mae: 44.0170\n",
      "Epoch 761/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.4085 - mae: 0.7174 - val_loss: 43.1897 - val_mae: 43.8770\n",
      "Epoch 762/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.4570 - mae: 0.7638 - val_loss: 43.1394 - val_mae: 43.8270\n",
      "Epoch 763/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.4088 - mae: 0.7088 - val_loss: 43.5177 - val_mae: 44.2055\n",
      "Epoch 764/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.4854 - mae: 0.8083 - val_loss: 43.6925 - val_mae: 44.3781\n",
      "Epoch 765/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.3902 - mae: 0.6897 - val_loss: 43.6179 - val_mae: 44.3034\n",
      "Epoch 766/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.5753 - mae: 0.9104 - val_loss: 43.8267 - val_mae: 44.5119\n",
      "Epoch 767/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.5052 - mae: 0.8412 - val_loss: 43.4673 - val_mae: 44.1538\n",
      "Epoch 768/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.6547 - mae: 1.0210 - val_loss: 43.4493 - val_mae: 44.1357\n",
      "Epoch 769/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.5172 - mae: 0.8234 - val_loss: 43.6339 - val_mae: 44.3179\n",
      "Epoch 770/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.5547 - mae: 0.8930 - val_loss: 43.3013 - val_mae: 43.9871\n",
      "Epoch 771/5000\n",
      "46/46 [==============================] - 3s 58ms/step - loss: 0.4359 - mae: 0.7423 - val_loss: 43.5512 - val_mae: 44.2365\n",
      "Epoch 772/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 0.3478 - mae: 0.6285 - val_loss: 43.4776 - val_mae: 44.1623\n",
      "Epoch 773/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.4226 - mae: 0.7285 - val_loss: 43.5111 - val_mae: 44.1973\n",
      "Epoch 774/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.4085 - mae: 0.6936 - val_loss: 43.7709 - val_mae: 44.4570\n",
      "Epoch 775/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.4939 - mae: 0.8069 - val_loss: 43.8082 - val_mae: 44.4942\n",
      "Epoch 776/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.4957 - mae: 0.8237 - val_loss: 43.4431 - val_mae: 44.1293\n",
      "Epoch 777/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.4789 - mae: 0.7877 - val_loss: 43.9547 - val_mae: 44.6439\n",
      "Epoch 778/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.4412 - mae: 0.7454 - val_loss: 43.7435 - val_mae: 44.4320\n",
      "Epoch 779/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.4676 - mae: 0.7781 - val_loss: 43.3428 - val_mae: 44.0302\n",
      "Epoch 780/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 0.4751 - mae: 0.7959 - val_loss: 43.6302 - val_mae: 44.3179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 781/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.4347 - mae: 0.7330 - val_loss: 43.7038 - val_mae: 44.3921\n",
      "Epoch 782/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.3455 - mae: 0.6323 - val_loss: 43.1701 - val_mae: 43.8549\n",
      "Epoch 783/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.4981 - mae: 0.8190 - val_loss: 43.2102 - val_mae: 43.8954\n",
      "Epoch 784/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 0.4608 - mae: 0.7716 - val_loss: 43.4733 - val_mae: 44.1579\n",
      "Epoch 785/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.4980 - mae: 0.8239 - val_loss: 43.2193 - val_mae: 43.9053\n",
      "Epoch 786/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.4677 - mae: 0.7941 - val_loss: 43.2942 - val_mae: 43.9811\n",
      "Epoch 787/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.4370 - mae: 0.7350 - val_loss: 43.4195 - val_mae: 44.1056\n",
      "Epoch 788/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.4606 - mae: 0.7674 - val_loss: 43.1449 - val_mae: 43.8301\n",
      "Epoch 789/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.4178 - mae: 0.7343 - val_loss: 43.2056 - val_mae: 43.8917\n",
      "Epoch 790/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 0.4323 - mae: 0.7442 - val_loss: 43.5182 - val_mae: 44.2047\n",
      "Epoch 791/5000\n",
      "46/46 [==============================] - 3s 58ms/step - loss: 0.4946 - mae: 0.8111 - val_loss: 43.6120 - val_mae: 44.2982\n",
      "Epoch 792/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 0.5004 - mae: 0.8312 - val_loss: 43.1341 - val_mae: 43.8185\n",
      "Epoch 793/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.4267 - mae: 0.7398 - val_loss: 43.2165 - val_mae: 43.9022\n",
      "Epoch 794/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.3836 - mae: 0.6977 - val_loss: 43.1434 - val_mae: 43.8292\n",
      "Epoch 795/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.3938 - mae: 0.6954 - val_loss: 43.0446 - val_mae: 43.7311\n",
      "Epoch 796/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.3727 - mae: 0.6458 - val_loss: 43.0545 - val_mae: 43.7394\n",
      "Epoch 797/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.4108 - mae: 0.7188 - val_loss: 43.5096 - val_mae: 44.1953\n",
      "Epoch 798/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.5370 - mae: 0.8585 - val_loss: 43.1622 - val_mae: 43.8485\n",
      "Epoch 799/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.4401 - mae: 0.7519 - val_loss: 43.2253 - val_mae: 43.9109\n",
      "Epoch 800/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.3302 - mae: 0.6078 - val_loss: 43.2987 - val_mae: 43.9834\n",
      "Epoch 801/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.3248 - mae: 0.5964 - val_loss: 43.5886 - val_mae: 44.2744\n",
      "Epoch 802/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.3562 - mae: 0.6458 - val_loss: 43.5501 - val_mae: 44.2371\n",
      "Epoch 803/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.4744 - mae: 0.7857 - val_loss: 43.3525 - val_mae: 44.0388\n",
      "Epoch 804/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.4276 - mae: 0.7242 - val_loss: 43.2234 - val_mae: 43.9095\n",
      "Epoch 805/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.3646 - mae: 0.6498 - val_loss: 43.7035 - val_mae: 44.3892\n",
      "Epoch 806/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.3511 - mae: 0.6331 - val_loss: 43.8308 - val_mae: 44.5166\n",
      "Epoch 807/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.4109 - mae: 0.7255 - val_loss: 43.3699 - val_mae: 44.0558\n",
      "Epoch 808/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.3612 - mae: 0.6481 - val_loss: 43.5670 - val_mae: 44.2533\n",
      "Epoch 809/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.4439 - mae: 0.7551 - val_loss: 43.1486 - val_mae: 43.8345\n",
      "Epoch 810/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.5001 - mae: 0.8017 - val_loss: 43.5609 - val_mae: 44.2481\n",
      "Epoch 811/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.4738 - mae: 0.7600 - val_loss: 43.7950 - val_mae: 44.4815\n",
      "Epoch 812/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.4497 - mae: 0.7763 - val_loss: 43.4002 - val_mae: 44.0897\n",
      "Epoch 813/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.3719 - mae: 0.6633 - val_loss: 43.4398 - val_mae: 44.1276\n",
      "Epoch 814/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.3633 - mae: 0.6531 - val_loss: 43.7613 - val_mae: 44.4473\n",
      "Epoch 815/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.4377 - mae: 0.7385 - val_loss: 43.2207 - val_mae: 43.9072\n",
      "Epoch 816/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 0.4784 - mae: 0.8197 - val_loss: 44.0677 - val_mae: 44.7534\n",
      "Epoch 817/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.3976 - mae: 0.6863 - val_loss: 43.7244 - val_mae: 44.4090\n",
      "Epoch 818/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.3538 - mae: 0.6392 - val_loss: 43.4374 - val_mae: 44.1237\n",
      "Epoch 819/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.3861 - mae: 0.6915 - val_loss: 43.0415 - val_mae: 43.7294\n",
      "Epoch 820/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.4799 - mae: 0.8244 - val_loss: 43.7190 - val_mae: 44.4061\n",
      "Epoch 821/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.5824 - mae: 0.9129 - val_loss: 43.3512 - val_mae: 44.0371\n",
      "Epoch 822/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.6022 - mae: 0.9426 - val_loss: 43.6429 - val_mae: 44.3287\n",
      "Epoch 823/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.5697 - mae: 0.9133 - val_loss: 43.7564 - val_mae: 44.4440\n",
      "Epoch 824/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.4424 - mae: 0.7443 - val_loss: 43.9364 - val_mae: 44.6224\n",
      "Epoch 825/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.4843 - mae: 0.7970 - val_loss: 43.4159 - val_mae: 44.1034\n",
      "Epoch 826/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.5031 - mae: 0.8047 - val_loss: 43.4111 - val_mae: 44.0967\n",
      "Epoch 827/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.3426 - mae: 0.6221 - val_loss: 43.5630 - val_mae: 44.2485\n",
      "Epoch 828/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.3665 - mae: 0.6573 - val_loss: 43.1656 - val_mae: 43.8520\n",
      "Epoch 829/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.3893 - mae: 0.6906 - val_loss: 43.7696 - val_mae: 44.4563\n",
      "Epoch 830/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.4425 - mae: 0.7385 - val_loss: 43.4121 - val_mae: 44.0984\n",
      "Epoch 831/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.4379 - mae: 0.7376 - val_loss: 43.7138 - val_mae: 44.4008\n",
      "Epoch 832/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.6123 - mae: 0.9617 - val_loss: 43.0157 - val_mae: 43.7040\n",
      "Epoch 833/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.4664 - mae: 0.7849 - val_loss: 43.6058 - val_mae: 44.2906\n",
      "Epoch 834/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.3811 - mae: 0.6896 - val_loss: 43.3300 - val_mae: 44.0162\n",
      "Epoch 835/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.4641 - mae: 0.7912 - val_loss: 43.5171 - val_mae: 44.2028\n",
      "Epoch 836/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.4512 - mae: 0.7796 - val_loss: 43.6878 - val_mae: 44.3761\n",
      "Epoch 837/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.5585 - mae: 0.8935 - val_loss: 43.6515 - val_mae: 44.3381\n",
      "Epoch 838/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.4875 - mae: 0.8125 - val_loss: 43.3348 - val_mae: 44.0200\n",
      "Epoch 839/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.3747 - mae: 0.6642 - val_loss: 43.5508 - val_mae: 44.2371\n",
      "Epoch 840/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.4713 - mae: 0.7885 - val_loss: 44.0867 - val_mae: 44.7742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 841/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 0.5307 - mae: 0.8541 - val_loss: 43.1427 - val_mae: 43.8275\n",
      "Epoch 842/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.3863 - mae: 0.6766 - val_loss: 43.5174 - val_mae: 44.2044\n",
      "Epoch 843/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.3862 - mae: 0.6811 - val_loss: 43.3843 - val_mae: 44.0716\n",
      "Epoch 844/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 0.4229 - mae: 0.7158 - val_loss: 43.6775 - val_mae: 44.3642\n",
      "Epoch 845/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.3785 - mae: 0.6644 - val_loss: 43.0698 - val_mae: 43.7558\n",
      "Epoch 846/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.4669 - mae: 0.7748 - val_loss: 43.3672 - val_mae: 44.0528\n",
      "Epoch 847/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.4013 - mae: 0.6974 - val_loss: 43.6078 - val_mae: 44.2944\n",
      "Epoch 848/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.4230 - mae: 0.7211 - val_loss: 43.6257 - val_mae: 44.3129\n",
      "Epoch 849/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.3740 - mae: 0.6625 - val_loss: 43.6751 - val_mae: 44.3612\n",
      "Epoch 850/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.3459 - mae: 0.6209 - val_loss: 43.4233 - val_mae: 44.1120\n",
      "Epoch 851/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.3345 - mae: 0.6252 - val_loss: 43.4203 - val_mae: 44.1066\n",
      "Epoch 852/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.3625 - mae: 0.6407 - val_loss: 43.5067 - val_mae: 44.1909\n",
      "Epoch 853/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.4594 - mae: 0.7540 - val_loss: 43.5920 - val_mae: 44.2798\n",
      "Epoch 854/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.3310 - mae: 0.5958 - val_loss: 43.2640 - val_mae: 43.9509\n",
      "Epoch 855/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 0.3730 - mae: 0.6554 - val_loss: 43.2057 - val_mae: 43.8917\n",
      "Epoch 856/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.4132 - mae: 0.7094 - val_loss: 43.8185 - val_mae: 44.5061\n",
      "Epoch 857/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.3866 - mae: 0.6762 - val_loss: 43.6602 - val_mae: 44.3481\n",
      "Epoch 858/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.3410 - mae: 0.6126 - val_loss: 43.5528 - val_mae: 44.2397\n",
      "Epoch 859/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.4576 - mae: 0.7642 - val_loss: 44.2602 - val_mae: 44.9489\n",
      "Epoch 860/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.4460 - mae: 0.7635 - val_loss: 43.8828 - val_mae: 44.5712\n",
      "Epoch 861/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.4165 - mae: 0.7145 - val_loss: 43.6592 - val_mae: 44.3456\n",
      "Epoch 862/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.3660 - mae: 0.6630 - val_loss: 43.3110 - val_mae: 43.9998\n",
      "Epoch 863/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.3676 - mae: 0.6667 - val_loss: 43.5923 - val_mae: 44.2798\n",
      "Epoch 864/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.4596 - mae: 0.7702 - val_loss: 43.0543 - val_mae: 43.7411\n",
      "Epoch 865/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 0.4216 - mae: 0.7459 - val_loss: 43.5884 - val_mae: 44.2758\n",
      "Epoch 866/5000\n",
      "46/46 [==============================] - 2s 50ms/step - loss: 0.3818 - mae: 0.6682 - val_loss: 43.8276 - val_mae: 44.5158\n",
      "Epoch 867/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 0.3838 - mae: 0.6632 - val_loss: 43.8837 - val_mae: 44.5718\n",
      "Epoch 868/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.4159 - mae: 0.7245 - val_loss: 43.8606 - val_mae: 44.5483\n",
      "Epoch 869/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.4142 - mae: 0.7141 - val_loss: 43.0634 - val_mae: 43.7527\n",
      "Epoch 870/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.4576 - mae: 0.7764 - val_loss: 43.3069 - val_mae: 43.9940\n",
      "Epoch 871/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.3461 - mae: 0.6349 - val_loss: 43.0887 - val_mae: 43.7765\n",
      "Epoch 872/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.3779 - mae: 0.6753 - val_loss: 43.5156 - val_mae: 44.2035\n",
      "Epoch 873/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.4008 - mae: 0.7085 - val_loss: 43.2903 - val_mae: 43.9778\n",
      "Epoch 874/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 0.4333 - mae: 0.7476 - val_loss: 43.2143 - val_mae: 43.9018\n",
      "Epoch 875/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 0.3574 - mae: 0.6454 - val_loss: 43.3229 - val_mae: 44.0109\n",
      "Epoch 876/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.4136 - mae: 0.7213 - val_loss: 43.2709 - val_mae: 43.9585\n",
      "Epoch 877/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.4514 - mae: 0.7523 - val_loss: 42.8825 - val_mae: 43.5705\n",
      "Epoch 878/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.3961 - mae: 0.6925 - val_loss: 43.6635 - val_mae: 44.3508\n",
      "Epoch 879/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.4651 - mae: 0.7755 - val_loss: 43.4309 - val_mae: 44.1170\n",
      "Epoch 880/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.3647 - mae: 0.6575 - val_loss: 43.6256 - val_mae: 44.3138\n",
      "Epoch 881/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.3623 - mae: 0.6575 - val_loss: 43.6109 - val_mae: 44.2998\n",
      "Epoch 882/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.3838 - mae: 0.6727 - val_loss: 43.2632 - val_mae: 43.9512\n",
      "Epoch 883/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.4184 - mae: 0.7216 - val_loss: 43.6087 - val_mae: 44.2964\n",
      "Epoch 884/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.4526 - mae: 0.7618 - val_loss: 43.4421 - val_mae: 44.1290\n",
      "Epoch 885/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.3684 - mae: 0.6617 - val_loss: 43.5046 - val_mae: 44.1928\n",
      "Epoch 886/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.3486 - mae: 0.6503 - val_loss: 43.2981 - val_mae: 43.9851\n",
      "Epoch 887/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.3641 - mae: 0.6578 - val_loss: 43.2944 - val_mae: 43.9819\n",
      "Epoch 888/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 0.3689 - mae: 0.6569 - val_loss: 43.5017 - val_mae: 44.1896\n",
      "Epoch 889/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.4405 - mae: 0.7464 - val_loss: 43.4590 - val_mae: 44.1473\n",
      "Epoch 890/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.5381 - mae: 0.8659 - val_loss: 43.5620 - val_mae: 44.2488\n",
      "Epoch 891/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.4328 - mae: 0.7500 - val_loss: 43.5139 - val_mae: 44.2034\n",
      "Epoch 892/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 0.5264 - mae: 0.8456 - val_loss: 43.4067 - val_mae: 44.0957\n",
      "Epoch 893/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.3855 - mae: 0.6822 - val_loss: 43.4270 - val_mae: 44.1168\n",
      "Epoch 894/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 0.3574 - mae: 0.6546 - val_loss: 43.7492 - val_mae: 44.4373\n",
      "Epoch 895/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.3829 - mae: 0.6801 - val_loss: 43.3053 - val_mae: 43.9914\n",
      "Epoch 896/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.3443 - mae: 0.6317 - val_loss: 43.3130 - val_mae: 44.0012\n",
      "Epoch 897/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.3239 - mae: 0.5938 - val_loss: 43.8154 - val_mae: 44.5048\n",
      "Epoch 898/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 0.4302 - mae: 0.7188 - val_loss: 43.6762 - val_mae: 44.3642\n",
      "Epoch 899/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.4566 - mae: 0.7628 - val_loss: 43.7842 - val_mae: 44.4725\n",
      "Epoch 900/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.4248 - mae: 0.7231 - val_loss: 43.7743 - val_mae: 44.4615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 901/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.4227 - mae: 0.7366 - val_loss: 43.4064 - val_mae: 44.0949\n",
      "Epoch 902/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.3155 - mae: 0.5962 - val_loss: 43.7181 - val_mae: 44.4063\n",
      "Epoch 903/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.3350 - mae: 0.6132 - val_loss: 43.9713 - val_mae: 44.6583\n",
      "Epoch 904/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.4538 - mae: 0.7476 - val_loss: 43.8375 - val_mae: 44.5261\n",
      "Epoch 905/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 0.5430 - mae: 0.8546 - val_loss: 43.2778 - val_mae: 43.9656\n",
      "Epoch 906/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 0.4911 - mae: 0.8084 - val_loss: 43.5996 - val_mae: 44.2864\n",
      "Epoch 907/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.3369 - mae: 0.6142 - val_loss: 43.6371 - val_mae: 44.3256\n",
      "Epoch 908/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.4420 - mae: 0.7501 - val_loss: 43.8300 - val_mae: 44.5181\n",
      "Epoch 909/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.3408 - mae: 0.6198 - val_loss: 44.1105 - val_mae: 44.7984\n",
      "Epoch 910/5000\n",
      "46/46 [==============================] - 2s 34ms/step - loss: 0.3143 - mae: 0.5976 - val_loss: 43.5842 - val_mae: 44.2733\n",
      "Epoch 911/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.4132 - mae: 0.7096 - val_loss: 43.5592 - val_mae: 44.2474\n",
      "Epoch 912/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.4005 - mae: 0.6958 - val_loss: 43.3066 - val_mae: 43.9941\n",
      "Epoch 913/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.4396 - mae: 0.7495 - val_loss: 43.8247 - val_mae: 44.5132\n",
      "Epoch 914/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 0.3607 - mae: 0.6508 - val_loss: 43.4347 - val_mae: 44.1234\n",
      "Epoch 915/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.3497 - mae: 0.6291 - val_loss: 43.4894 - val_mae: 44.1774\n",
      "Epoch 916/5000\n",
      "46/46 [==============================] - 2s 52ms/step - loss: 0.3278 - mae: 0.6067 - val_loss: 43.6825 - val_mae: 44.3711\n",
      "Epoch 917/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.3604 - mae: 0.6470 - val_loss: 43.6230 - val_mae: 44.3112\n",
      "Epoch 918/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.3770 - mae: 0.6746 - val_loss: 43.6873 - val_mae: 44.3751\n",
      "Epoch 919/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.3439 - mae: 0.6401 - val_loss: 43.9148 - val_mae: 44.6032\n",
      "Epoch 920/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.3607 - mae: 0.6454 - val_loss: 43.3952 - val_mae: 44.0831\n",
      "Epoch 921/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.4020 - mae: 0.7044 - val_loss: 43.6859 - val_mae: 44.3754\n",
      "Epoch 922/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.3778 - mae: 0.6829 - val_loss: 43.4246 - val_mae: 44.1131\n",
      "Epoch 923/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.4046 - mae: 0.7169 - val_loss: 43.5328 - val_mae: 44.2202\n",
      "Epoch 924/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.5086 - mae: 0.8302 - val_loss: 43.8531 - val_mae: 44.5400\n",
      "Epoch 925/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.4276 - mae: 0.7511 - val_loss: 43.7598 - val_mae: 44.4487\n",
      "Epoch 926/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.3660 - mae: 0.6591 - val_loss: 43.6862 - val_mae: 44.3742\n",
      "Epoch 927/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.3589 - mae: 0.6471 - val_loss: 44.0292 - val_mae: 44.7169\n",
      "Epoch 928/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 0.3139 - mae: 0.5913 - val_loss: 43.6652 - val_mae: 44.3541\n",
      "Epoch 929/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 0.4302 - mae: 0.7129 - val_loss: 43.5530 - val_mae: 44.2396\n",
      "Epoch 930/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.3695 - mae: 0.6761 - val_loss: 43.8049 - val_mae: 44.4946\n",
      "Epoch 931/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.4271 - mae: 0.7381 - val_loss: 43.3035 - val_mae: 43.9890\n",
      "Epoch 932/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.3895 - mae: 0.6929 - val_loss: 43.9607 - val_mae: 44.6462\n",
      "Epoch 933/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.3513 - mae: 0.6340 - val_loss: 43.7231 - val_mae: 44.4096\n",
      "Epoch 934/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.3401 - mae: 0.5981 - val_loss: 43.5281 - val_mae: 44.2157\n",
      "Epoch 935/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.3967 - mae: 0.6815 - val_loss: 43.2178 - val_mae: 43.9064\n",
      "Epoch 936/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.3394 - mae: 0.6275 - val_loss: 43.6336 - val_mae: 44.3199\n",
      "Epoch 937/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.3797 - mae: 0.6775 - val_loss: 44.0416 - val_mae: 44.7277\n",
      "Epoch 938/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.2949 - mae: 0.5676 - val_loss: 43.3161 - val_mae: 44.0050\n",
      "Epoch 939/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.3236 - mae: 0.6062 - val_loss: 43.5328 - val_mae: 44.2199\n",
      "Epoch 940/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.4012 - mae: 0.6797 - val_loss: 43.9445 - val_mae: 44.6322\n",
      "Epoch 941/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 0.3544 - mae: 0.6343 - val_loss: 43.7727 - val_mae: 44.4598\n",
      "Epoch 942/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.3904 - mae: 0.6811 - val_loss: 43.7334 - val_mae: 44.4211\n",
      "Epoch 943/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.4329 - mae: 0.7391 - val_loss: 43.6285 - val_mae: 44.3165\n",
      "Epoch 944/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 0.4355 - mae: 0.7555 - val_loss: 43.6934 - val_mae: 44.3817\n",
      "Epoch 945/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.4109 - mae: 0.7092 - val_loss: 43.6405 - val_mae: 44.3289\n",
      "Epoch 946/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.4657 - mae: 0.7808 - val_loss: 43.5695 - val_mae: 44.2584\n",
      "Epoch 947/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.3718 - mae: 0.6645 - val_loss: 43.5130 - val_mae: 44.2028\n",
      "Epoch 948/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.3852 - mae: 0.6769 - val_loss: 43.8008 - val_mae: 44.4884\n",
      "Epoch 949/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.3677 - mae: 0.6581 - val_loss: 43.2383 - val_mae: 43.9274\n",
      "Epoch 950/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.3885 - mae: 0.6797 - val_loss: 43.9379 - val_mae: 44.6276\n",
      "Epoch 951/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.2952 - mae: 0.5680 - val_loss: 43.5435 - val_mae: 44.2329\n",
      "Epoch 952/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.3697 - mae: 0.6639 - val_loss: 43.9256 - val_mae: 44.6141\n",
      "Epoch 953/5000\n",
      "46/46 [==============================] - 2s 54ms/step - loss: 0.3407 - mae: 0.6271 - val_loss: 43.3596 - val_mae: 44.0480\n",
      "Epoch 954/5000\n",
      "46/46 [==============================] - 2s 51ms/step - loss: 0.2981 - mae: 0.5755 - val_loss: 43.6166 - val_mae: 44.3053\n",
      "Epoch 955/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.5415 - mae: 0.8475 - val_loss: 43.6542 - val_mae: 44.3419\n",
      "Epoch 956/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.3712 - mae: 0.6512 - val_loss: 43.4626 - val_mae: 44.1510\n",
      "Epoch 957/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.4440 - mae: 0.7424 - val_loss: 43.6266 - val_mae: 44.3157\n",
      "Epoch 958/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.3903 - mae: 0.6955 - val_loss: 43.6481 - val_mae: 44.3358\n",
      "Epoch 959/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 0.3016 - mae: 0.5828 - val_loss: 43.4311 - val_mae: 44.1206\n",
      "Epoch 960/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.3823 - mae: 0.6732 - val_loss: 43.6439 - val_mae: 44.3325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 961/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.3455 - mae: 0.6334 - val_loss: 43.5482 - val_mae: 44.2378\n",
      "Epoch 962/5000\n",
      "46/46 [==============================] - 2s 49ms/step - loss: 0.3994 - mae: 0.6970 - val_loss: 43.6963 - val_mae: 44.3866\n",
      "Epoch 963/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.3367 - mae: 0.6155 - val_loss: 43.3922 - val_mae: 44.0805\n",
      "Epoch 964/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.3254 - mae: 0.5951 - val_loss: 43.2683 - val_mae: 43.9568\n",
      "Epoch 965/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.3264 - mae: 0.6007 - val_loss: 43.9861 - val_mae: 44.6754\n",
      "Epoch 966/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.4787 - mae: 0.7975 - val_loss: 43.4894 - val_mae: 44.1789\n",
      "Epoch 967/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.4007 - mae: 0.6956 - val_loss: 43.6072 - val_mae: 44.2962\n",
      "Epoch 968/5000\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 0.3796 - mae: 0.6799 - val_loss: 43.4373 - val_mae: 44.1264\n",
      "Epoch 969/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.3765 - mae: 0.6460 - val_loss: 43.6333 - val_mae: 44.3204\n",
      "Epoch 970/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.3726 - mae: 0.6506 - val_loss: 43.4230 - val_mae: 44.1124\n",
      "Epoch 971/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.3236 - mae: 0.6012 - val_loss: 43.3836 - val_mae: 44.0728\n",
      "Epoch 972/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.3647 - mae: 0.6596 - val_loss: 43.5194 - val_mae: 44.2084\n",
      "Epoch 973/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.3863 - mae: 0.6820 - val_loss: 43.5347 - val_mae: 44.2240\n",
      "Epoch 974/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.3340 - mae: 0.6285 - val_loss: 43.4550 - val_mae: 44.1415\n",
      "Epoch 975/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.2871 - mae: 0.5649 - val_loss: 43.5606 - val_mae: 44.2488\n",
      "Epoch 976/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.3657 - mae: 0.6441 - val_loss: 43.4989 - val_mae: 44.1868\n",
      "Epoch 977/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.4132 - mae: 0.7094 - val_loss: 43.7613 - val_mae: 44.4503\n",
      "Epoch 978/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.3277 - mae: 0.6102 - val_loss: 43.8236 - val_mae: 44.5134\n",
      "Epoch 979/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.3371 - mae: 0.6124 - val_loss: 44.2375 - val_mae: 44.9254\n",
      "Epoch 980/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 0.4043 - mae: 0.7077 - val_loss: 43.9009 - val_mae: 44.5911\n",
      "Epoch 981/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.3809 - mae: 0.6861 - val_loss: 43.7383 - val_mae: 44.4276\n",
      "Epoch 982/5000\n",
      "46/46 [==============================] - 2s 35ms/step - loss: 0.3847 - mae: 0.6989 - val_loss: 43.8306 - val_mae: 44.5198\n",
      "Epoch 983/5000\n",
      "46/46 [==============================] - 2s 38ms/step - loss: 0.2762 - mae: 0.5462 - val_loss: 43.9198 - val_mae: 44.6089\n",
      "Epoch 984/5000\n",
      "46/46 [==============================] - 2s 37ms/step - loss: 0.4131 - mae: 0.7279 - val_loss: 43.9544 - val_mae: 44.6447\n",
      "Epoch 985/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.4223 - mae: 0.7347 - val_loss: 43.7632 - val_mae: 44.4530\n",
      "Epoch 986/5000\n",
      "46/46 [==============================] - 2s 46ms/step - loss: 0.3342 - mae: 0.6202 - val_loss: 43.6179 - val_mae: 44.3070\n",
      "Epoch 987/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.3744 - mae: 0.6505 - val_loss: 43.8888 - val_mae: 44.5766\n",
      "Epoch 988/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 0.5173 - mae: 0.8448 - val_loss: 44.1235 - val_mae: 44.8124\n",
      "Epoch 989/5000\n",
      "46/46 [==============================] - 2s 48ms/step - loss: 0.3189 - mae: 0.5994 - val_loss: 43.8388 - val_mae: 44.5288\n",
      "Epoch 990/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.3366 - mae: 0.6138 - val_loss: 43.9596 - val_mae: 44.6499\n",
      "Epoch 991/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.3117 - mae: 0.5931 - val_loss: 44.3051 - val_mae: 44.9943\n",
      "Epoch 992/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.3322 - mae: 0.6326 - val_loss: 43.7247 - val_mae: 44.4133\n",
      "Epoch 993/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.2961 - mae: 0.5906 - val_loss: 43.6108 - val_mae: 44.2998\n",
      "Epoch 994/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.3158 - mae: 0.5772 - val_loss: 43.5349 - val_mae: 44.2219\n",
      "Epoch 995/5000\n",
      "46/46 [==============================] - 2s 43ms/step - loss: 0.3093 - mae: 0.5881 - val_loss: 43.8022 - val_mae: 44.4909\n",
      "Epoch 996/5000\n",
      "46/46 [==============================] - 2s 41ms/step - loss: 0.3281 - mae: 0.6019 - val_loss: 44.1039 - val_mae: 44.7921\n",
      "Epoch 997/5000\n",
      "46/46 [==============================] - 2s 40ms/step - loss: 0.3161 - mae: 0.5969 - val_loss: 43.6756 - val_mae: 44.3663\n",
      "Epoch 998/5000\n",
      "46/46 [==============================] - 2s 39ms/step - loss: 0.3586 - mae: 0.6447 - val_loss: 43.9498 - val_mae: 44.6372\n",
      "Epoch 999/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 0.3452 - mae: 0.6202 - val_loss: 43.7170 - val_mae: 44.4065\n",
      "Epoch 1000/5000\n",
      "46/46 [==============================] - 2s 44ms/step - loss: 0.2836 - mae: 0.5466 - val_loss: 44.1003 - val_mae: 44.7894\n",
      "Epoch 1001/5000\n",
      "46/46 [==============================] - 2s 42ms/step - loss: 0.3082 - mae: 0.5815 - val_loss: 43.9717 - val_mae: 44.6607\n",
      "Epoch 1002/5000\n",
      "46/46 [==============================] - 2s 47ms/step - loss: 0.3908 - mae: 0.6881 - val_loss: 43.5988 - val_mae: 44.2866\n",
      "Epoch 1003/5000\n",
      "46/46 [==============================] - 2s 45ms/step - loss: 0.3967 - mae: 0.6818 - val_loss: 43.9444 - val_mae: 44.6333\n",
      "Epoch 1003: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9d981d7e80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train,Y_train, epochs=5000, batch_size=32, validation_data=(X_val,Y_val), callbacks=[earlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adf8814a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 5ms/step\n",
      "18/18 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_train_pred=regressor.predict(X_train)\n",
    "y_pred=regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.ravel()\n",
    "Y_train_pred = Y_train_pred.ravel().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train.ravel()\n",
    "Y_test = Y_test.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b0f090b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999548880396638"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for check\n",
    "r2_score(Y_train, Y_train_pred) #training score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e757ef47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2:-13.796555395987328\n"
     ]
    }
   ],
   "source": [
    "r2=r2_score(Y_test[:-30],y_pred[:-30]) #score/ r^2\n",
    "print(f'r2:{r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00ef1c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2_oos\n",
    "def r2_oos(ret, pred):\n",
    "    sum_of_sq_res = np.nansum(np.power((ret-pred), 2))\n",
    "    sum_of_sq_total = np.nansum(np.power(ret, 2))\n",
    "    \n",
    "    return 1-sum_of_sq_res/sum_of_sq_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8969a6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_oos:-1.706555476322864\n"
     ]
    }
   ],
   "source": [
    "r2_oos = r2_oos(Y_test[:-30], y_pred[:-30])\n",
    "print(f'r2_oos:{r2_oos}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70b87143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae:50.00097317812424\n",
      "rmse:206.8559615660686\n",
      "mape:60.36657163267265\n"
     ]
    }
   ],
   "source": [
    "mae=mean_absolute_error(Y_test[:-30],y_pred[:-30]) #mae\n",
    "print(f'mae:{mae}')\n",
    "\n",
    "rmse=np.sqrt(mean_squared_error(Y_test[:-30],y_pred[:-30])) #rmse\n",
    "print(f'rmse:{rmse}')\n",
    "\n",
    "mape=mean_absolute_percentage_error(Y_test[:-30],y_pred[:-30]) #mape\n",
    "print(f'mape:{mape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb36caf",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5641115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-06-01</th>\n",
       "      <td>137.796</td>\n",
       "      <td>135.435165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-02</th>\n",
       "      <td>133.855</td>\n",
       "      <td>143.762848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-03</th>\n",
       "      <td>138.441</td>\n",
       "      <td>138.642853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-04</th>\n",
       "      <td>143.405</td>\n",
       "      <td>135.274612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-05</th>\n",
       "      <td>139.483</td>\n",
       "      <td>134.361816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>134.023804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>139.413818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>140.318436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>134.921555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>128.350555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>546 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Y_test      y_pred\n",
       "Date                           \n",
       "2021-06-01  137.796  135.435165\n",
       "2021-06-02  133.855  143.762848\n",
       "2021-06-03  138.441  138.642853\n",
       "2021-06-04  143.405  135.274612\n",
       "2021-06-05  139.483  134.361816\n",
       "...             ...         ...\n",
       "2022-11-24      NaN  134.023804\n",
       "2022-11-25      NaN  139.413818\n",
       "2022-11-26      NaN  140.318436\n",
       "2022-11-27      NaN  134.921555\n",
       "2022-11-28      NaN  128.350555\n",
       "\n",
       "[546 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_df = pd.DataFrame(zip(Y_test,y_pred),columns=['Y_test','y_pred'])\n",
    "pre_df.index = tmp_index\n",
    "pre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f4bd2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df['pred_returns'] = pre_df['y_pred'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b94aa95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_test</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>pred_returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-06-01</th>\n",
       "      <td>137.796</td>\n",
       "      <td>135.435165</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-02</th>\n",
       "      <td>133.855</td>\n",
       "      <td>143.762848</td>\n",
       "      <td>0.061488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-03</th>\n",
       "      <td>138.441</td>\n",
       "      <td>138.642853</td>\n",
       "      <td>-0.035614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-04</th>\n",
       "      <td>143.405</td>\n",
       "      <td>135.274612</td>\n",
       "      <td>-0.024294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-05</th>\n",
       "      <td>139.483</td>\n",
       "      <td>134.361816</td>\n",
       "      <td>-0.006748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>134.023804</td>\n",
       "      <td>-0.079993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>139.413818</td>\n",
       "      <td>0.040217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>140.318436</td>\n",
       "      <td>0.006489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>134.921555</td>\n",
       "      <td>-0.038462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>128.350555</td>\n",
       "      <td>-0.048702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>546 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Y_test      y_pred  pred_returns\n",
       "Date                                         \n",
       "2021-06-01  137.796  135.435165           NaN\n",
       "2021-06-02  133.855  143.762848      0.061488\n",
       "2021-06-03  138.441  138.642853     -0.035614\n",
       "2021-06-04  143.405  135.274612     -0.024294\n",
       "2021-06-05  139.483  134.361816     -0.006748\n",
       "...             ...         ...           ...\n",
       "2022-11-24      NaN  134.023804     -0.079993\n",
       "2022-11-25      NaN  139.413818      0.040217\n",
       "2022-11-26      NaN  140.318436      0.006489\n",
       "2022-11-27      NaN  134.921555     -0.038462\n",
       "2022-11-28      NaN  128.350555     -0.048702\n",
       "\n",
       "[546 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d9674c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(zip(Y_test,y_pred),columns=['Y_test','y_pred']).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "732393ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df.to_csv(\"../result/LSTM/ltc_NN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!kdeconnect-cli -n TAS-AN00 --ping-msg 'Script complete!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Stock Market Predictor.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "0a952188e4bab49300a5758bda39ddc90e91f41f35dfe6ea820e496e515be371"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
