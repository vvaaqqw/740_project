{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1350c800",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 00:34:15.194826: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# conda install keras-tuner\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_validate\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from collections import Counter\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import randint\n",
    "from sklearn.metrics import mean_squared_error, make_scorer, accuracy_score, f1_score, classification_report\n",
    "# import pickle\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor, KerasClassifier\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import *\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ded3682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535a3fac",
   "metadata": {},
   "source": [
    "### ltc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1467391e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1730670/1097672958.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltc['Date'][i]  =  datetime.strptime(ltc['Date'][i], '%Y/%m/%d')\n"
     ]
    }
   ],
   "source": [
    "regs = pd.read_csv(\"../Data/train_ltc_selected_features.csv\")\n",
    "ltc = pd.read_csv(\"../Data/litecoin_Data.csv\")\n",
    "for i in range(len(ltc['Date'])):\n",
    "    ltc['Date'][i]  =  datetime.strptime(ltc['Date'][i], '%Y/%m/%d')\n",
    "\n",
    "ltc = ltc.set_index(\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d665a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ltcData = ltc[regs.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8227b01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1730670/1118086751.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ltcData['returns'] = ltcData['priceUSD'].pct_change()\n"
     ]
    }
   ],
   "source": [
    "ltcData['returns'] = ltcData['priceUSD'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0204bfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = ltcData.drop(columns=['priceUSD'])\n",
    "Data = Data[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a926d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activeaddresses30std</th>\n",
       "      <th>activeaddresses30var</th>\n",
       "      <th>activeaddresses7trx</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>difficulty30mom</th>\n",
       "      <th>difficulty30trx</th>\n",
       "      <th>difficulty90mom</th>\n",
       "      <th>difficulty90roc</th>\n",
       "      <th>difficulty90rsi</th>\n",
       "      <th>difficulty90trx</th>\n",
       "      <th>...</th>\n",
       "      <th>sentinusd30emaUSD</th>\n",
       "      <th>sentinusd30smaUSD</th>\n",
       "      <th>sentinusd30wmaUSD</th>\n",
       "      <th>sentinusd90emaUSD</th>\n",
       "      <th>sentinusd90varUSD</th>\n",
       "      <th>sentinusd90wmaUSD</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>top100cap</th>\n",
       "      <th>transactionvalueUSD</th>\n",
       "      <th>returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-02</th>\n",
       "      <td>7666</td>\n",
       "      <td>14691594</td>\n",
       "      <td>0.296</td>\n",
       "      <td>51718</td>\n",
       "      <td>2875.000</td>\n",
       "      <td>0.146</td>\n",
       "      <td>3694.0</td>\n",
       "      <td>7.693</td>\n",
       "      <td>55.143</td>\n",
       "      <td>0.073</td>\n",
       "      <td>...</td>\n",
       "      <td>13119990</td>\n",
       "      <td>14447549</td>\n",
       "      <td>13084361</td>\n",
       "      <td>15062343</td>\n",
       "      <td>9.207781e+13</td>\n",
       "      <td>15267519</td>\n",
       "      <td>6145265</td>\n",
       "      <td>49.907</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>-0.004836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03</th>\n",
       "      <td>7553</td>\n",
       "      <td>14263642</td>\n",
       "      <td>0.531</td>\n",
       "      <td>50653</td>\n",
       "      <td>1810.000</td>\n",
       "      <td>0.152</td>\n",
       "      <td>2764.0</td>\n",
       "      <td>5.771</td>\n",
       "      <td>53.920</td>\n",
       "      <td>0.074</td>\n",
       "      <td>...</td>\n",
       "      <td>12661408</td>\n",
       "      <td>14247155</td>\n",
       "      <td>12540130</td>\n",
       "      <td>14863434</td>\n",
       "      <td>9.237091e+13</td>\n",
       "      <td>15058214</td>\n",
       "      <td>6011974</td>\n",
       "      <td>49.914</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>-0.008005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>6990</td>\n",
       "      <td>12215979</td>\n",
       "      <td>0.492</td>\n",
       "      <td>50158</td>\n",
       "      <td>1315.000</td>\n",
       "      <td>0.156</td>\n",
       "      <td>2268.0</td>\n",
       "      <td>4.737</td>\n",
       "      <td>53.364</td>\n",
       "      <td>0.074</td>\n",
       "      <td>...</td>\n",
       "      <td>12160118</td>\n",
       "      <td>13934412</td>\n",
       "      <td>11936534</td>\n",
       "      <td>14644269</td>\n",
       "      <td>9.336173e+13</td>\n",
       "      <td>14824650</td>\n",
       "      <td>4891418</td>\n",
       "      <td>49.963</td>\n",
       "      <td>1112.0</td>\n",
       "      <td>0.004323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>7207</td>\n",
       "      <td>12983796</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>50158</td>\n",
       "      <td>436.688</td>\n",
       "      <td>0.159</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>3.574</td>\n",
       "      <td>53.364</td>\n",
       "      <td>0.075</td>\n",
       "      <td>...</td>\n",
       "      <td>11733962</td>\n",
       "      <td>13588124</td>\n",
       "      <td>11395907</td>\n",
       "      <td>14444498</td>\n",
       "      <td>9.368327e+13</td>\n",
       "      <td>14607077</td>\n",
       "      <td>5554693</td>\n",
       "      <td>49.976</td>\n",
       "      <td>1505.0</td>\n",
       "      <td>-0.004878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>7368</td>\n",
       "      <td>13572232</td>\n",
       "      <td>-0.950</td>\n",
       "      <td>51299</td>\n",
       "      <td>1184.000</td>\n",
       "      <td>0.161</td>\n",
       "      <td>1473.0</td>\n",
       "      <td>2.956</td>\n",
       "      <td>54.471</td>\n",
       "      <td>0.075</td>\n",
       "      <td>...</td>\n",
       "      <td>11652530</td>\n",
       "      <td>13295257</td>\n",
       "      <td>11194853</td>\n",
       "      <td>14357186</td>\n",
       "      <td>9.312956e+13</td>\n",
       "      <td>14497960</td>\n",
       "      <td>10471777</td>\n",
       "      <td>49.916</td>\n",
       "      <td>3469.0</td>\n",
       "      <td>-0.004902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-24</th>\n",
       "      <td>55298</td>\n",
       "      <td>764459612</td>\n",
       "      <td>-0.329</td>\n",
       "      <td>19352505</td>\n",
       "      <td>2570167.000</td>\n",
       "      <td>0.274</td>\n",
       "      <td>3935133.0</td>\n",
       "      <td>25.524</td>\n",
       "      <td>61.809</td>\n",
       "      <td>0.095</td>\n",
       "      <td>...</td>\n",
       "      <td>1038289555</td>\n",
       "      <td>1236990379</td>\n",
       "      <td>1125469305</td>\n",
       "      <td>906646434</td>\n",
       "      <td>7.982758e+17</td>\n",
       "      <td>1088633253</td>\n",
       "      <td>361588723</td>\n",
       "      <td>44.670</td>\n",
       "      <td>30828.0</td>\n",
       "      <td>-0.001286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-25</th>\n",
       "      <td>55854</td>\n",
       "      <td>779921846</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>19996996</td>\n",
       "      <td>3214659.000</td>\n",
       "      <td>0.279</td>\n",
       "      <td>4316584.0</td>\n",
       "      <td>27.529</td>\n",
       "      <td>63.623</td>\n",
       "      <td>0.097</td>\n",
       "      <td>...</td>\n",
       "      <td>990339490</td>\n",
       "      <td>1228280282</td>\n",
       "      <td>1064699832</td>\n",
       "      <td>893205052</td>\n",
       "      <td>7.936632e+17</td>\n",
       "      <td>1076450910</td>\n",
       "      <td>295063546</td>\n",
       "      <td>44.667</td>\n",
       "      <td>37548.0</td>\n",
       "      <td>-0.023929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-26</th>\n",
       "      <td>55376</td>\n",
       "      <td>766634614</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>19996996</td>\n",
       "      <td>3214659.000</td>\n",
       "      <td>0.284</td>\n",
       "      <td>4316584.0</td>\n",
       "      <td>27.529</td>\n",
       "      <td>63.623</td>\n",
       "      <td>0.099</td>\n",
       "      <td>...</td>\n",
       "      <td>939695376</td>\n",
       "      <td>1214390963</td>\n",
       "      <td>998704699</td>\n",
       "      <td>878087484</td>\n",
       "      <td>7.902356e+17</td>\n",
       "      <td>1062224912</td>\n",
       "      <td>205355717</td>\n",
       "      <td>44.746</td>\n",
       "      <td>35847.0</td>\n",
       "      <td>0.012488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-27</th>\n",
       "      <td>55508</td>\n",
       "      <td>770273876</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>19996996</td>\n",
       "      <td>2274388.000</td>\n",
       "      <td>0.289</td>\n",
       "      <td>4316584.0</td>\n",
       "      <td>27.529</td>\n",
       "      <td>63.623</td>\n",
       "      <td>0.101</td>\n",
       "      <td>...</td>\n",
       "      <td>890366945</td>\n",
       "      <td>1190592377</td>\n",
       "      <td>931653972</td>\n",
       "      <td>862637313</td>\n",
       "      <td>7.872458e+17</td>\n",
       "      <td>1047283908</td>\n",
       "      <td>175104696</td>\n",
       "      <td>44.739</td>\n",
       "      <td>23536.0</td>\n",
       "      <td>0.001146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-28</th>\n",
       "      <td>54692</td>\n",
       "      <td>747797946</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>19429695</td>\n",
       "      <td>1678156.000</td>\n",
       "      <td>0.294</td>\n",
       "      <td>4598305.0</td>\n",
       "      <td>31.004</td>\n",
       "      <td>60.986</td>\n",
       "      <td>0.103</td>\n",
       "      <td>...</td>\n",
       "      <td>845359022</td>\n",
       "      <td>1183566854</td>\n",
       "      <td>867276666</td>\n",
       "      <td>847914386</td>\n",
       "      <td>7.839838e+17</td>\n",
       "      <td>1032687824</td>\n",
       "      <td>192744138</td>\n",
       "      <td>44.742</td>\n",
       "      <td>24643.0</td>\n",
       "      <td>-0.054550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2523 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            activeaddresses30std  activeaddresses30var  activeaddresses7trx  \\\n",
       "Date                                                                          \n",
       "2016-01-02                  7666              14691594                0.296   \n",
       "2016-01-03                  7553              14263642                0.531   \n",
       "2016-01-04                  6990              12215979                0.492   \n",
       "2016-01-05                  7207              12983796               -0.176   \n",
       "2016-01-06                  7368              13572232               -0.950   \n",
       "...                          ...                   ...                  ...   \n",
       "2022-11-24                 55298             764459612               -0.329   \n",
       "2022-11-25                 55854             779921846               -0.097   \n",
       "2022-11-26                 55376             766634614               -0.101   \n",
       "2022-11-27                 55508             770273876               -0.228   \n",
       "2022-11-28                 54692             747797946               -0.210   \n",
       "\n",
       "            difficulty  difficulty30mom  difficulty30trx  difficulty90mom  \\\n",
       "Date                                                                        \n",
       "2016-01-02       51718         2875.000            0.146           3694.0   \n",
       "2016-01-03       50653         1810.000            0.152           2764.0   \n",
       "2016-01-04       50158         1315.000            0.156           2268.0   \n",
       "2016-01-05       50158          436.688            0.159           1731.0   \n",
       "2016-01-06       51299         1184.000            0.161           1473.0   \n",
       "...                ...              ...              ...              ...   \n",
       "2022-11-24    19352505      2570167.000            0.274        3935133.0   \n",
       "2022-11-25    19996996      3214659.000            0.279        4316584.0   \n",
       "2022-11-26    19996996      3214659.000            0.284        4316584.0   \n",
       "2022-11-27    19996996      2274388.000            0.289        4316584.0   \n",
       "2022-11-28    19429695      1678156.000            0.294        4598305.0   \n",
       "\n",
       "            difficulty90roc  difficulty90rsi  difficulty90trx  ...  \\\n",
       "Date                                                           ...   \n",
       "2016-01-02            7.693           55.143            0.073  ...   \n",
       "2016-01-03            5.771           53.920            0.074  ...   \n",
       "2016-01-04            4.737           53.364            0.074  ...   \n",
       "2016-01-05            3.574           53.364            0.075  ...   \n",
       "2016-01-06            2.956           54.471            0.075  ...   \n",
       "...                     ...              ...              ...  ...   \n",
       "2022-11-24           25.524           61.809            0.095  ...   \n",
       "2022-11-25           27.529           63.623            0.097  ...   \n",
       "2022-11-26           27.529           63.623            0.099  ...   \n",
       "2022-11-27           27.529           63.623            0.101  ...   \n",
       "2022-11-28           31.004           60.986            0.103  ...   \n",
       "\n",
       "            sentinusd30emaUSD  sentinusd30smaUSD  sentinusd30wmaUSD  \\\n",
       "Date                                                                  \n",
       "2016-01-02           13119990           14447549           13084361   \n",
       "2016-01-03           12661408           14247155           12540130   \n",
       "2016-01-04           12160118           13934412           11936534   \n",
       "2016-01-05           11733962           13588124           11395907   \n",
       "2016-01-06           11652530           13295257           11194853   \n",
       "...                       ...                ...                ...   \n",
       "2022-11-24         1038289555         1236990379         1125469305   \n",
       "2022-11-25          990339490         1228280282         1064699832   \n",
       "2022-11-26          939695376         1214390963          998704699   \n",
       "2022-11-27          890366945         1190592377          931653972   \n",
       "2022-11-28          845359022         1183566854          867276666   \n",
       "\n",
       "            sentinusd90emaUSD  sentinusd90varUSD  sentinusd90wmaUSD  \\\n",
       "Date                                                                  \n",
       "2016-01-02           15062343       9.207781e+13           15267519   \n",
       "2016-01-03           14863434       9.237091e+13           15058214   \n",
       "2016-01-04           14644269       9.336173e+13           14824650   \n",
       "2016-01-05           14444498       9.368327e+13           14607077   \n",
       "2016-01-06           14357186       9.312956e+13           14497960   \n",
       "...                       ...                ...                ...   \n",
       "2022-11-24          906646434       7.982758e+17         1088633253   \n",
       "2022-11-25          893205052       7.936632e+17         1076450910   \n",
       "2022-11-26          878087484       7.902356e+17         1062224912   \n",
       "2022-11-27          862637313       7.872458e+17         1047283908   \n",
       "2022-11-28          847914386       7.839838e+17         1032687824   \n",
       "\n",
       "            sentinusdUSD  top100cap  transactionvalueUSD   returns  \n",
       "Date                                                                \n",
       "2016-01-02       6145265     49.907               1299.0 -0.004836  \n",
       "2016-01-03       6011974     49.914               1650.0 -0.008005  \n",
       "2016-01-04       4891418     49.963               1112.0  0.004323  \n",
       "2016-01-05       5554693     49.976               1505.0 -0.004878  \n",
       "2016-01-06      10471777     49.916               3469.0 -0.004902  \n",
       "...                  ...        ...                  ...       ...  \n",
       "2022-11-24     361588723     44.670              30828.0 -0.001286  \n",
       "2022-11-25     295063546     44.667              37548.0 -0.023929  \n",
       "2022-11-26     205355717     44.746              35847.0  0.012488  \n",
       "2022-11-27     175104696     44.739              23536.0  0.001146  \n",
       "2022-11-28     192744138     44.742              24643.0 -0.054550  \n",
       "\n",
       "[2523 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5d4f07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide X and Y\n",
    "X = Data.iloc[:,0:]\n",
    "#Y = Data['returns']   # 用returns的话就用这一行，然后把下一行comment掉\n",
    "Y = ltcData['priceUSD'].shift(-1)[30:] # 反之亦然"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb3275b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activeaddresses30std</th>\n",
       "      <th>activeaddresses30var</th>\n",
       "      <th>activeaddresses7trx</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>difficulty30mom</th>\n",
       "      <th>difficulty30trx</th>\n",
       "      <th>difficulty90mom</th>\n",
       "      <th>difficulty90roc</th>\n",
       "      <th>difficulty90rsi</th>\n",
       "      <th>difficulty90trx</th>\n",
       "      <th>...</th>\n",
       "      <th>sentinusd30emaUSD</th>\n",
       "      <th>sentinusd30smaUSD</th>\n",
       "      <th>sentinusd30wmaUSD</th>\n",
       "      <th>sentinusd90emaUSD</th>\n",
       "      <th>sentinusd90varUSD</th>\n",
       "      <th>sentinusd90wmaUSD</th>\n",
       "      <th>sentinusdUSD</th>\n",
       "      <th>top100cap</th>\n",
       "      <th>transactionvalueUSD</th>\n",
       "      <th>returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-02</th>\n",
       "      <td>7666</td>\n",
       "      <td>14691594</td>\n",
       "      <td>0.296</td>\n",
       "      <td>51718</td>\n",
       "      <td>2875.0</td>\n",
       "      <td>0.146</td>\n",
       "      <td>3694.0</td>\n",
       "      <td>7.693</td>\n",
       "      <td>55.143</td>\n",
       "      <td>0.073</td>\n",
       "      <td>...</td>\n",
       "      <td>13119990</td>\n",
       "      <td>14447549</td>\n",
       "      <td>13084361</td>\n",
       "      <td>15062343</td>\n",
       "      <td>9.207781e+13</td>\n",
       "      <td>15267519</td>\n",
       "      <td>6145265</td>\n",
       "      <td>49.907</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>-0.004836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03</th>\n",
       "      <td>7553</td>\n",
       "      <td>14263642</td>\n",
       "      <td>0.531</td>\n",
       "      <td>50653</td>\n",
       "      <td>1810.0</td>\n",
       "      <td>0.152</td>\n",
       "      <td>2764.0</td>\n",
       "      <td>5.771</td>\n",
       "      <td>53.920</td>\n",
       "      <td>0.074</td>\n",
       "      <td>...</td>\n",
       "      <td>12661408</td>\n",
       "      <td>14247155</td>\n",
       "      <td>12540130</td>\n",
       "      <td>14863434</td>\n",
       "      <td>9.237091e+13</td>\n",
       "      <td>15058214</td>\n",
       "      <td>6011974</td>\n",
       "      <td>49.914</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>-0.008005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>6990</td>\n",
       "      <td>12215979</td>\n",
       "      <td>0.492</td>\n",
       "      <td>50158</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>0.156</td>\n",
       "      <td>2268.0</td>\n",
       "      <td>4.737</td>\n",
       "      <td>53.364</td>\n",
       "      <td>0.074</td>\n",
       "      <td>...</td>\n",
       "      <td>12160118</td>\n",
       "      <td>13934412</td>\n",
       "      <td>11936534</td>\n",
       "      <td>14644269</td>\n",
       "      <td>9.336173e+13</td>\n",
       "      <td>14824650</td>\n",
       "      <td>4891418</td>\n",
       "      <td>49.963</td>\n",
       "      <td>1112.0</td>\n",
       "      <td>0.004323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            activeaddresses30std  activeaddresses30var  activeaddresses7trx  \\\n",
       "Date                                                                          \n",
       "2016-01-02                  7666              14691594                0.296   \n",
       "2016-01-03                  7553              14263642                0.531   \n",
       "2016-01-04                  6990              12215979                0.492   \n",
       "\n",
       "            difficulty  difficulty30mom  difficulty30trx  difficulty90mom  \\\n",
       "Date                                                                        \n",
       "2016-01-02       51718           2875.0            0.146           3694.0   \n",
       "2016-01-03       50653           1810.0            0.152           2764.0   \n",
       "2016-01-04       50158           1315.0            0.156           2268.0   \n",
       "\n",
       "            difficulty90roc  difficulty90rsi  difficulty90trx  ...  \\\n",
       "Date                                                           ...   \n",
       "2016-01-02            7.693           55.143            0.073  ...   \n",
       "2016-01-03            5.771           53.920            0.074  ...   \n",
       "2016-01-04            4.737           53.364            0.074  ...   \n",
       "\n",
       "            sentinusd30emaUSD  sentinusd30smaUSD  sentinusd30wmaUSD  \\\n",
       "Date                                                                  \n",
       "2016-01-02           13119990           14447549           13084361   \n",
       "2016-01-03           12661408           14247155           12540130   \n",
       "2016-01-04           12160118           13934412           11936534   \n",
       "\n",
       "            sentinusd90emaUSD  sentinusd90varUSD  sentinusd90wmaUSD  \\\n",
       "Date                                                                  \n",
       "2016-01-02           15062343       9.207781e+13           15267519   \n",
       "2016-01-03           14863434       9.237091e+13           15058214   \n",
       "2016-01-04           14644269       9.336173e+13           14824650   \n",
       "\n",
       "            sentinusdUSD  top100cap  transactionvalueUSD   returns  \n",
       "Date                                                                \n",
       "2016-01-02       6145265     49.907               1299.0 -0.004836  \n",
       "2016-01-03       6011974     49.914               1650.0 -0.008005  \n",
       "2016-01-04       4891418     49.963               1112.0  0.004323  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd589ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into three data sets\n",
    "X_train = X['2016-01-01':'2019-12-31']\n",
    "X_val = X['2020-01-01':'2021-05-31']\n",
    "X_test = X['2021-06-01':'2023-01-01']\n",
    "\n",
    "Y_train = Y['2016-01-01':'2019-12-31']\n",
    "Y_val = Y['2020-01-01':'2021-05-31']\n",
    "Y_test = Y['2021-06-01':'2023-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e5e9fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing mixmax, total=   0.0s\n",
      "[Pipeline] ............ (step 2 of 2) Processing robust, total=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;mixmax&#x27;, MinMaxScaler()), [&#x27;robust&#x27;, RobustScaler()]],\n",
       "         verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;mixmax&#x27;, MinMaxScaler()), [&#x27;robust&#x27;, RobustScaler()]],\n",
       "         verbose=True)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RobustScaler</label><div class=\"sk-toggleable__content\"><pre>RobustScaler()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('mixmax', MinMaxScaler()), ['robust', RobustScaler()]],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators=[]\n",
    "estimators.append(['mixmax',MinMaxScaler()])\n",
    "estimators.append(['robust',RobustScaler()])\n",
    "scale=Pipeline(estimators,verbose=True)\n",
    "scale.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6fc0859",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=scale.transform(X_train)\n",
    "X_test=scale.transform(X_test)\n",
    "X_val = scale.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8a84d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f6916ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define neural network model\n",
    "shape=X.shape[1]\n",
    "def build_model(hp, initializer='normal', activation='relu', NUM_FEATURES=shape):\n",
    "    # create model\n",
    "    hp_units1 = hp.Int('units1', min_value=32, max_value=512, step=32)\n",
    "    hp_units2 = hp.Int('units2', min_value=32, max_value=512, step=32)\n",
    "    hp_units3 = hp.Int('units3', min_value=32, max_value=512, step=32)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hp_units1, input_shape=(NUM_FEATURES,), kernel_initializer=initializer, activation=activation))\n",
    "    model.add(Dense(hp_units2, activation=activation))\n",
    "    model.add(Dense(hp_units3, activation=activation))\n",
    "    model.add(Dense(1, activation=activation))\n",
    "    # Compile model\n",
    "    adam=keras.optimizers.Adam(lr=lr_schedule(0), amsgrad=True)\n",
    "    #sgd=keras.optimizers.SGD(learning_rate=0.08, momentum=0.9, nesterov=False)\n",
    "    model.compile(loss='logcosh', optimizer=adam, metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "112c8df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 00:34:16.609927: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-04 00:34:16.610990: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "/home/spectre/anaconda3/envs/tensorplustorch/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "320               |?                 |units1\n",
      "96                |?                 |units2\n",
      "224               |?                 |units3\n",
      "\n",
      "Learning rate:  0.001\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 1460\n  y sizes: 1431\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m tuner \u001b[38;5;241m=\u001b[39m kt\u001b[38;5;241m.\u001b[39mRandomSearch(\n\u001b[1;32m      2\u001b[0m     build_model,\n\u001b[1;32m      3\u001b[0m     objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_mae\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m     directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mltc_tune\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m     project_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mANN_TUNE\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 8\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorplustorch/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py:183\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 183\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorplustorch/lib/python3.10/site-packages/keras_tuner/engine/tuner.py:295\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    294\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[0;32m--> 295\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorplustorch/lib/python3.10/site-packages/keras_tuner/engine/tuner.py:222\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[1;32m    221\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 222\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m tuner_utils\u001b[38;5;241m.\u001b[39mvalidate_trial_results(\n\u001b[1;32m    224\u001b[0m     results, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHyperModel.fit()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m )\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorplustorch/lib/python3.10/site-packages/keras_tuner/engine/hypermodel.py:140\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorplustorch/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorplustorch/lib/python3.10/site-packages/keras/engine/data_adapter.py:1851\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1844\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1845\u001b[0m         label,\n\u001b[1;32m   1846\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m   1847\u001b[0m             \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[1;32m   1848\u001b[0m         ),\n\u001b[1;32m   1849\u001b[0m     )\n\u001b[1;32m   1850\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1851\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 1460\n  y sizes: 1431\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_mae',\n",
    "    directory='ltc_tune',\n",
    "    project_name='ANN_TUNE'\n",
    ")\n",
    "\n",
    "tuner.search(X_train, Y_train, epochs=5000, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9884fdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best hyperparameters.\n",
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "# Build the model with the best hp.\n",
    "regressor = build_model(best_hp)\n",
    "# Fit with the entire dataset.\n",
    "X_all = np.concatenate((X_train, X_val))\n",
    "Y_all = np.concatenate((Y_train, Y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46c3b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best hyperparameters\n",
    "best_hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a7de56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a85653fe",
   "metadata": {},
   "source": [
    "stop training when loss is not increasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48b24b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='loss', patience=1000,verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85174a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(x=X_all, y=Y_all, epochs=5000, use_multiprocessing=True, callbacks=[earlyStopping])\n",
    "# regressor=KerasRegressor(build_fn=sequential_model,epochs=5000,verbose=1, use_multiprocessing=True, callback=[earlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf8814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred=regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0f090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for check\n",
    "Y_train_pred=regressor.predict(X_train)\n",
    "r2_score(Y_train, Y_train_pred) #training score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e757ef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2=r2_score(Y_test[:-30],y_pred[:-30]) #score/ r^2\n",
    "print(f'r2:{r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ef1c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2_oos\n",
    "def r2_oos(ret, pred):\n",
    "    sum_of_sq_res = np.nansum(np.power((ret-pred), 2))\n",
    "    sum_of_sq_total = np.nansum(np.power(ret, 2))\n",
    "    \n",
    "    return 1-sum_of_sq_res/sum_of_sq_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b87143",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae=mean_absolute_error(Y_test[:-30],y_pred[:-30]) #mae\n",
    "print(f'mae:{mae}')\n",
    "\n",
    "rmse=np.sqrt(mean_squared_error(Y_test[:-30],y_pred[:-30])) #rmse\n",
    "print(f'rmse:{rmse}')\n",
    "\n",
    "mape=mean_absolute_percentage_error(Y_test[:-30],y_pred[:-30]) #mape\n",
    "print(f'mape:{mape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1ba462",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e15009",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_oos = r2_oos(Y_test[:-30], y_pred[:-30])\n",
    "print(f'r2_oos:{r2_oos}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb36caf",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5641115",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df = pd.DataFrame(zip(Y_test,y_pred),columns=['Y_test','y_pred'])\n",
    "pre_df.index = Y_test.index\n",
    "pre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4bd2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df['pred_returns'] = pre_df['y_pred'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b94aa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9674c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(zip(Y_test,y_pred),columns=['Y_test','y_pred']).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732393ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df.to_csv(\"../result/ANN/ltc_NN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12ff04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kdeconnect-cli -n TAS-AN00 --ping-msg 'Script complete!'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "efc08374433b8d8e4a9fd8a0a66f7295c7ce37eceb639810a945045512ff181b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
