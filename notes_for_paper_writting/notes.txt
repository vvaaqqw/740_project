用spider。。。里面的爬虫爬去数据放到data文件夹里>>用preprocessing里的文件进行feature selection，放到Data文件夹里>>
针对第一篇paper
paper中标黄的是我们新加的用于所有模型的衡量(performance metrics for evaluation)好坏的指标
我们没有做classcification model， 全部是回归
我们只做了feature selection这个部分, 没用pca
Feature selection process is based on Pearson correlation, random forest, and variance inflation factor.
我们没有把数据分成三个intervals

btc数据2010/07/17 - 2022/11/29 但我们只用了2016/01/01 - 2022/11/29 来分析，以提高准确率
eth数据2016/01/01 - 2022/11/29
ltc数据2012/01/01 - 2022/11/29 我们只用2016/01/01之后的数据


我们的目标是用模型去预测30天之后的price，其他不管
把data分为training, validation, 和testing
training set 2016/01/01- 2019/12/31
validation set 2020/01/01 - 2021/05/31
testing set 2021/06/01 - 2022/11/29

我们只做了ANN, LSTM, GBRT, random forest
LSTM的结果其实在结尾为basic而不是tune的ipynb文件里，实际是因为没有时间去调参
其中gbrt和random forest可以照着同文件夹下的report写。
对每个模型需要汇报 mae, rmse, mape, r2, 还有一副图，效果比较好的图可以展示一下

LSTM：从传统的神经网络结构我们可以看出，信号流从输入层到输出层依次流过，同一层级的神经元之间，信号是不会相互传递的。这样就会导致一个问题，输出信号只与输入信号有关，而与输入信号的先后顺序无关。并且神经元本身也不具有存储信息的能力，整个网络也就没有“记忆”能力，当输入信号是一个跟时间相关的信号时，如果我们想要通过这段信号的“上下文”信息来理解一段时间序列的意思，传统的神经网络结构就显得无力了。与我们人类的理解过程类似，我们听到一句话时往往需要通过这句话中词语出现的顺序以及我们之前所学的关于这些词语的意思来理解整段话的意思，而不是简单的通过其中的几个词语来理解。
普通RNN对于信息的长期依赖问题没有很好的处理办法。为了克服这个问题，Hochreiter等人在1997年改进了RNN，提出了一种特殊的RNN模型——LSTM网络，可以学习长期依赖信息，在后面的20多年被改良和得到了广泛的应用，并且取得了极大的成功。
我们用randomsearch 来做hyperparameter tuning
-------------------------------------
>BTC:
>>ANN:
>>> r2:0.1927361342862608
>>> mae:8163.219480529312
>>> rmse:12157.60514903401
>>> mape:41.23410571653858
>>> r2_oos:0.9015624405056986

>LSTM:
>>>  r2:0.36840732956924405
>>> mae:8796.191353258237
>>> rmse:10753.722330603252
>>> mape:27.21430715435315
>>> r2_oos:0.9229837433430483

>GBRT:
>>> r2:0.4598534304244001
>>> mae:31.444099032858905
>>> rmse:39.522421057233664
>>> mape:31.68330093202775
>>> r2_oos:0.901197500581905

>Random Forest:
>>> r2:0.20344581562968067
>>> mae:9819.435502013786
>>> rmse:12076.690584499942
>>>mape:36.91348580851829
>>> r2_oos:0.9028683764445947


------------------------------------------
>ETH:
>>ANN:
>>> r2:
>>> mae:
>>> rmse:
>>> mape:
>>> r2_oos:

>LSTM:
>>>
>>>
>>>
>>>
>>>

>GBRT:
>>>
>>>
>>>
>>>
>>>

>Random Forest:
>>>
>>>
>>>
>>>
>>>

------------------------------------------
>LTC:
>>ANN:
>>> r2:
>>> mae:
>>> rmse:
>>> mape:
>>> r2_oos:

>LSTM:
>>>
>>>
>>>
>>>
>>>

>GBRT:
>>>
>>>
>>>
>>>
>>>

>Random Forest:
>>>
>>>
>>>
>>>
>>>

